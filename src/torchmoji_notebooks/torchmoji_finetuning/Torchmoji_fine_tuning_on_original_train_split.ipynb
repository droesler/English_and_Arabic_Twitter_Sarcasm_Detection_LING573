{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Torchmoji_fine_tuning_on_original_train_split.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Torchmoji cpu-based chain thaw fine-tuning\n",
        "\n",
        "Set runtime accelerator to 'None'\n",
        "\n",
        "code based on: https://github.com/huggingface/torchMoji/blob/master/examples/finetune_insults_chain-thaw.py"
      ],
      "metadata": {
        "id": "bIffiNzWb22r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installs"
      ],
      "metadata": {
        "id": "6mhPadkqcpXd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install emoji==0.6.0\n",
        "!pip install numpy==1.21.5\n",
        "!pip install torch==1.10.0+cu111 torchvision==0.11.0+cu111 torchaudio==0.10.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip install scipy==1.5.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHNV0tLpbuYS",
        "outputId": "43c2dde3-a5d5-4dc3-8411-c07adada704b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (22.0.4)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: emoji==0.6.0 in /usr/local/lib/python3.7/dist-packages (0.6.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: numpy==1.21.5 in /usr/local/lib/python3.7/dist-packages (1.21.5)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Requirement already satisfied: torch==1.10.0+cu111 in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision==0.11.0+cu111 in /usr/local/lib/python3.7/dist-packages (0.11.0+cu111)\n",
            "Requirement already satisfied: torchaudio==0.10.0 in /usr/local/lib/python3.7/dist-packages (0.10.0+rocm4.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.10.0+cu111) (4.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.11.0+cu111) (1.21.5)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.11.0+cu111) (7.1.2)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: scipy==1.5.2 in /usr/local/lib/python3.7/dist-packages (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from scipy==1.5.2) (1.21.5)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Restart the runtime after installs!**"
      ],
      "metadata": {
        "id": "gii2Cl3YraPD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clone torchmoji repo\n",
        "This is a modified version of the original Torchmoji that works with pytorch 1.10. I forked this to my github in case the modder removes it.\n",
        "\n",
        "original: https://github.com/huggingface/torchMoji\n",
        "modded: https://github.com/cw75/torchMoji"
      ],
      "metadata": {
        "id": "pgK64YD7hkPf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/droesler/torchMoji"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07_r0JnYhGWT",
        "outputId": "b8630fbd-3a41-4b07-e363-6904a7506a6a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'torchMoji'...\n",
            "remote: Enumerating objects: 192, done.\u001b[K\n",
            "remote: Counting objects: 100% (15/15), done.\u001b[K\n",
            "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 192 (delta 4), reused 15 (delta 4), pack-reused 177\u001b[K\n",
            "Receiving objects: 100% (192/192), 82.41 MiB | 25.69 MiB/s, done.\n",
            "Resolving deltas: 100% (75/75), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# change to torchMoji directory to run scripts from\n",
        "import os\n",
        "os.chdir('torchMoji')"
      ],
      "metadata": {
        "id": "bWUWB_eILO1I"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download torchmoji pre-trained weights (Type 'y' when prompted)\n",
        "These are the original huggingface pre-trained weights"
      ],
      "metadata": {
        "id": "b_Ug9u8lhUN7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 scripts/download_weights.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6r4ZHeH9hSoN",
        "outputId": "a3f40c30-b6c9-449c-97c3-ba3406db5d1c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "About to download the pretrained weights file from https://www.dropbox.com/s/q8lax9ary32c7t9/pytorch_model.bin?dl=0#\n",
            "The size of the file is roughly 85MB. Continue? [y/n]\n",
            "y\n",
            "Downloading...\n",
            "Running system call: wget https://www.dropbox.com/s/q8lax9ary32c7t9/pytorch_model.bin?dl=0# -O /content/torchMoji/model/pytorch_model.bin\n",
            "--2022-05-05 19:33:57--  https://www.dropbox.com/s/q8lax9ary32c7t9/pytorch_model.bin?dl=0\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.2.18, 2620:100:6021:18::a27d:4112\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.2.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/q8lax9ary32c7t9/pytorch_model.bin [following]\n",
            "--2022-05-05 19:33:58--  https://www.dropbox.com/s/raw/q8lax9ary32c7t9/pytorch_model.bin\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc3a2ba3544aba61b4044c3871ef.dl.dropboxusercontent.com/cd/0/inline/BktY3lxyFjOP3g-gWLzOIZXaZpU5ZG2bmbothwvNnSvbwFr6vVfd5odSo6K03IbyMFnYCN_gYAJtGX6N4mSbW9ORxtkH0yH5PNkUepNoswpeAAw4zDHgO0GEVU_Qu3iaySy2z4ZnDgaFDsYZEitpFH-ic6e6m7zrJOojaWUBidD2kw/file# [following]\n",
            "--2022-05-05 19:33:59--  https://uc3a2ba3544aba61b4044c3871ef.dl.dropboxusercontent.com/cd/0/inline/BktY3lxyFjOP3g-gWLzOIZXaZpU5ZG2bmbothwvNnSvbwFr6vVfd5odSo6K03IbyMFnYCN_gYAJtGX6N4mSbW9ORxtkH0yH5PNkUepNoswpeAAw4zDHgO0GEVU_Qu3iaySy2z4ZnDgaFDsYZEitpFH-ic6e6m7zrJOojaWUBidD2kw/file\n",
            "Resolving uc3a2ba3544aba61b4044c3871ef.dl.dropboxusercontent.com (uc3a2ba3544aba61b4044c3871ef.dl.dropboxusercontent.com)... 162.125.65.15, 2620:100:601a:15::a27d:70f\n",
            "Connecting to uc3a2ba3544aba61b4044c3871ef.dl.dropboxusercontent.com (uc3a2ba3544aba61b4044c3871ef.dl.dropboxusercontent.com)|162.125.65.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/BktNlJIV9FF_xCy7Hg-4VJvc7-B7YM-VjiWJgUZKeNXmamnc50bQLRJ0vMYuMIRGvdBkZ9Vmp9reaZkDjfpzgtFlrGpJZsq97Jke_Q4Oru8qhs6Hixq42mwGgvM_yN8g7RqsapMtl8l-RHCLV8_kqi_8FDPoch8YVzCwzewBcPEBGVlvLnSyYv32diXxOv5DfrZQ691FCGDZl5FFUTwtGPzbiXKaahaMW-Uu9-sb0s6hOitiQ2W456GMkkpFr0iQMYMiwaaORioWC2o-LK1nsNbTuR0bPoT1rZFY-JC6hWhAzNrCLLauRI_IpQ8xG6Zh9MtHREmO6iBIf-7NgkRThSx3z2HbzicfBwCMV3DLcZE-RWST5Zf36SdFKFEv1eNsa_COkDjiW_T1yPvwhZ7KjiDhe5UwHv88ZcPyJ8Bn9aVVVw/file [following]\n",
            "--2022-05-05 19:33:59--  https://uc3a2ba3544aba61b4044c3871ef.dl.dropboxusercontent.com/cd/0/inline2/BktNlJIV9FF_xCy7Hg-4VJvc7-B7YM-VjiWJgUZKeNXmamnc50bQLRJ0vMYuMIRGvdBkZ9Vmp9reaZkDjfpzgtFlrGpJZsq97Jke_Q4Oru8qhs6Hixq42mwGgvM_yN8g7RqsapMtl8l-RHCLV8_kqi_8FDPoch8YVzCwzewBcPEBGVlvLnSyYv32diXxOv5DfrZQ691FCGDZl5FFUTwtGPzbiXKaahaMW-Uu9-sb0s6hOitiQ2W456GMkkpFr0iQMYMiwaaORioWC2o-LK1nsNbTuR0bPoT1rZFY-JC6hWhAzNrCLLauRI_IpQ8xG6Zh9MtHREmO6iBIf-7NgkRThSx3z2HbzicfBwCMV3DLcZE-RWST5Zf36SdFKFEv1eNsa_COkDjiW_T1yPvwhZ7KjiDhe5UwHv88ZcPyJ8Bn9aVVVw/file\n",
            "Reusing existing connection to uc3a2ba3544aba61b4044c3871ef.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 89616062 (85M) [application/octet-stream]\n",
            "Saving to: ‘/content/torchMoji/model/pytorch_model.bin’\n",
            "\n",
            "/content/torchMoji/ 100%[===================>]  85.46M  22.0MB/s    in 4.1s    \n",
            "\n",
            "2022-05-05 19:34:03 (21.0 MB/s) - ‘/content/torchMoji/model/pytorch_model.bin’ saved [89616062/89616062]\n",
            "\n",
            "Downloaded weights to model/pytorch_model.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function from torchmoji github:"
      ],
      "metadata": {
        "id": "YZRJ6qmd5ddW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Finetuning example.\n",
        "Trains the torchMoji model on the kaggle insults dataset, using the 'chain-thaw'\n",
        "finetuning method and the accuracy metric. See the blog post at\n",
        "https://medium.com/@bjarkefelbo/what-can-we-learn-from-emojis-6beb165a5ea0\n",
        "for more information. Note that results may differ a bit due to slight\n",
        "changes in preprocessing and train/val/test split.\n",
        "The 'chain-thaw' method does the following:\n",
        "0) Load all weights except for the softmax layer. Extend the embedding layer if\n",
        "   necessary, initialising the new weights with random values.\n",
        "1) Freeze every layer except the last (softmax) layer and train it.\n",
        "2) Freeze every layer except the first layer and train it.\n",
        "3) Freeze every layer except the second etc., until the second last layer.\n",
        "4) Unfreeze all layers and train entire model.\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import print_function\n",
        "# import example_helper\n",
        "import json\n",
        "from torchmoji.model_def import torchmoji_transfer\n",
        "from torchmoji.global_variables import PRETRAINED_PATH\n",
        "from torchmoji.finetuning import (\n",
        "     load_benchmark,\n",
        "     finetune)\n",
        "\n",
        "\n",
        "TRAIN_DATASET_PATH = '/content/balanced_train_En_no_emoji.pkl'\n",
        "VAL_DATASET_PATH = '/content/balanced_validation_En_no_emoji.pkl'\n",
        "\n",
        "nb_classes = 2\n",
        "\n",
        "with open('/content/torchMoji/model/vocabulary.json', 'r') as f:\n",
        "    vocab = json.load(f)\n",
        "\n",
        "# Load dataset. Extend the existing vocabulary with up to 10000 tokens from\n",
        "# the training dataset.\n",
        "data = load_benchmark(TRAIN_DATASET_PATH, VAL_DATASET_PATH, vocab, extend_with=10000)\n",
        "\n",
        "# Set up model and finetune. Note that we have to extend the embedding layer\n",
        "# with the number of tokens added to the vocabulary.\n",
        "model = torchmoji_transfer(nb_classes, PRETRAINED_PATH, extend_embedding=data['added'])\n",
        "print(model)\n",
        "model, acc = finetune(model, data['texts'], data['labels'], nb_classes,\n",
        "                      data['batch_size'], method='chain-thaw')\n",
        "print('Acc: {}'.format(acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rBaPZCI0g6r",
        "outputId": "459c4c21-0148-4c51-f567-e27f14d14761"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/torchMoji/torchmoji/model_def.py:163: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  nn.init.uniform(self.embed.weight.data, a=-0.5, b=0.5)\n",
            "/content/torchMoji/torchmoji/model_def.py:165: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  nn.init.xavier_uniform(t)\n",
            "/content/torchMoji/torchmoji/model_def.py:167: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.\n",
            "  nn.init.orthogonal(t)\n",
            "/content/torchMoji/torchmoji/model_def.py:169: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
            "  nn.init.constant(t, 0)\n",
            "/content/torchMoji/torchmoji/model_def.py:171: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  nn.init.xavier_uniform(self.output_layer[0].weight.data)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading weights for embed.weight\n",
            "Loading weights for lstm_0.weight_ih_l0\n",
            "Loading weights for lstm_0.weight_hh_l0\n",
            "Loading weights for lstm_0.bias_ih_l0\n",
            "Loading weights for lstm_0.bias_hh_l0\n",
            "Loading weights for lstm_0.weight_ih_l0_reverse\n",
            "Loading weights for lstm_0.weight_hh_l0_reverse\n",
            "Loading weights for lstm_0.bias_ih_l0_reverse\n",
            "Loading weights for lstm_0.bias_hh_l0_reverse\n",
            "Loading weights for lstm_1.weight_ih_l0\n",
            "Loading weights for lstm_1.weight_hh_l0\n",
            "Loading weights for lstm_1.bias_ih_l0\n",
            "Loading weights for lstm_1.bias_hh_l0\n",
            "Loading weights for lstm_1.weight_ih_l0_reverse\n",
            "Loading weights for lstm_1.weight_hh_l0_reverse\n",
            "Loading weights for lstm_1.bias_ih_l0_reverse\n",
            "Loading weights for lstm_1.bias_hh_l0_reverse\n",
            "Loading weights for attention_layer.attention_vector\n",
            "Ignoring weights for output_layer.0.weight\n",
            "Ignoring weights for output_layer.0.bias\n",
            "TorchMoji(\n",
            "  (embed): Embedding(50000, 256)\n",
            "  (embed_dropout): Dropout2d(p=0.1, inplace=False)\n",
            "  (lstm_0): LSTMHardSigmoid(256, 512, batch_first=True, bidirectional=True)\n",
            "  (lstm_1): LSTMHardSigmoid(1024, 512, batch_first=True, bidirectional=True)\n",
            "  (attention_layer): Attention(2304, return attention=False)\n",
            "  (final_dropout): Dropout(p=0.5, inplace=False)\n",
            "  (output_layer): Sequential(\n",
            "    (0): Linear(in_features=2304, out_features=1, bias=True)\n",
            "  )\n",
            ")\n",
            "Method:  chain-thaw\n",
            "Metric:  acc\n",
            "Classes: 2\n",
            "Training..\n",
            "Finetuning Sequential(\n",
            "  (0): Linear(in_features=2304, out_features=1, bias=True)\n",
            ")\n",
            "original val loss 0.69364053\n",
            "== Epoch 0 step 0 train loss 0.6923286 train acc 0.56\n",
            "== Epoch 0 step 1 train loss 0.6968866 train acc 0.528\n",
            "== Epoch 0 step 2 train loss 0.6962049 train acc 0.452\n",
            "== Epoch 0 step 3 train loss 0.6952184 train acc 0.488\n",
            "== Epoch 0 step 4 train loss 0.69380796 train acc 0.48\n",
            "== Epoch 0 step 5 train loss 0.69245183 train acc 0.52\n",
            "== Epoch 0 step 6 train loss 0.6905877 train acc 0.52\n",
            "== Epoch 0 step 7 train loss 0.6908545 train acc 0.524\n",
            "== Epoch 0 step 8 train loss 0.693396 train acc 0.516\n",
            "== Epoch 0 step 9 train loss 0.68808943 train acc 0.596\n",
            "== Epoch 0 step 10 train loss 0.6889389 train acc 0.572\n",
            "== Epoch 0 step 11 train loss 0.69289255 train acc 0.54\n",
            "== Epoch 0 step 12 train loss 0.6874208 train acc 0.644\n",
            "== Epoch 0 step 13 train loss 0.68754286 train acc 0.564\n",
            "== Epoch 0 step 14 train loss 0.687596 train acc 0.58\n",
            "== Epoch 0 step 15 train loss 0.690083 train acc 0.552\n",
            "== Epoch 0 step 16 train loss 0.68685466 train acc 0.6\n",
            "== Epoch 0 step 17 train loss 0.68401366 train acc 0.584\n",
            "== Epoch 0 step 18 train loss 0.68176305 train acc 0.608\n",
            "== Epoch 0 step 19 train loss 0.69014966 train acc 0.556\n",
            "val acc 0.6162790697674418\n",
            "val loss 0.685174\n",
            "Saving model at /tmp/tmpl4hmbw_e/torchmoji-checkpoint-ff996a33-fdc2-4d12-93c7-d89fc8e7551a.bin\n",
            "== Epoch 1 step 0 train loss 0.67720306 train acc 0.656\n",
            "== Epoch 1 step 1 train loss 0.6818677 train acc 0.644\n",
            "== Epoch 1 step 2 train loss 0.6891221 train acc 0.592\n",
            "== Epoch 1 step 3 train loss 0.6782174 train acc 0.632\n",
            "== Epoch 1 step 4 train loss 0.68141985 train acc 0.584\n",
            "== Epoch 1 step 5 train loss 0.68291444 train acc 0.62\n",
            "== Epoch 1 step 6 train loss 0.68391347 train acc 0.588\n",
            "== Epoch 1 step 7 train loss 0.6825973 train acc 0.588\n",
            "== Epoch 1 step 8 train loss 0.68513316 train acc 0.564\n",
            "== Epoch 1 step 9 train loss 0.6776621 train acc 0.624\n",
            "== Epoch 1 step 10 train loss 0.67789435 train acc 0.68\n",
            "== Epoch 1 step 11 train loss 0.6796652 train acc 0.652\n",
            "== Epoch 1 step 12 train loss 0.674548 train acc 0.652\n",
            "== Epoch 1 step 13 train loss 0.6755148 train acc 0.636\n",
            "== Epoch 1 step 14 train loss 0.6756862 train acc 0.648\n",
            "== Epoch 1 step 15 train loss 0.6808453 train acc 0.624\n",
            "== Epoch 1 step 16 train loss 0.6754181 train acc 0.664\n",
            "== Epoch 1 step 17 train loss 0.6793866 train acc 0.62\n",
            "== Epoch 1 step 18 train loss 0.6774216 train acc 0.652\n",
            "== Epoch 1 step 19 train loss 0.6783873 train acc 0.6\n",
            "val acc 0.6453488372093024\n",
            "val loss 0.6778503\n",
            "Saving model at /tmp/tmpl4hmbw_e/torchmoji-checkpoint-ff996a33-fdc2-4d12-93c7-d89fc8e7551a.bin\n",
            "== Epoch 2 step 0 train loss 0.6684974 train acc 0.664\n",
            "== Epoch 2 step 1 train loss 0.67271996 train acc 0.664\n",
            "== Epoch 2 step 2 train loss 0.68039054 train acc 0.644\n",
            "== Epoch 2 step 3 train loss 0.670453 train acc 0.668\n",
            "== Epoch 2 step 4 train loss 0.67123955 train acc 0.652\n",
            "== Epoch 2 step 5 train loss 0.6680129 train acc 0.656\n",
            "== Epoch 2 step 6 train loss 0.6816286 train acc 0.62\n",
            "== Epoch 2 step 7 train loss 0.67411 train acc 0.62\n",
            "== Epoch 2 step 8 train loss 0.6735254 train acc 0.636\n",
            "== Epoch 2 step 9 train loss 0.669863 train acc 0.656\n",
            "== Epoch 2 step 10 train loss 0.666597 train acc 0.692\n",
            "== Epoch 2 step 11 train loss 0.66850287 train acc 0.64\n",
            "== Epoch 2 step 12 train loss 0.6680844 train acc 0.644\n",
            "== Epoch 2 step 13 train loss 0.66715467 train acc 0.644\n",
            "== Epoch 2 step 14 train loss 0.6680782 train acc 0.676\n",
            "== Epoch 2 step 15 train loss 0.67223066 train acc 0.636\n",
            "== Epoch 2 step 16 train loss 0.6664833 train acc 0.684\n",
            "== Epoch 2 step 17 train loss 0.6713903 train acc 0.632\n",
            "== Epoch 2 step 18 train loss 0.66740215 train acc 0.656\n",
            "== Epoch 2 step 19 train loss 0.66405046 train acc 0.616\n",
            "val acc 0.6395348837209303\n",
            "val loss 0.67137295\n",
            "Saving model at /tmp/tmpl4hmbw_e/torchmoji-checkpoint-ff996a33-fdc2-4d12-93c7-d89fc8e7551a.bin\n",
            "== Epoch 3 step 0 train loss 0.6638096 train acc 0.688\n",
            "== Epoch 3 step 1 train loss 0.66588426 train acc 0.668\n",
            "== Epoch 3 step 2 train loss 0.67128193 train acc 0.644\n",
            "== Epoch 3 step 3 train loss 0.6638281 train acc 0.688\n",
            "== Epoch 3 step 4 train loss 0.66312844 train acc 0.692\n",
            "== Epoch 3 step 5 train loss 0.6652138 train acc 0.668\n",
            "== Epoch 3 step 6 train loss 0.6700511 train acc 0.644\n",
            "== Epoch 3 step 7 train loss 0.664897 train acc 0.624\n",
            "== Epoch 3 step 8 train loss 0.66815275 train acc 0.636\n",
            "== Epoch 3 step 9 train loss 0.65694994 train acc 0.664\n",
            "== Epoch 3 step 10 train loss 0.6553416 train acc 0.688\n",
            "== Epoch 3 step 11 train loss 0.6630769 train acc 0.676\n",
            "== Epoch 3 step 12 train loss 0.66194034 train acc 0.644\n",
            "== Epoch 3 step 13 train loss 0.6590608 train acc 0.664\n",
            "== Epoch 3 step 14 train loss 0.658926 train acc 0.704\n",
            "== Epoch 3 step 15 train loss 0.6631964 train acc 0.644\n",
            "== Epoch 3 step 16 train loss 0.65443593 train acc 0.712\n",
            "== Epoch 3 step 17 train loss 0.66551524 train acc 0.632\n",
            "== Epoch 3 step 18 train loss 0.66306657 train acc 0.668\n",
            "== Epoch 3 step 19 train loss 0.6669322 train acc 0.64\n",
            "val acc 0.6395348837209303\n",
            "val loss 0.665625\n",
            "Saving model at /tmp/tmpl4hmbw_e/torchmoji-checkpoint-ff996a33-fdc2-4d12-93c7-d89fc8e7551a.bin\n",
            "== Epoch 4 step 0 train loss 0.6563131 train acc 0.688\n",
            "== Epoch 4 step 1 train loss 0.65602964 train acc 0.688\n",
            "== Epoch 4 step 2 train loss 0.6614867 train acc 0.672\n",
            "== Epoch 4 step 3 train loss 0.654132 train acc 0.68\n",
            "== Epoch 4 step 4 train loss 0.6538185 train acc 0.7\n",
            "== Epoch 4 step 5 train loss 0.65532607 train acc 0.68\n",
            "== Epoch 4 step 6 train loss 0.6622137 train acc 0.66\n",
            "== Epoch 4 step 7 train loss 0.6599128 train acc 0.64\n",
            "== Epoch 4 step 8 train loss 0.66163796 train acc 0.632\n",
            "== Epoch 4 step 9 train loss 0.6515927 train acc 0.668\n",
            "== Epoch 4 step 10 train loss 0.65325063 train acc 0.688\n",
            "== Epoch 4 step 11 train loss 0.6558962 train acc 0.668\n",
            "== Epoch 4 step 12 train loss 0.6577377 train acc 0.656\n",
            "== Epoch 4 step 13 train loss 0.6496542 train acc 0.68\n",
            "== Epoch 4 step 14 train loss 0.6508944 train acc 0.708\n",
            "== Epoch 4 step 15 train loss 0.6603604 train acc 0.648\n",
            "== Epoch 4 step 16 train loss 0.64607716 train acc 0.72\n",
            "== Epoch 4 step 17 train loss 0.6531889 train acc 0.652\n",
            "== Epoch 4 step 18 train loss 0.659269 train acc 0.676\n",
            "== Epoch 4 step 19 train loss 0.6513826 train acc 0.652\n",
            "val acc 0.6569767441860465\n",
            "val loss 0.6605667\n",
            "Saving model at /tmp/tmpl4hmbw_e/torchmoji-checkpoint-ff996a33-fdc2-4d12-93c7-d89fc8e7551a.bin\n",
            "== Epoch 5 step 0 train loss 0.6507852 train acc 0.7\n",
            "== Epoch 5 step 1 train loss 0.6491673 train acc 0.7\n",
            "== Epoch 5 step 2 train loss 0.66183895 train acc 0.676\n",
            "== Epoch 5 step 3 train loss 0.64620376 train acc 0.688\n",
            "== Epoch 5 step 4 train loss 0.6538888 train acc 0.712\n",
            "== Epoch 5 step 5 train loss 0.6501939 train acc 0.684\n",
            "== Epoch 5 step 6 train loss 0.6543848 train acc 0.664\n",
            "== Epoch 5 step 7 train loss 0.65706724 train acc 0.664\n",
            "== Epoch 5 step 8 train loss 0.6590156 train acc 0.64\n",
            "== Epoch 5 step 9 train loss 0.6449822 train acc 0.684\n",
            "== Epoch 5 step 10 train loss 0.64208657 train acc 0.696\n",
            "== Epoch 5 step 11 train loss 0.64321107 train acc 0.688\n",
            "== Epoch 5 step 12 train loss 0.6526694 train acc 0.668\n",
            "== Epoch 5 step 13 train loss 0.6447713 train acc 0.688\n",
            "== Epoch 5 step 14 train loss 0.6444368 train acc 0.716\n",
            "== Epoch 5 step 15 train loss 0.6558321 train acc 0.66\n",
            "== Epoch 5 step 16 train loss 0.6396972 train acc 0.72\n",
            "== Epoch 5 step 17 train loss 0.6550787 train acc 0.66\n",
            "== Epoch 5 step 18 train loss 0.65458333 train acc 0.684\n",
            "== Epoch 5 step 19 train loss 0.648949 train acc 0.668\n",
            "val acc 0.6511627906976745\n",
            "val loss 0.6563009\n",
            "Saving model at /tmp/tmpl4hmbw_e/torchmoji-checkpoint-ff996a33-fdc2-4d12-93c7-d89fc8e7551a.bin\n",
            "== Epoch 6 step 0 train loss 0.6467377 train acc 0.704\n",
            "== Epoch 6 step 1 train loss 0.64450186 train acc 0.696\n",
            "== Epoch 6 step 2 train loss 0.65158796 train acc 0.676\n",
            "== Epoch 6 step 3 train loss 0.6378531 train acc 0.696\n",
            "== Epoch 6 step 4 train loss 0.6441911 train acc 0.72\n",
            "== Epoch 6 step 5 train loss 0.63987184 train acc 0.684\n",
            "== Epoch 6 step 6 train loss 0.6500514 train acc 0.66\n",
            "== Epoch 6 step 7 train loss 0.65049636 train acc 0.66\n",
            "== Epoch 6 step 8 train loss 0.6450653 train acc 0.644\n",
            "== Epoch 6 step 9 train loss 0.63927495 train acc 0.7\n",
            "== Epoch 6 step 10 train loss 0.64086103 train acc 0.72\n",
            "== Epoch 6 step 11 train loss 0.63579094 train acc 0.696\n",
            "== Epoch 6 step 12 train loss 0.63964194 train acc 0.668\n",
            "== Epoch 6 step 13 train loss 0.6375885 train acc 0.696\n",
            "== Epoch 6 step 14 train loss 0.6382114 train acc 0.724\n",
            "== Epoch 6 step 15 train loss 0.64610445 train acc 0.668\n",
            "== Epoch 6 step 16 train loss 0.6337555 train acc 0.732\n",
            "== Epoch 6 step 17 train loss 0.64381397 train acc 0.66\n",
            "== Epoch 6 step 18 train loss 0.64257497 train acc 0.688\n",
            "== Epoch 6 step 19 train loss 0.646302 train acc 0.672\n",
            "val acc 0.6569767441860465\n",
            "val loss 0.65247965\n",
            "Saving model at /tmp/tmpl4hmbw_e/torchmoji-checkpoint-ff996a33-fdc2-4d12-93c7-d89fc8e7551a.bin\n",
            "== Epoch 7 step 0 train loss 0.6350299 train acc 0.7\n",
            "== Epoch 7 step 1 train loss 0.6366092 train acc 0.688\n",
            "== Epoch 7 step 2 train loss 0.6401576 train acc 0.684\n",
            "== Epoch 7 step 3 train loss 0.6332656 train acc 0.7\n",
            "== Epoch 7 step 4 train loss 0.6356127 train acc 0.724\n",
            "== Epoch 7 step 5 train loss 0.6305308 train acc 0.68\n",
            "== Epoch 7 step 6 train loss 0.64460707 train acc 0.656\n",
            "== Epoch 7 step 7 train loss 0.6374709 train acc 0.672\n",
            "== Epoch 7 step 8 train loss 0.6495067 train acc 0.656\n",
            "== Epoch 7 step 9 train loss 0.6292857 train acc 0.696\n",
            "== Epoch 7 step 10 train loss 0.6283777 train acc 0.716\n",
            "== Epoch 7 step 11 train loss 0.63544476 train acc 0.692\n",
            "== Epoch 7 step 12 train loss 0.6456639 train acc 0.68\n",
            "== Epoch 7 step 13 train loss 0.6386821 train acc 0.696\n",
            "== Epoch 7 step 14 train loss 0.6291019 train acc 0.72\n",
            "== Epoch 7 step 15 train loss 0.6489321 train acc 0.672\n",
            "== Epoch 7 step 16 train loss 0.61932945 train acc 0.732\n",
            "== Epoch 7 step 17 train loss 0.6396816 train acc 0.66\n",
            "== Epoch 7 step 18 train loss 0.63873863 train acc 0.684\n",
            "== Epoch 7 step 19 train loss 0.6464909 train acc 0.68\n",
            "val acc 0.6511627906976745\n",
            "val loss 0.64916587\n",
            "Saving model at /tmp/tmpl4hmbw_e/torchmoji-checkpoint-ff996a33-fdc2-4d12-93c7-d89fc8e7551a.bin\n",
            "== Epoch 8 step 0 train loss 0.62452507 train acc 0.704\n",
            "== Epoch 8 step 1 train loss 0.6357532 train acc 0.692\n",
            "== Epoch 8 step 2 train loss 0.63819206 train acc 0.684\n",
            "== Epoch 8 step 3 train loss 0.62755895 train acc 0.704\n",
            "== Epoch 8 step 4 train loss 0.6321074 train acc 0.728\n",
            "== Epoch 8 step 5 train loss 0.63007826 train acc 0.684\n",
            "== Epoch 8 step 6 train loss 0.6387385 train acc 0.664\n",
            "== Epoch 8 step 7 train loss 0.633378 train acc 0.668\n",
            "== Epoch 8 step 8 train loss 0.63765955 train acc 0.656\n",
            "== Epoch 8 step 9 train loss 0.62880063 train acc 0.7\n",
            "== Epoch 8 step 10 train loss 0.62939095 train acc 0.72\n",
            "== Epoch 8 step 11 train loss 0.6295294 train acc 0.704\n",
            "== Epoch 8 step 12 train loss 0.63165325 train acc 0.684\n",
            "== Epoch 8 step 13 train loss 0.62483424 train acc 0.7\n",
            "== Epoch 8 step 14 train loss 0.62062144 train acc 0.724\n",
            "== Epoch 8 step 15 train loss 0.6444734 train acc 0.676\n",
            "== Epoch 8 step 16 train loss 0.61890167 train acc 0.732\n",
            "== Epoch 8 step 17 train loss 0.6385287 train acc 0.664\n",
            "== Epoch 8 step 18 train loss 0.6294315 train acc 0.688\n",
            "== Epoch 8 step 19 train loss 0.63173497 train acc 0.676\n",
            "val acc 0.6511627906976745\n",
            "val loss 0.64640653\n",
            "Saving model at /tmp/tmpl4hmbw_e/torchmoji-checkpoint-ff996a33-fdc2-4d12-93c7-d89fc8e7551a.bin\n",
            "== Epoch 9 step 0 train loss 0.61992425 train acc 0.704\n",
            "== Epoch 9 step 1 train loss 0.6278754 train acc 0.692\n",
            "== Epoch 9 step 2 train loss 0.6347815 train acc 0.68\n",
            "== Epoch 9 step 3 train loss 0.62224835 train acc 0.708\n",
            "== Epoch 9 step 4 train loss 0.625808 train acc 0.724\n",
            "== Epoch 9 step 5 train loss 0.623751 train acc 0.684\n",
            "== Epoch 9 step 6 train loss 0.638357 train acc 0.664\n",
            "== Epoch 9 step 7 train loss 0.6311079 train acc 0.668\n",
            "== Epoch 9 step 8 train loss 0.6387145 train acc 0.66\n",
            "== Epoch 9 step 9 train loss 0.625567 train acc 0.704\n",
            "== Epoch 9 step 10 train loss 0.6174727 train acc 0.72\n",
            "== Epoch 9 step 11 train loss 0.6208546 train acc 0.716\n",
            "== Epoch 9 step 12 train loss 0.6359383 train acc 0.684\n",
            "== Epoch 9 step 13 train loss 0.62307286 train acc 0.704\n",
            "== Epoch 9 step 14 train loss 0.62310034 train acc 0.74\n",
            "== Epoch 9 step 15 train loss 0.6413537 train acc 0.672\n",
            "== Epoch 9 step 16 train loss 0.60469514 train acc 0.732\n",
            "== Epoch 9 step 17 train loss 0.63238096 train acc 0.668\n",
            "== Epoch 9 step 18 train loss 0.63252723 train acc 0.688\n",
            "== Epoch 9 step 19 train loss 0.6294028 train acc 0.672\n",
            "val acc 0.6511627906976745\n",
            "val loss 0.6437403\n",
            "Saving model at /tmp/tmpl4hmbw_e/torchmoji-checkpoint-ff996a33-fdc2-4d12-93c7-d89fc8e7551a.bin\n",
            "== Epoch 10 step 0 train loss 0.6174579 train acc 0.712\n",
            "== Epoch 10 step 1 train loss 0.626505 train acc 0.692\n",
            "== Epoch 10 step 2 train loss 0.6317394 train acc 0.68\n",
            "== Epoch 10 step 3 train loss 0.61248463 train acc 0.708\n",
            "== Epoch 10 step 4 train loss 0.6204386 train acc 0.744\n",
            "== Epoch 10 step 5 train loss 0.6222948 train acc 0.684\n",
            "== Epoch 10 step 6 train loss 0.634908 train acc 0.672\n",
            "== Epoch 10 step 7 train loss 0.63009334 train acc 0.676\n",
            "== Epoch 10 step 8 train loss 0.6350693 train acc 0.668\n",
            "== Epoch 10 step 9 train loss 0.6212762 train acc 0.7\n",
            "== Epoch 10 step 10 train loss 0.6169759 train acc 0.728\n",
            "== Epoch 10 step 11 train loss 0.61263925 train acc 0.72\n",
            "== Epoch 10 step 12 train loss 0.628859 train acc 0.692\n",
            "== Epoch 10 step 13 train loss 0.6221314 train acc 0.7\n",
            "== Epoch 10 step 14 train loss 0.61442995 train acc 0.74\n",
            "== Epoch 10 step 15 train loss 0.6310948 train acc 0.672\n",
            "== Epoch 10 step 16 train loss 0.6058184 train acc 0.74\n",
            "== Epoch 10 step 17 train loss 0.626765 train acc 0.672\n",
            "== Epoch 10 step 18 train loss 0.626147 train acc 0.696\n",
            "== Epoch 10 step 19 train loss 0.63003635 train acc 0.672\n",
            "val acc 0.6511627906976745\n",
            "val loss 0.6412737\n",
            "Saving model at /tmp/tmpl4hmbw_e/torchmoji-checkpoint-ff996a33-fdc2-4d12-93c7-d89fc8e7551a.bin\n",
            "== Epoch 11 step 0 train loss 0.61419225 train acc 0.72\n",
            "== Epoch 11 step 1 train loss 0.6255871 train acc 0.692\n",
            "== Epoch 11 step 2 train loss 0.630572 train acc 0.696\n",
            "== Epoch 11 step 3 train loss 0.6072705 train acc 0.708\n",
            "== Epoch 11 step 4 train loss 0.61573106 train acc 0.752\n",
            "== Epoch 11 step 5 train loss 0.61664075 train acc 0.7\n",
            "== Epoch 11 step 6 train loss 0.62413764 train acc 0.676\n",
            "== Epoch 11 step 7 train loss 0.62537855 train acc 0.688\n",
            "== Epoch 11 step 8 train loss 0.6268126 train acc 0.672\n",
            "== Epoch 11 step 9 train loss 0.6136043 train acc 0.704\n",
            "== Epoch 11 step 10 train loss 0.6092635 train acc 0.732\n",
            "== Epoch 11 step 11 train loss 0.61222863 train acc 0.72\n",
            "== Epoch 11 step 12 train loss 0.6215961 train acc 0.692\n",
            "== Epoch 11 step 13 train loss 0.61502934 train acc 0.704\n",
            "== Epoch 11 step 14 train loss 0.6098102 train acc 0.74\n",
            "== Epoch 11 step 15 train loss 0.6270466 train acc 0.676\n",
            "== Epoch 11 step 16 train loss 0.60021234 train acc 0.736\n",
            "== Epoch 11 step 17 train loss 0.6265661 train acc 0.676\n",
            "== Epoch 11 step 18 train loss 0.62180346 train acc 0.692\n",
            "== Epoch 11 step 19 train loss 0.62343454 train acc 0.672\n",
            "val acc 0.6511627906976745\n",
            "val loss 0.6392206\n",
            "Saving model at /tmp/tmpl4hmbw_e/torchmoji-checkpoint-ff996a33-fdc2-4d12-93c7-d89fc8e7551a.bin\n",
            "== Epoch 12 step 0 train loss 0.6111169 train acc 0.72\n",
            "== Epoch 12 step 1 train loss 0.6204464 train acc 0.696\n",
            "== Epoch 12 step 2 train loss 0.6298399 train acc 0.696\n",
            "== Epoch 12 step 3 train loss 0.5996209 train acc 0.708\n",
            "== Epoch 12 step 4 train loss 0.6196515 train acc 0.756\n",
            "== Epoch 12 step 5 train loss 0.60819876 train acc 0.7\n",
            "== Epoch 12 step 6 train loss 0.63080484 train acc 0.68\n",
            "== Epoch 12 step 7 train loss 0.62491864 train acc 0.688\n",
            "== Epoch 12 step 8 train loss 0.61699545 train acc 0.668\n",
            "== Epoch 12 step 9 train loss 0.59901875 train acc 0.704\n",
            "== Epoch 12 step 10 train loss 0.6133857 train acc 0.728\n",
            "== Epoch 12 step 11 train loss 0.612769 train acc 0.728\n",
            "== Epoch 12 step 12 train loss 0.62054026 train acc 0.7\n",
            "== Epoch 12 step 13 train loss 0.60956675 train acc 0.704\n",
            "== Epoch 12 step 14 train loss 0.6004801 train acc 0.74\n",
            "== Epoch 12 step 15 train loss 0.63077706 train acc 0.676\n",
            "== Epoch 12 step 16 train loss 0.59698886 train acc 0.74\n",
            "== Epoch 12 step 17 train loss 0.615625 train acc 0.684\n",
            "== Epoch 12 step 18 train loss 0.62201136 train acc 0.708\n",
            "== Epoch 12 step 19 train loss 0.6292002 train acc 0.672\n",
            "val acc 0.6569767441860465\n",
            "val loss 0.6371613\n",
            "Saving model at /tmp/tmpl4hmbw_e/torchmoji-checkpoint-ff996a33-fdc2-4d12-93c7-d89fc8e7551a.bin\n",
            "== Epoch 13 step 0 train loss 0.6078015 train acc 0.728\n",
            "== Epoch 13 step 1 train loss 0.6102764 train acc 0.7\n",
            "== Epoch 13 step 2 train loss 0.61730176 train acc 0.696\n",
            "== Epoch 13 step 3 train loss 0.59782255 train acc 0.712\n",
            "== Epoch 13 step 4 train loss 0.6065062 train acc 0.756\n",
            "== Epoch 13 step 5 train loss 0.60231173 train acc 0.708\n",
            "== Epoch 13 step 6 train loss 0.6268922 train acc 0.68\n",
            "== Epoch 13 step 7 train loss 0.62588936 train acc 0.688\n",
            "== Epoch 13 step 8 train loss 0.6302241 train acc 0.676\n",
            "== Epoch 13 step 9 train loss 0.60568076 train acc 0.708\n",
            "== Epoch 13 step 10 train loss 0.6015146 train acc 0.736\n",
            "== Epoch 13 step 11 train loss 0.6007936 train acc 0.736\n",
            "== Epoch 13 step 12 train loss 0.6121698 train acc 0.7\n",
            "== Epoch 13 step 13 train loss 0.6017004 train acc 0.708\n",
            "== Epoch 13 step 14 train loss 0.599939 train acc 0.74\n",
            "== Epoch 13 step 15 train loss 0.62281513 train acc 0.688\n",
            "== Epoch 13 step 16 train loss 0.59017503 train acc 0.736\n",
            "== Epoch 13 step 17 train loss 0.61739516 train acc 0.684\n",
            "== Epoch 13 step 18 train loss 0.6203638 train acc 0.712\n",
            "== Epoch 13 step 19 train loss 0.6134125 train acc 0.676\n",
            "val acc 0.6569767441860465\n",
            "val loss 0.6353764\n",
            "Saving model at /tmp/tmpl4hmbw_e/torchmoji-checkpoint-ff996a33-fdc2-4d12-93c7-d89fc8e7551a.bin\n",
            "== Epoch 14 step 0 train loss 0.60452574 train acc 0.732\n",
            "== Epoch 14 step 1 train loss 0.6091216 train acc 0.7\n",
            "== Epoch 14 step 2 train loss 0.61777407 train acc 0.7\n",
            "== Epoch 14 step 3 train loss 0.5953157 train acc 0.712\n",
            "== Epoch 14 step 4 train loss 0.61517596 train acc 0.756\n",
            "== Epoch 14 step 5 train loss 0.6031152 train acc 0.712\n",
            "== Epoch 14 step 6 train loss 0.61119115 train acc 0.68\n",
            "== Epoch 14 step 7 train loss 0.6174674 train acc 0.688\n",
            "== Epoch 14 step 8 train loss 0.6190614 train acc 0.672\n",
            "== Epoch 14 step 9 train loss 0.60212094 train acc 0.7\n",
            "== Epoch 14 step 10 train loss 0.596341 train acc 0.728\n",
            "== Epoch 14 step 11 train loss 0.5950317 train acc 0.732\n",
            "== Epoch 14 step 12 train loss 0.62254673 train acc 0.704\n",
            "== Epoch 14 step 13 train loss 0.6087257 train acc 0.708\n",
            "== Epoch 14 step 14 train loss 0.596766 train acc 0.744\n",
            "== Epoch 14 step 15 train loss 0.62195945 train acc 0.688\n",
            "== Epoch 14 step 16 train loss 0.5960393 train acc 0.74\n",
            "== Epoch 14 step 17 train loss 0.6121151 train acc 0.688\n",
            "== Epoch 14 step 18 train loss 0.6088289 train acc 0.72\n",
            "== Epoch 14 step 19 train loss 0.61111987 train acc 0.672\n",
            "val acc 0.6627906976744186\n",
            "val loss 0.63382107\n",
            "Saving model at /tmp/tmpl4hmbw_e/torchmoji-checkpoint-ff996a33-fdc2-4d12-93c7-d89fc8e7551a.bin\n",
            "== Epoch 15 step 0 train loss 0.59806883 train acc 0.744\n",
            "== Epoch 15 step 1 train loss 0.60794795 train acc 0.704\n",
            "== Epoch 15 step 2 train loss 0.61887294 train acc 0.7\n",
            "== Epoch 15 step 3 train loss 0.5958391 train acc 0.724\n",
            "== Epoch 15 step 4 train loss 0.6039678 train acc 0.756\n",
            "== Epoch 15 step 5 train loss 0.60625064 train acc 0.724\n",
            "== Epoch 15 step 6 train loss 0.610176 train acc 0.692\n",
            "== Epoch 15 step 7 train loss 0.5955136 train acc 0.688\n",
            "== Epoch 15 step 8 train loss 0.6180917 train acc 0.692\n",
            "== Epoch 15 step 9 train loss 0.59158397 train acc 0.712\n",
            "== Epoch 15 step 10 train loss 0.59413713 train acc 0.732\n",
            "== Epoch 15 step 11 train loss 0.59390616 train acc 0.74\n",
            "== Epoch 15 step 12 train loss 0.6070933 train acc 0.712\n",
            "== Epoch 15 step 13 train loss 0.60128784 train acc 0.708\n",
            "== Epoch 15 step 14 train loss 0.5899027 train acc 0.744\n",
            "== Epoch 15 step 15 train loss 0.61600935 train acc 0.7\n",
            "== Epoch 15 step 16 train loss 0.5863944 train acc 0.74\n",
            "== Epoch 15 step 17 train loss 0.60927135 train acc 0.688\n",
            "== Epoch 15 step 18 train loss 0.60524887 train acc 0.72\n",
            "== Epoch 15 step 19 train loss 0.6168351 train acc 0.672\n",
            "val acc 0.6686046511627907\n",
            "val loss 0.6323994\n",
            "Saving model at /tmp/tmpl4hmbw_e/torchmoji-checkpoint-ff996a33-fdc2-4d12-93c7-d89fc8e7551a.bin\n",
            "== Epoch 16 step 0 train loss 0.5941693 train acc 0.74\n",
            "== Epoch 16 step 1 train loss 0.60657823 train acc 0.696\n",
            "== Epoch 16 step 2 train loss 0.611752 train acc 0.716\n",
            "== Epoch 16 step 3 train loss 0.5763369 train acc 0.728\n",
            "== Epoch 16 step 4 train loss 0.5905858 train acc 0.756\n",
            "== Epoch 16 step 5 train loss 0.6005562 train acc 0.724\n",
            "== Epoch 16 step 6 train loss 0.620091 train acc 0.688\n",
            "== Epoch 16 step 7 train loss 0.61166453 train acc 0.688\n",
            "== Epoch 16 step 8 train loss 0.60842854 train acc 0.688\n",
            "== Epoch 16 step 9 train loss 0.5955372 train acc 0.712\n",
            "== Epoch 16 step 10 train loss 0.5877644 train acc 0.736\n",
            "== Epoch 16 step 11 train loss 0.58815676 train acc 0.744\n",
            "== Epoch 16 step 12 train loss 0.60134804 train acc 0.712\n",
            "== Epoch 16 step 13 train loss 0.5997856 train acc 0.708\n",
            "== Epoch 16 step 14 train loss 0.5959731 train acc 0.744\n",
            "== Epoch 16 step 15 train loss 0.6170226 train acc 0.704\n",
            "== Epoch 16 step 16 train loss 0.57705283 train acc 0.74\n",
            "== Epoch 16 step 17 train loss 0.6007809 train acc 0.688\n",
            "== Epoch 16 step 18 train loss 0.6098348 train acc 0.724\n",
            "== Epoch 16 step 19 train loss 0.6117411 train acc 0.672\n",
            "val acc 0.6686046511627907\n",
            "val loss 0.631187\n",
            "Saving model at /tmp/tmpl4hmbw_e/torchmoji-checkpoint-ff996a33-fdc2-4d12-93c7-d89fc8e7551a.bin\n",
            "== Epoch 17 step 0 train loss 0.58400315 train acc 0.74\n",
            "== Epoch 17 step 1 train loss 0.602824 train acc 0.708\n",
            "== Epoch 17 step 2 train loss 0.6003606 train acc 0.712\n",
            "== Epoch 17 step 3 train loss 0.5880492 train acc 0.732\n",
            "== Epoch 17 step 4 train loss 0.59956086 train acc 0.76\n",
            "== Epoch 17 step 5 train loss 0.59900403 train acc 0.728\n",
            "== Epoch 17 step 6 train loss 0.60855585 train acc 0.692\n",
            "== Epoch 17 step 7 train loss 0.6106352 train acc 0.696\n",
            "== Epoch 17 step 8 train loss 0.6121877 train acc 0.692\n",
            "== Epoch 17 step 9 train loss 0.59969735 train acc 0.712\n",
            "== Epoch 17 step 10 train loss 0.5958844 train acc 0.744\n",
            "== Epoch 17 step 11 train loss 0.5899923 train acc 0.748\n",
            "== Epoch 17 step 12 train loss 0.60026747 train acc 0.72\n",
            "== Epoch 17 step 13 train loss 0.5906517 train acc 0.712\n",
            "== Epoch 17 step 14 train loss 0.5904544 train acc 0.748\n",
            "== Epoch 17 step 15 train loss 0.6144793 train acc 0.704\n",
            "== Epoch 17 step 16 train loss 0.5804007 train acc 0.744\n",
            "== Epoch 17 step 17 train loss 0.60993165 train acc 0.692\n",
            "== Epoch 17 step 18 train loss 0.60345054 train acc 0.728\n",
            "== Epoch 17 step 19 train loss 0.6103164 train acc 0.672\n",
            "val acc 0.6686046511627907\n",
            "val loss 0.6300821\n",
            "Saving model at /tmp/tmpl4hmbw_e/torchmoji-checkpoint-ff996a33-fdc2-4d12-93c7-d89fc8e7551a.bin\n",
            "== Epoch 18 step 0 train loss 0.5884359 train acc 0.74\n",
            "== Epoch 18 step 1 train loss 0.60355014 train acc 0.7\n",
            "== Epoch 18 step 2 train loss 0.60939866 train acc 0.708\n",
            "== Epoch 18 step 3 train loss 0.5913611 train acc 0.732\n",
            "== Epoch 18 step 4 train loss 0.58915764 train acc 0.764\n",
            "== Epoch 18 step 5 train loss 0.5884934 train acc 0.732\n",
            "== Epoch 18 step 6 train loss 0.60166883 train acc 0.7\n",
            "== Epoch 18 step 7 train loss 0.60455674 train acc 0.692\n",
            "== Epoch 18 step 8 train loss 0.6169259 train acc 0.7\n",
            "== Epoch 18 step 9 train loss 0.5963324 train acc 0.708\n",
            "== Epoch 18 step 10 train loss 0.5800276 train acc 0.748\n",
            "== Epoch 18 step 11 train loss 0.5817286 train acc 0.756\n",
            "== Epoch 18 step 12 train loss 0.59500927 train acc 0.72\n",
            "== Epoch 18 step 13 train loss 0.591614 train acc 0.708\n",
            "== Epoch 18 step 14 train loss 0.5837098 train acc 0.752\n",
            "== Epoch 18 step 15 train loss 0.6151792 train acc 0.7\n",
            "== Epoch 18 step 16 train loss 0.57430667 train acc 0.748\n",
            "== Epoch 18 step 17 train loss 0.6046343 train acc 0.696\n",
            "== Epoch 18 step 18 train loss 0.5993692 train acc 0.732\n",
            "== Epoch 18 step 19 train loss 0.6008922 train acc 0.676\n",
            "val acc 0.6744186046511628\n",
            "val loss 0.6290863\n",
            "Saving model at /tmp/tmpl4hmbw_e/torchmoji-checkpoint-ff996a33-fdc2-4d12-93c7-d89fc8e7551a.bin\n",
            "== Epoch 19 step 0 train loss 0.59336865 train acc 0.748\n",
            "== Epoch 19 step 1 train loss 0.6080629 train acc 0.7\n",
            "== Epoch 19 step 2 train loss 0.59617364 train acc 0.708\n",
            "== Epoch 19 step 3 train loss 0.5728805 train acc 0.724\n",
            "== Epoch 19 step 4 train loss 0.58836144 train acc 0.764\n",
            "== Epoch 19 step 5 train loss 0.5867894 train acc 0.736\n",
            "== Epoch 19 step 6 train loss 0.59599674 train acc 0.696\n",
            "== Epoch 19 step 7 train loss 0.5945871 train acc 0.696\n",
            "== Epoch 19 step 8 train loss 0.59731996 train acc 0.704\n",
            "== Epoch 19 step 9 train loss 0.59340817 train acc 0.712\n",
            "== Epoch 19 step 10 train loss 0.58357686 train acc 0.752\n",
            "== Epoch 19 step 11 train loss 0.58313084 train acc 0.764\n",
            "== Epoch 19 step 12 train loss 0.6014967 train acc 0.716\n",
            "== Epoch 19 step 13 train loss 0.5845313 train acc 0.72\n",
            "== Epoch 19 step 14 train loss 0.57430446 train acc 0.756\n",
            "== Epoch 19 step 15 train loss 0.6018301 train acc 0.688\n",
            "== Epoch 19 step 16 train loss 0.5729572 train acc 0.744\n",
            "== Epoch 19 step 17 train loss 0.59340274 train acc 0.704\n",
            "== Epoch 19 step 18 train loss 0.5910639 train acc 0.728\n",
            "== Epoch 19 step 19 train loss 0.6016624 train acc 0.672\n",
            "val acc 0.6802325581395349\n",
            "val loss 0.6278946\n",
            "Saving model at /tmp/tmpl4hmbw_e/torchmoji-checkpoint-ff996a33-fdc2-4d12-93c7-d89fc8e7551a.bin\n",
            "== Epoch 20 step 0 train loss 0.58622754 train acc 0.744\n",
            "== Epoch 20 step 1 train loss 0.59394515 train acc 0.7\n",
            "== Epoch 20 step 2 train loss 0.60711986 train acc 0.716\n",
            "== Epoch 20 step 3 train loss 0.5690617 train acc 0.74\n",
            "== Epoch 20 step 4 train loss 0.58680516 train acc 0.768\n",
            "== Epoch 20 step 5 train loss 0.5802988 train acc 0.74\n",
            "== Epoch 20 step 6 train loss 0.6008719 train acc 0.708\n",
            "== Epoch 20 step 7 train loss 0.6082989 train acc 0.7\n",
            "== Epoch 20 step 8 train loss 0.592894 train acc 0.708\n",
            "== Epoch 20 step 9 train loss 0.5820358 train acc 0.708\n",
            "== Epoch 20 step 10 train loss 0.57175785 train acc 0.752\n",
            "== Epoch 20 step 11 train loss 0.57825 train acc 0.764\n",
            "== Epoch 20 step 12 train loss 0.6066345 train acc 0.72\n",
            "== Epoch 20 step 13 train loss 0.58435106 train acc 0.724\n",
            "== Epoch 20 step 14 train loss 0.56763756 train acc 0.756\n",
            "== Epoch 20 step 15 train loss 0.61080897 train acc 0.688\n",
            "== Epoch 20 step 16 train loss 0.5580775 train acc 0.748\n",
            "== Epoch 20 step 17 train loss 0.5977117 train acc 0.708\n",
            "== Epoch 20 step 18 train loss 0.5972037 train acc 0.74\n",
            "== Epoch 20 step 19 train loss 0.6106271 train acc 0.688\n",
            "val acc 0.6802325581395349\n",
            "val loss 0.62699145\n",
            "Saving model at /tmp/tmpl4hmbw_e/torchmoji-checkpoint-ff996a33-fdc2-4d12-93c7-d89fc8e7551a.bin\n",
            "== Epoch 21 step 0 train loss 0.5747924 train acc 0.752\n",
            "== Epoch 21 step 1 train loss 0.599469 train acc 0.7\n",
            "== Epoch 21 step 2 train loss 0.6022842 train acc 0.724\n",
            "== Epoch 21 step 3 train loss 0.56383586 train acc 0.736\n",
            "== Epoch 21 step 4 train loss 0.5764009 train acc 0.768\n",
            "== Epoch 21 step 5 train loss 0.5901749 train acc 0.74\n",
            "== Epoch 21 step 6 train loss 0.5975034 train acc 0.704\n",
            "== Epoch 21 step 7 train loss 0.5860494 train acc 0.704\n",
            "== Epoch 21 step 8 train loss 0.59280056 train acc 0.712\n",
            "== Epoch 21 step 9 train loss 0.5855172 train acc 0.708\n",
            "== Epoch 21 step 10 train loss 0.55444515 train acc 0.748\n",
            "== Epoch 21 step 11 train loss 0.5753817 train acc 0.768\n",
            "== Epoch 21 step 12 train loss 0.5948338 train acc 0.72\n",
            "== Epoch 21 step 13 train loss 0.58824956 train acc 0.728\n",
            "== Epoch 21 step 14 train loss 0.56029594 train acc 0.76\n",
            "== Epoch 21 step 15 train loss 0.5930366 train acc 0.696\n",
            "== Epoch 21 step 16 train loss 0.55771947 train acc 0.748\n",
            "== Epoch 21 step 17 train loss 0.5882958 train acc 0.716\n",
            "== Epoch 21 step 18 train loss 0.5928315 train acc 0.744\n",
            "== Epoch 21 step 19 train loss 0.6070103 train acc 0.688\n",
            "val acc 0.6802325581395349\n",
            "val loss 0.62612766\n",
            "Saving model at /tmp/tmpl4hmbw_e/torchmoji-checkpoint-ff996a33-fdc2-4d12-93c7-d89fc8e7551a.bin\n",
            "== Epoch 22 step 0 train loss 0.5779896 train acc 0.752\n",
            "== Epoch 22 step 1 train loss 0.5917109 train acc 0.704\n",
            "== Epoch 22 step 2 train loss 0.59523517 train acc 0.728\n",
            "== Epoch 22 step 3 train loss 0.55675083 train acc 0.736\n",
            "== Epoch 22 step 4 train loss 0.58211946 train acc 0.764\n",
            "== Epoch 22 step 5 train loss 0.58070004 train acc 0.744\n",
            "== Epoch 22 step 6 train loss 0.58305323 train acc 0.724\n",
            "== Epoch 22 step 7 train loss 0.5912262 train acc 0.712\n",
            "== Epoch 22 step 8 train loss 0.5941169 train acc 0.712\n",
            "== Epoch 22 step 9 train loss 0.5757545 train acc 0.72\n",
            "== Epoch 22 step 10 train loss 0.55902594 train acc 0.752\n",
            "== Epoch 22 step 11 train loss 0.5681068 train acc 0.768\n",
            "== Epoch 22 step 12 train loss 0.59219384 train acc 0.724\n",
            "== Epoch 22 step 13 train loss 0.58214885 train acc 0.732\n",
            "== Epoch 22 step 14 train loss 0.56430733 train acc 0.764\n",
            "== Epoch 22 step 15 train loss 0.5974327 train acc 0.7\n",
            "== Epoch 22 step 16 train loss 0.55646145 train acc 0.748\n",
            "== Epoch 22 step 17 train loss 0.5984458 train acc 0.72\n",
            "== Epoch 22 step 18 train loss 0.58661747 train acc 0.74\n",
            "== Epoch 22 step 19 train loss 0.599357 train acc 0.684\n",
            "val acc 0.6744186046511628\n",
            "val loss 0.62518764\n",
            "Saving model at /tmp/tmpl4hmbw_e/torchmoji-checkpoint-ff996a33-fdc2-4d12-93c7-d89fc8e7551a.bin\n",
            "== Epoch 23 step 0 train loss 0.57817584 train acc 0.752\n",
            "== Epoch 23 step 1 train loss 0.58538926 train acc 0.704\n",
            "== Epoch 23 step 2 train loss 0.587735 train acc 0.728\n",
            "== Epoch 23 step 3 train loss 0.5816702 train acc 0.74\n",
            "== Epoch 23 step 4 train loss 0.5763087 train acc 0.764\n",
            "== Epoch 23 step 5 train loss 0.57233673 train acc 0.74\n",
            "== Epoch 23 step 6 train loss 0.58675855 train acc 0.728\n",
            "== Epoch 23 step 7 train loss 0.59160614 train acc 0.712\n",
            "== Epoch 23 step 8 train loss 0.600139 train acc 0.708\n",
            "== Epoch 23 step 9 train loss 0.57537353 train acc 0.724\n",
            "== Epoch 23 step 10 train loss 0.5531082 train acc 0.76\n",
            "== Epoch 23 step 11 train loss 0.57052535 train acc 0.772\n",
            "== Epoch 23 step 12 train loss 0.5848488 train acc 0.72\n",
            "== Epoch 23 step 13 train loss 0.5800707 train acc 0.732\n",
            "== Epoch 23 step 14 train loss 0.552786 train acc 0.768\n",
            "== Epoch 23 step 15 train loss 0.5980748 train acc 0.696\n",
            "== Epoch 23 step 16 train loss 0.553604 train acc 0.74\n",
            "== Epoch 23 step 17 train loss 0.59190196 train acc 0.72\n",
            "== Epoch 23 step 18 train loss 0.591717 train acc 0.752\n",
            "== Epoch 23 step 19 train loss 0.5952949 train acc 0.684\n",
            "val acc 0.6744186046511628\n",
            "val loss 0.62449205\n",
            "Saving model at /tmp/tmpl4hmbw_e/torchmoji-checkpoint-ff996a33-fdc2-4d12-93c7-d89fc8e7551a.bin\n",
            "== Epoch 24 step 0 train loss 0.56546026 train acc 0.752\n",
            "== Epoch 24 step 1 train loss 0.5903668 train acc 0.704\n",
            "== Epoch 24 step 2 train loss 0.588772 train acc 0.732\n",
            "== Epoch 24 step 3 train loss 0.5692043 train acc 0.736\n",
            "== Epoch 24 step 4 train loss 0.5826818 train acc 0.768\n",
            "== Epoch 24 step 5 train loss 0.5782529 train acc 0.744\n",
            "== Epoch 24 step 6 train loss 0.60354066 train acc 0.732\n",
            "== Epoch 24 step 7 train loss 0.5796937 train acc 0.712\n",
            "== Epoch 24 step 8 train loss 0.58899224 train acc 0.708\n",
            "== Epoch 24 step 9 train loss 0.5877376 train acc 0.724\n",
            "== Epoch 24 step 10 train loss 0.56014025 train acc 0.756\n",
            "== Epoch 24 step 11 train loss 0.57074136 train acc 0.776\n",
            "== Epoch 24 step 12 train loss 0.58639807 train acc 0.728\n",
            "== Epoch 24 step 13 train loss 0.58158344 train acc 0.732\n",
            "== Epoch 24 step 14 train loss 0.55447143 train acc 0.776\n",
            "== Epoch 24 step 15 train loss 0.58730865 train acc 0.696\n",
            "== Epoch 24 step 16 train loss 0.54587346 train acc 0.752\n",
            "== Epoch 24 step 17 train loss 0.5856757 train acc 0.724\n",
            "== Epoch 24 step 18 train loss 0.57462144 train acc 0.752\n",
            "== Epoch 24 step 19 train loss 0.5836343 train acc 0.684\n",
            "val acc 0.6744186046511628\n",
            "val loss 0.62407196\n",
            "Saving model at /tmp/tmpl4hmbw_e/torchmoji-checkpoint-ff996a33-fdc2-4d12-93c7-d89fc8e7551a.bin\n",
            "== Epoch 25 step 0 train loss 0.55277085 train acc 0.752\n",
            "== Epoch 25 step 1 train loss 0.5909516 train acc 0.7\n",
            "== Epoch 25 step 2 train loss 0.58887416 train acc 0.732\n",
            "== Epoch 25 step 3 train loss 0.5619237 train acc 0.74\n",
            "== Epoch 25 step 4 train loss 0.56908756 train acc 0.768\n",
            "== Epoch 25 step 5 train loss 0.5653774 train acc 0.748\n",
            "== Epoch 25 step 6 train loss 0.58948374 train acc 0.732\n",
            "== Epoch 25 step 7 train loss 0.5769856 train acc 0.708\n",
            "== Epoch 25 step 8 train loss 0.59566885 train acc 0.716\n",
            "== Epoch 25 step 9 train loss 0.57455605 train acc 0.72\n",
            "== Epoch 25 step 10 train loss 0.5631402 train acc 0.756\n",
            "== Epoch 25 step 11 train loss 0.5551283 train acc 0.772\n",
            "== Epoch 25 step 12 train loss 0.59558934 train acc 0.736\n",
            "== Epoch 25 step 13 train loss 0.5716512 train acc 0.732\n",
            "== Epoch 25 step 14 train loss 0.56167585 train acc 0.776\n",
            "== Epoch 25 step 15 train loss 0.6094112 train acc 0.696\n",
            "== Epoch 25 step 16 train loss 0.549996 train acc 0.752\n",
            "== Epoch 25 step 17 train loss 0.5912619 train acc 0.724\n",
            "== Epoch 25 step 18 train loss 0.5774818 train acc 0.756\n",
            "== Epoch 25 step 19 train loss 0.5950916 train acc 0.688\n",
            "val acc 0.6686046511627907\n",
            "val loss 0.6235272\n",
            "Saving model at /tmp/tmpl4hmbw_e/torchmoji-checkpoint-ff996a33-fdc2-4d12-93c7-d89fc8e7551a.bin\n",
            "== Epoch 26 step 0 train loss 0.5615496 train acc 0.752\n",
            "== Epoch 26 step 1 train loss 0.5822888 train acc 0.712\n",
            "== Epoch 26 step 2 train loss 0.57117903 train acc 0.748\n",
            "== Epoch 26 step 3 train loss 0.56360066 train acc 0.744\n",
            "== Epoch 26 step 4 train loss 0.57885677 train acc 0.764\n",
            "== Epoch 26 step 5 train loss 0.57196385 train acc 0.744\n",
            "== Epoch 26 step 6 train loss 0.60148 train acc 0.732\n",
            "== Epoch 26 step 7 train loss 0.59311366 train acc 0.712\n",
            "== Epoch 26 step 8 train loss 0.5773961 train acc 0.712\n",
            "== Epoch 26 step 9 train loss 0.57123595 train acc 0.724\n",
            "== Epoch 26 step 10 train loss 0.5610083 train acc 0.76\n",
            "== Epoch 26 step 11 train loss 0.57122195 train acc 0.772\n",
            "== Epoch 26 step 12 train loss 0.578056 train acc 0.736\n",
            "== Epoch 26 step 13 train loss 0.5676596 train acc 0.732\n",
            "== Epoch 26 step 14 train loss 0.5594613 train acc 0.776\n",
            "== Epoch 26 step 15 train loss 0.5863076 train acc 0.696\n",
            "== Epoch 26 step 16 train loss 0.54462147 train acc 0.744\n",
            "== Epoch 26 step 17 train loss 0.5823143 train acc 0.724\n",
            "== Epoch 26 step 18 train loss 0.5810176 train acc 0.756\n",
            "== Epoch 26 step 19 train loss 0.6007803 train acc 0.688\n",
            "val acc 0.6686046511627907\n",
            "val loss 0.6229016\n",
            "Saving model at /tmp/tmpl4hmbw_e/torchmoji-checkpoint-ff996a33-fdc2-4d12-93c7-d89fc8e7551a.bin\n",
            "== Epoch 27 step 0 train loss 0.5706147 train acc 0.752\n",
            "== Epoch 27 step 1 train loss 0.59090924 train acc 0.716\n",
            "== Epoch 27 step 2 train loss 0.5890198 train acc 0.748\n",
            "== Epoch 27 step 3 train loss 0.55122405 train acc 0.748\n",
            "== Epoch 27 step 4 train loss 0.5716931 train acc 0.768\n",
            "== Epoch 27 step 5 train loss 0.5630307 train acc 0.752\n",
            "== Epoch 27 step 6 train loss 0.589933 train acc 0.732\n",
            "== Epoch 27 step 7 train loss 0.58486444 train acc 0.712\n",
            "== Epoch 27 step 8 train loss 0.5757521 train acc 0.712\n",
            "== Epoch 27 step 9 train loss 0.58690023 train acc 0.724\n",
            "== Epoch 27 step 10 train loss 0.5662021 train acc 0.76\n",
            "== Epoch 27 step 11 train loss 0.55172515 train acc 0.772\n",
            "== Epoch 27 step 12 train loss 0.5811403 train acc 0.74\n",
            "== Epoch 27 step 13 train loss 0.5691293 train acc 0.732\n",
            "== Epoch 27 step 14 train loss 0.5547566 train acc 0.78\n",
            "== Epoch 27 step 15 train loss 0.5801411 train acc 0.7\n",
            "== Epoch 27 step 16 train loss 0.5505305 train acc 0.744\n",
            "== Epoch 27 step 17 train loss 0.5904257 train acc 0.724\n",
            "== Epoch 27 step 18 train loss 0.5623402 train acc 0.76\n",
            "== Epoch 27 step 19 train loss 0.5987747 train acc 0.692\n",
            "val acc 0.6686046511627907\n",
            "val loss 0.62236255\n",
            "Saving model at /tmp/tmpl4hmbw_e/torchmoji-checkpoint-ff996a33-fdc2-4d12-93c7-d89fc8e7551a.bin\n",
            "== Epoch 28 step 0 train loss 0.5657603 train acc 0.76\n",
            "== Epoch 28 step 1 train loss 0.5904237 train acc 0.716\n",
            "== Epoch 28 step 2 train loss 0.57755727 train acc 0.748\n",
            "== Epoch 28 step 3 train loss 0.55277747 train acc 0.752\n",
            "== Epoch 28 step 4 train loss 0.5730714 train acc 0.772\n",
            "== Epoch 28 step 5 train loss 0.5686779 train acc 0.748\n",
            "== Epoch 28 step 6 train loss 0.5841948 train acc 0.732\n",
            "== Epoch 28 step 7 train loss 0.5851845 train acc 0.712\n",
            "== Epoch 28 step 8 train loss 0.58102137 train acc 0.712\n",
            "== Epoch 28 step 9 train loss 0.5832134 train acc 0.728\n",
            "== Epoch 28 step 10 train loss 0.5476001 train acc 0.764\n",
            "== Epoch 28 step 11 train loss 0.5467576 train acc 0.768\n",
            "== Epoch 28 step 12 train loss 0.58234555 train acc 0.74\n",
            "== Epoch 28 step 13 train loss 0.56950325 train acc 0.736\n",
            "== Epoch 28 step 14 train loss 0.5499275 train acc 0.78\n",
            "== Epoch 28 step 15 train loss 0.57407695 train acc 0.712\n",
            "== Epoch 28 step 16 train loss 0.55440134 train acc 0.748\n",
            "== Epoch 28 step 17 train loss 0.58457536 train acc 0.728\n",
            "== Epoch 28 step 18 train loss 0.5571316 train acc 0.76\n",
            "== Epoch 28 step 19 train loss 0.5883421 train acc 0.696\n",
            "val acc 0.6686046511627907\n",
            "val loss 0.62183404\n",
            "Saving model at /tmp/tmpl4hmbw_e/torchmoji-checkpoint-ff996a33-fdc2-4d12-93c7-d89fc8e7551a.bin\n",
            "== Epoch 29 step 0 train loss 0.5761886 train acc 0.764\n",
            "== Epoch 29 step 1 train loss 0.57420444 train acc 0.712\n",
            "== Epoch 29 step 2 train loss 0.5914664 train acc 0.748\n",
            "== Epoch 29 step 3 train loss 0.553571 train acc 0.76\n",
            "== Epoch 29 step 4 train loss 0.5612678 train acc 0.772\n",
            "== Epoch 29 step 5 train loss 0.5522196 train acc 0.752\n",
            "== Epoch 29 step 6 train loss 0.58698666 train acc 0.732\n",
            "== Epoch 29 step 7 train loss 0.57555187 train acc 0.72\n",
            "== Epoch 29 step 8 train loss 0.57004255 train acc 0.72\n",
            "== Epoch 29 step 9 train loss 0.56714815 train acc 0.732\n",
            "== Epoch 29 step 10 train loss 0.5435019 train acc 0.772\n",
            "== Epoch 29 step 11 train loss 0.5458435 train acc 0.768\n",
            "== Epoch 29 step 12 train loss 0.5737151 train acc 0.74\n",
            "== Epoch 29 step 13 train loss 0.56186545 train acc 0.74\n",
            "== Epoch 29 step 14 train loss 0.5552772 train acc 0.78\n",
            "== Epoch 29 step 15 train loss 0.5820576 train acc 0.712\n",
            "== Epoch 29 step 16 train loss 0.5397786 train acc 0.744\n",
            "== Epoch 29 step 17 train loss 0.566166 train acc 0.724\n",
            "== Epoch 29 step 18 train loss 0.5798699 train acc 0.76\n",
            "== Epoch 29 step 19 train loss 0.5845221 train acc 0.688\n",
            "val acc 0.6744186046511628\n",
            "val loss 0.6212817\n",
            "Saving model at /tmp/tmpl4hmbw_e/torchmoji-checkpoint-ff996a33-fdc2-4d12-93c7-d89fc8e7551a.bin\n",
            "== Epoch 30 step 0 train loss 0.55429566 train acc 0.772\n",
            "== Epoch 30 step 1 train loss 0.5752474 train acc 0.708\n",
            "== Epoch 30 step 2 train loss 0.59648854 train acc 0.748\n",
            "== Epoch 30 step 3 train loss 0.5499778 train acc 0.76\n",
            "== Epoch 30 step 4 train loss 0.5742496 train acc 0.772\n",
            "== Epoch 30 step 5 train loss 0.5624 train acc 0.752\n",
            "== Epoch 30 step 6 train loss 0.58207005 train acc 0.74\n",
            "== Epoch 30 step 7 train loss 0.5829681 train acc 0.72\n",
            "== Epoch 30 step 8 train loss 0.5712045 train acc 0.72\n",
            "== Epoch 30 step 9 train loss 0.573607 train acc 0.736\n",
            "== Epoch 30 step 10 train loss 0.5430785 train acc 0.772\n",
            "== Epoch 30 step 11 train loss 0.55188745 train acc 0.768\n",
            "== Epoch 30 step 12 train loss 0.5864386 train acc 0.736\n",
            "== Epoch 30 step 13 train loss 0.5614411 train acc 0.74\n",
            "== Epoch 30 step 14 train loss 0.5446909 train acc 0.788\n",
            "== Epoch 30 step 15 train loss 0.5686792 train acc 0.716\n",
            "== Epoch 30 step 16 train loss 0.5268196 train acc 0.744\n",
            "== Epoch 30 step 17 train loss 0.5688356 train acc 0.724\n",
            "== Epoch 30 step 18 train loss 0.57722926 train acc 0.76\n",
            "== Epoch 30 step 19 train loss 0.5893691 train acc 0.688\n",
            "val acc 0.6744186046511628\n",
            "val loss 0.6207955\n",
            "Saving model at /tmp/tmpl4hmbw_e/torchmoji-checkpoint-ff996a33-fdc2-4d12-93c7-d89fc8e7551a.bin\n",
            "== Epoch 31 step 0 train loss 0.5534144 train acc 0.772\n",
            "== Epoch 31 step 1 train loss 0.5687206 train acc 0.708\n",
            "== Epoch 31 step 2 train loss 0.5810708 train acc 0.748\n",
            "== Epoch 31 step 3 train loss 0.55415887 train acc 0.76\n",
            "== Epoch 31 step 4 train loss 0.55346924 train acc 0.772\n",
            "== Epoch 31 step 5 train loss 0.55094504 train acc 0.748\n",
            "== Epoch 31 step 6 train loss 0.5729766 train acc 0.736\n",
            "== Epoch 31 step 7 train loss 0.57595503 train acc 0.708\n",
            "== Epoch 31 step 8 train loss 0.57705736 train acc 0.72\n",
            "== Epoch 31 step 9 train loss 0.5553331 train acc 0.732\n",
            "== Epoch 31 step 10 train loss 0.5464975 train acc 0.768\n",
            "== Epoch 31 step 11 train loss 0.5558579 train acc 0.768\n",
            "== Epoch 31 step 12 train loss 0.57622486 train acc 0.736\n",
            "== Epoch 31 step 13 train loss 0.57010627 train acc 0.74\n",
            "== Epoch 31 step 14 train loss 0.55050164 train acc 0.788\n",
            "== Epoch 31 step 15 train loss 0.58484906 train acc 0.716\n",
            "== Epoch 31 step 16 train loss 0.53018 train acc 0.752\n",
            "== Epoch 31 step 17 train loss 0.5754464 train acc 0.724\n",
            "== Epoch 31 step 18 train loss 0.57443136 train acc 0.76\n",
            "== Epoch 31 step 19 train loss 0.58448803 train acc 0.688\n",
            "val acc 0.6686046511627907\n",
            "val loss 0.6203989\n",
            "Saving model at /tmp/tmpl4hmbw_e/torchmoji-checkpoint-ff996a33-fdc2-4d12-93c7-d89fc8e7551a.bin\n",
            "== Epoch 32 step 0 train loss 0.5555318 train acc 0.772\n",
            "== Epoch 32 step 1 train loss 0.5671814 train acc 0.708\n",
            "== Epoch 32 step 2 train loss 0.56600654 train acc 0.744\n",
            "== Epoch 32 step 3 train loss 0.5304565 train acc 0.76\n",
            "== Epoch 32 step 4 train loss 0.57452613 train acc 0.772\n",
            "== Epoch 32 step 5 train loss 0.5422034 train acc 0.752\n",
            "== Epoch 32 step 6 train loss 0.5707308 train acc 0.736\n",
            "== Epoch 32 step 7 train loss 0.57702297 train acc 0.716\n",
            "== Epoch 32 step 8 train loss 0.58430743 train acc 0.724\n",
            "== Epoch 32 step 9 train loss 0.5670686 train acc 0.736\n",
            "== Epoch 32 step 10 train loss 0.52422243 train acc 0.768\n",
            "== Epoch 32 step 11 train loss 0.5513523 train acc 0.776\n",
            "== Epoch 32 step 12 train loss 0.5888391 train acc 0.74\n",
            "== Epoch 32 step 13 train loss 0.56229913 train acc 0.744\n",
            "== Epoch 32 step 14 train loss 0.5317396 train acc 0.792\n",
            "== Epoch 32 step 15 train loss 0.58006394 train acc 0.716\n",
            "== Epoch 32 step 16 train loss 0.54048496 train acc 0.752\n",
            "== Epoch 32 step 17 train loss 0.5621046 train acc 0.724\n",
            "== Epoch 32 step 18 train loss 0.5638444 train acc 0.76\n",
            "== Epoch 32 step 19 train loss 0.5934126 train acc 0.688\n",
            "val acc 0.6686046511627907\n",
            "val loss 0.6201308\n",
            "Saving model at /tmp/tmpl4hmbw_e/torchmoji-checkpoint-ff996a33-fdc2-4d12-93c7-d89fc8e7551a.bin\n",
            "== Epoch 33 step 0 train loss 0.5554557 train acc 0.772\n",
            "== Epoch 33 step 1 train loss 0.5741482 train acc 0.708\n",
            "== Epoch 33 step 2 train loss 0.5628467 train acc 0.76\n",
            "== Epoch 33 step 3 train loss 0.54658306 train acc 0.76\n",
            "== Epoch 33 step 4 train loss 0.5610603 train acc 0.776\n",
            "== Epoch 33 step 5 train loss 0.5563268 train acc 0.756\n",
            "== Epoch 33 step 6 train loss 0.5719525 train acc 0.736\n",
            "== Epoch 33 step 7 train loss 0.57622194 train acc 0.72\n",
            "== Epoch 33 step 8 train loss 0.56466645 train acc 0.728\n",
            "== Epoch 33 step 9 train loss 0.55834746 train acc 0.736\n",
            "== Epoch 33 step 10 train loss 0.54255974 train acc 0.772\n",
            "== Epoch 33 step 11 train loss 0.5502863 train acc 0.78\n",
            "== Epoch 33 step 12 train loss 0.57503396 train acc 0.74\n",
            "== Epoch 33 step 13 train loss 0.55101717 train acc 0.744\n",
            "== Epoch 33 step 14 train loss 0.54863995 train acc 0.8\n",
            "== Epoch 33 step 15 train loss 0.5716774 train acc 0.716\n",
            "== Epoch 33 step 16 train loss 0.5376687 train acc 0.752\n",
            "== Epoch 33 step 17 train loss 0.56644285 train acc 0.724\n",
            "== Epoch 33 step 18 train loss 0.57232064 train acc 0.756\n",
            "== Epoch 33 step 19 train loss 0.57928836 train acc 0.684\n",
            "val acc 0.6686046511627907\n",
            "val loss 0.61985147\n",
            "Saving model at /tmp/tmpl4hmbw_e/torchmoji-checkpoint-ff996a33-fdc2-4d12-93c7-d89fc8e7551a.bin\n",
            "== Epoch 34 step 0 train loss 0.5581394 train acc 0.772\n",
            "== Epoch 34 step 1 train loss 0.56680226 train acc 0.704\n",
            "== Epoch 34 step 2 train loss 0.56603634 train acc 0.752\n",
            "== Epoch 34 step 3 train loss 0.5515241 train acc 0.76\n",
            "== Epoch 34 step 4 train loss 0.5509921 train acc 0.772\n",
            "== Epoch 34 step 5 train loss 0.5443219 train acc 0.744\n",
            "== Epoch 34 step 6 train loss 0.5716404 train acc 0.744\n",
            "== Epoch 34 step 7 train loss 0.5696369 train acc 0.716\n",
            "== Epoch 34 step 8 train loss 0.57379913 train acc 0.732\n",
            "== Epoch 34 step 9 train loss 0.5685264 train acc 0.736\n",
            "== Epoch 34 step 10 train loss 0.55213 train acc 0.776\n",
            "== Epoch 34 step 11 train loss 0.5566369 train acc 0.78\n",
            "== Epoch 34 step 12 train loss 0.5704038 train acc 0.736\n",
            "== Epoch 34 step 13 train loss 0.5643784 train acc 0.74\n",
            "== Epoch 34 step 14 train loss 0.53701806 train acc 0.8\n",
            "== Epoch 34 step 15 train loss 0.5806164 train acc 0.716\n",
            "== Epoch 34 step 16 train loss 0.53442955 train acc 0.76\n",
            "== Epoch 34 step 17 train loss 0.5584853 train acc 0.724\n",
            "== Epoch 34 step 18 train loss 0.55622166 train acc 0.756\n",
            "== Epoch 34 step 19 train loss 0.5808166 train acc 0.696\n",
            "val acc 0.6627906976744186\n",
            "val loss 0.6196648\n",
            "Saving model at /tmp/tmpl4hmbw_e/torchmoji-checkpoint-ff996a33-fdc2-4d12-93c7-d89fc8e7551a.bin\n",
            "== Epoch 35 step 0 train loss 0.5559696 train acc 0.768\n",
            "== Epoch 35 step 1 train loss 0.5774636 train acc 0.708\n",
            "== Epoch 35 step 2 train loss 0.5609117 train acc 0.748\n",
            "== Epoch 35 step 3 train loss 0.5470797 train acc 0.764\n",
            "== Epoch 35 step 4 train loss 0.5606304 train acc 0.776\n",
            "== Epoch 35 step 5 train loss 0.5343912 train acc 0.748\n",
            "== Epoch 35 step 6 train loss 0.57173854 train acc 0.74\n",
            "== Epoch 35 step 7 train loss 0.55849224 train acc 0.716\n",
            "== Epoch 35 step 8 train loss 0.56827384 train acc 0.728\n",
            "== Epoch 35 step 9 train loss 0.553386 train acc 0.732\n",
            "== Epoch 35 step 10 train loss 0.53736806 train acc 0.772\n",
            "== Epoch 35 step 11 train loss 0.5397134 train acc 0.78\n",
            "== Epoch 35 step 12 train loss 0.5671782 train acc 0.74\n",
            "== Epoch 35 step 13 train loss 0.55849636 train acc 0.74\n",
            "== Epoch 35 step 14 train loss 0.52583796 train acc 0.8\n",
            "== Epoch 35 step 15 train loss 0.58144873 train acc 0.716\n",
            "== Epoch 35 step 16 train loss 0.53605705 train acc 0.752\n",
            "== Epoch 35 step 17 train loss 0.5671795 train acc 0.728\n",
            "== Epoch 35 step 18 train loss 0.55269104 train acc 0.756\n",
            "== Epoch 35 step 19 train loss 0.5697315 train acc 0.688\n",
            "val acc 0.6686046511627907\n",
            "val loss 0.6195286\n",
            "Saving model at /tmp/tmpl4hmbw_e/torchmoji-checkpoint-ff996a33-fdc2-4d12-93c7-d89fc8e7551a.bin\n",
            "== Epoch 36 step 0 train loss 0.54998475 train acc 0.776\n",
            "== Epoch 36 step 1 train loss 0.56643534 train acc 0.708\n",
            "== Epoch 36 step 2 train loss 0.57596064 train acc 0.76\n",
            "== Epoch 36 step 3 train loss 0.5367616 train acc 0.76\n",
            "== Epoch 36 step 4 train loss 0.54964185 train acc 0.776\n",
            "== Epoch 36 step 5 train loss 0.5384815 train acc 0.748\n",
            "== Epoch 36 step 6 train loss 0.57339674 train acc 0.74\n",
            "== Epoch 36 step 7 train loss 0.55242443 train acc 0.716\n",
            "== Epoch 36 step 8 train loss 0.5739572 train acc 0.728\n",
            "== Epoch 36 step 9 train loss 0.5533264 train acc 0.736\n",
            "== Epoch 36 step 10 train loss 0.52182466 train acc 0.772\n",
            "== Epoch 36 step 11 train loss 0.5378363 train acc 0.784\n",
            "== Epoch 36 step 12 train loss 0.57302886 train acc 0.74\n",
            "== Epoch 36 step 13 train loss 0.55683976 train acc 0.736\n",
            "== Epoch 36 step 14 train loss 0.5298689 train acc 0.8\n",
            "== Epoch 36 step 15 train loss 0.58612967 train acc 0.716\n",
            "== Epoch 36 step 16 train loss 0.5337783 train acc 0.76\n",
            "== Epoch 36 step 17 train loss 0.5664961 train acc 0.736\n",
            "== Epoch 36 step 18 train loss 0.5589977 train acc 0.756\n",
            "== Epoch 36 step 19 train loss 0.5667057 train acc 0.696\n",
            "val acc 0.6686046511627907\n",
            "val loss 0.61955374\n",
            "No improvement over previous best loss:  0.6195286\n",
            "== Epoch 37 step 0 train loss 0.54135567 train acc 0.776\n",
            "== Epoch 37 step 1 train loss 0.5676737 train acc 0.712\n",
            "== Epoch 37 step 2 train loss 0.56170046 train acc 0.768\n",
            "== Epoch 37 step 3 train loss 0.52867484 train acc 0.768\n",
            "== Epoch 37 step 4 train loss 0.54065204 train acc 0.784\n",
            "== Epoch 37 step 5 train loss 0.5340153 train acc 0.752\n",
            "== Epoch 37 step 6 train loss 0.5747444 train acc 0.744\n",
            "== Epoch 37 step 7 train loss 0.5727545 train acc 0.724\n",
            "== Epoch 37 step 8 train loss 0.5520157 train acc 0.728\n",
            "== Epoch 37 step 9 train loss 0.5514738 train acc 0.736\n",
            "== Epoch 37 step 10 train loss 0.53699213 train acc 0.772\n",
            "== Epoch 37 step 11 train loss 0.54917234 train acc 0.784\n",
            "== Epoch 37 step 12 train loss 0.5508693 train acc 0.736\n",
            "== Epoch 37 step 13 train loss 0.5441585 train acc 0.74\n",
            "== Epoch 37 step 14 train loss 0.5405792 train acc 0.8\n",
            "== Epoch 37 step 15 train loss 0.5740125 train acc 0.724\n",
            "== Epoch 37 step 16 train loss 0.51332265 train acc 0.76\n",
            "== Epoch 37 step 17 train loss 0.576457 train acc 0.732\n",
            "== Epoch 37 step 18 train loss 0.5595306 train acc 0.764\n",
            "== Epoch 37 step 19 train loss 0.5698615 train acc 0.7\n",
            "val acc 0.6744186046511628\n",
            "val loss 0.6192975\n",
            "Saving model at /tmp/tmpl4hmbw_e/torchmoji-checkpoint-ff996a33-fdc2-4d12-93c7-d89fc8e7551a.bin\n",
            "== Epoch 38 step 0 train loss 0.55063283 train acc 0.78\n",
            "== Epoch 38 step 1 train loss 0.5702335 train acc 0.708\n",
            "== Epoch 38 step 2 train loss 0.57381284 train acc 0.764\n",
            "== Epoch 38 step 3 train loss 0.5286403 train acc 0.768\n",
            "== Epoch 38 step 4 train loss 0.5467508 train acc 0.788\n",
            "== Epoch 38 step 5 train loss 0.5531734 train acc 0.748\n",
            "== Epoch 38 step 6 train loss 0.5652379 train acc 0.744\n",
            "== Epoch 38 step 7 train loss 0.5709226 train acc 0.724\n",
            "== Epoch 38 step 8 train loss 0.5531343 train acc 0.728\n",
            "== Epoch 38 step 9 train loss 0.55019754 train acc 0.74\n",
            "== Epoch 38 step 10 train loss 0.5323027 train acc 0.776\n",
            "== Epoch 38 step 11 train loss 0.5411413 train acc 0.784\n",
            "== Epoch 38 step 12 train loss 0.5607559 train acc 0.732\n",
            "== Epoch 38 step 13 train loss 0.53855425 train acc 0.74\n",
            "== Epoch 38 step 14 train loss 0.52620506 train acc 0.804\n",
            "== Epoch 38 step 15 train loss 0.5597102 train acc 0.736\n",
            "== Epoch 38 step 16 train loss 0.52234226 train acc 0.764\n",
            "== Epoch 38 step 17 train loss 0.5700982 train acc 0.732\n",
            "== Epoch 38 step 18 train loss 0.5591039 train acc 0.764\n",
            "== Epoch 38 step 19 train loss 0.5892227 train acc 0.7\n",
            "val acc 0.6744186046511628\n",
            "val loss 0.6192299\n",
            "Saving model at /tmp/tmpl4hmbw_e/torchmoji-checkpoint-ff996a33-fdc2-4d12-93c7-d89fc8e7551a.bin\n",
            "== Epoch 39 step 0 train loss 0.56320643 train acc 0.784\n",
            "== Epoch 39 step 1 train loss 0.5621202 train acc 0.712\n",
            "== Epoch 39 step 2 train loss 0.5588881 train acc 0.764\n",
            "== Epoch 39 step 3 train loss 0.54781973 train acc 0.768\n",
            "== Epoch 39 step 4 train loss 0.5527712 train acc 0.788\n",
            "== Epoch 39 step 5 train loss 0.5569227 train acc 0.748\n",
            "== Epoch 39 step 6 train loss 0.5515482 train acc 0.744\n",
            "== Epoch 39 step 7 train loss 0.5442109 train acc 0.72\n",
            "== Epoch 39 step 8 train loss 0.56465966 train acc 0.74\n",
            "== Epoch 39 step 9 train loss 0.55521303 train acc 0.744\n",
            "== Epoch 39 step 10 train loss 0.5502081 train acc 0.776\n",
            "== Epoch 39 step 11 train loss 0.5298095 train acc 0.784\n",
            "== Epoch 39 step 12 train loss 0.57316154 train acc 0.74\n",
            "== Epoch 39 step 13 train loss 0.5381472 train acc 0.74\n",
            "== Epoch 39 step 14 train loss 0.52506304 train acc 0.804\n",
            "== Epoch 39 step 15 train loss 0.5701364 train acc 0.736\n",
            "== Epoch 39 step 16 train loss 0.5286644 train acc 0.76\n",
            "== Epoch 39 step 17 train loss 0.5681239 train acc 0.736\n",
            "== Epoch 39 step 18 train loss 0.56357944 train acc 0.76\n",
            "== Epoch 39 step 19 train loss 0.57565147 train acc 0.696\n",
            "val acc 0.6627906976744186\n",
            "val loss 0.6189988\n",
            "Saving model at /tmp/tmpl4hmbw_e/torchmoji-checkpoint-ff996a33-fdc2-4d12-93c7-d89fc8e7551a.bin\n",
            "== Epoch 40 step 0 train loss 0.54301566 train acc 0.78\n",
            "== Epoch 40 step 1 train loss 0.57499427 train acc 0.712\n",
            "== Epoch 40 step 2 train loss 0.5673566 train acc 0.764\n",
            "== Epoch 40 step 3 train loss 0.5326782 train acc 0.776\n",
            "== Epoch 40 step 4 train loss 0.5502463 train acc 0.784\n",
            "== Epoch 40 step 5 train loss 0.5421813 train acc 0.756\n",
            "== Epoch 40 step 6 train loss 0.5533458 train acc 0.744\n",
            "== Epoch 40 step 7 train loss 0.5567432 train acc 0.724\n",
            "== Epoch 40 step 8 train loss 0.55544114 train acc 0.744\n",
            "== Epoch 40 step 9 train loss 0.5603507 train acc 0.744\n",
            "== Epoch 40 step 10 train loss 0.5119381 train acc 0.776\n",
            "== Epoch 40 step 11 train loss 0.54695314 train acc 0.784\n",
            "== Epoch 40 step 12 train loss 0.5653772 train acc 0.74\n",
            "== Epoch 40 step 13 train loss 0.53669804 train acc 0.74\n",
            "== Epoch 40 step 14 train loss 0.51944923 train acc 0.812\n",
            "== Epoch 40 step 15 train loss 0.55002457 train acc 0.736\n",
            "== Epoch 40 step 16 train loss 0.52242565 train acc 0.764\n",
            "== Epoch 40 step 17 train loss 0.5480278 train acc 0.74\n",
            "== Epoch 40 step 18 train loss 0.578833 train acc 0.772\n",
            "== Epoch 40 step 19 train loss 0.56798863 train acc 0.7\n",
            "val acc 0.6744186046511628\n",
            "val loss 0.6188808\n",
            "Saving model at /tmp/tmpl4hmbw_e/torchmoji-checkpoint-ff996a33-fdc2-4d12-93c7-d89fc8e7551a.bin\n",
            "== Epoch 41 step 0 train loss 0.54078 train acc 0.78\n",
            "== Epoch 41 step 1 train loss 0.5575087 train acc 0.712\n",
            "== Epoch 41 step 2 train loss 0.5702094 train acc 0.764\n",
            "== Epoch 41 step 3 train loss 0.52284884 train acc 0.78\n",
            "== Epoch 41 step 4 train loss 0.54258734 train acc 0.792\n",
            "== Epoch 41 step 5 train loss 0.526417 train acc 0.756\n",
            "== Epoch 41 step 6 train loss 0.5609236 train acc 0.744\n",
            "== Epoch 41 step 7 train loss 0.54753166 train acc 0.724\n",
            "== Epoch 41 step 8 train loss 0.57326186 train acc 0.744\n",
            "== Epoch 41 step 9 train loss 0.5385812 train acc 0.744\n",
            "== Epoch 41 step 10 train loss 0.52175885 train acc 0.776\n",
            "== Epoch 41 step 11 train loss 0.53847325 train acc 0.792\n",
            "== Epoch 41 step 12 train loss 0.55701566 train acc 0.736\n",
            "== Epoch 41 step 13 train loss 0.54485 train acc 0.74\n",
            "== Epoch 41 step 14 train loss 0.5293801 train acc 0.812\n",
            "== Epoch 41 step 15 train loss 0.5673228 train acc 0.736\n",
            "== Epoch 41 step 16 train loss 0.50932497 train acc 0.76\n",
            "== Epoch 41 step 17 train loss 0.5615238 train acc 0.736\n",
            "== Epoch 41 step 18 train loss 0.56198996 train acc 0.772\n",
            "== Epoch 41 step 19 train loss 0.573621 train acc 0.704\n",
            "val acc 0.6686046511627907\n",
            "val loss 0.6185511\n",
            "Saving model at /tmp/tmpl4hmbw_e/torchmoji-checkpoint-ff996a33-fdc2-4d12-93c7-d89fc8e7551a.bin\n",
            "== Epoch 42 step 0 train loss 0.5518968 train acc 0.78\n",
            "== Epoch 42 step 1 train loss 0.5748712 train acc 0.712\n",
            "== Epoch 42 step 2 train loss 0.54843765 train acc 0.768\n",
            "== Epoch 42 step 3 train loss 0.53090316 train acc 0.776\n",
            "== Epoch 42 step 4 train loss 0.53880733 train acc 0.788\n",
            "== Epoch 42 step 5 train loss 0.527395 train acc 0.756\n",
            "== Epoch 42 step 6 train loss 0.564233 train acc 0.74\n",
            "== Epoch 42 step 7 train loss 0.5404613 train acc 0.724\n",
            "== Epoch 42 step 8 train loss 0.55284184 train acc 0.74\n",
            "== Epoch 42 step 9 train loss 0.5406314 train acc 0.748\n",
            "== Epoch 42 step 10 train loss 0.5199687 train acc 0.78\n",
            "== Epoch 42 step 11 train loss 0.532245 train acc 0.796\n",
            "== Epoch 42 step 12 train loss 0.55604744 train acc 0.728\n",
            "== Epoch 42 step 13 train loss 0.53930205 train acc 0.74\n",
            "== Epoch 42 step 14 train loss 0.5192086 train acc 0.812\n",
            "== Epoch 42 step 15 train loss 0.5592361 train acc 0.736\n",
            "== Epoch 42 step 16 train loss 0.52000207 train acc 0.76\n",
            "== Epoch 42 step 17 train loss 0.5528268 train acc 0.74\n",
            "== Epoch 42 step 18 train loss 0.5398505 train acc 0.772\n",
            "== Epoch 42 step 19 train loss 0.5739368 train acc 0.7\n",
            "val acc 0.6744186046511628\n",
            "val loss 0.6182998\n",
            "Saving model at /tmp/tmpl4hmbw_e/torchmoji-checkpoint-ff996a33-fdc2-4d12-93c7-d89fc8e7551a.bin\n",
            "== Epoch 43 step 0 train loss 0.53112185 train acc 0.78\n",
            "== Epoch 43 step 1 train loss 0.5604818 train acc 0.712\n",
            "== Epoch 43 step 2 train loss 0.55554235 train acc 0.768\n",
            "== Epoch 43 step 3 train loss 0.5402451 train acc 0.784\n",
            "== Epoch 43 step 4 train loss 0.5581384 train acc 0.792\n",
            "== Epoch 43 step 5 train loss 0.5350225 train acc 0.756\n",
            "== Epoch 43 step 6 train loss 0.5673785 train acc 0.748\n",
            "== Epoch 43 step 7 train loss 0.5652841 train acc 0.724\n",
            "== Epoch 43 step 8 train loss 0.5615422 train acc 0.744\n",
            "== Epoch 43 step 9 train loss 0.54048884 train acc 0.744\n",
            "== Epoch 43 step 10 train loss 0.5238674 train acc 0.78\n",
            "== Epoch 43 step 11 train loss 0.52807724 train acc 0.792\n",
            "== Epoch 43 step 12 train loss 0.56016374 train acc 0.736\n",
            "== Epoch 43 step 13 train loss 0.5427637 train acc 0.748\n",
            "== Epoch 43 step 14 train loss 0.5226851 train acc 0.816\n",
            "== Epoch 43 step 15 train loss 0.55626255 train acc 0.736\n",
            "== Epoch 43 step 16 train loss 0.5115416 train acc 0.764\n",
            "== Epoch 43 step 17 train loss 0.5520575 train acc 0.744\n",
            "== Epoch 43 step 18 train loss 0.5467071 train acc 0.776\n",
            "== Epoch 43 step 19 train loss 0.567147 train acc 0.708\n",
            "val acc 0.6744186046511628\n",
            "val loss 0.61831915\n",
            "No improvement over previous best loss:  0.6182998\n",
            "== Epoch 44 step 0 train loss 0.5366432 train acc 0.78\n",
            "== Epoch 44 step 1 train loss 0.5720519 train acc 0.712\n",
            "== Epoch 44 step 2 train loss 0.55478185 train acc 0.768\n",
            "== Epoch 44 step 3 train loss 0.5146699 train acc 0.788\n",
            "== Epoch 44 step 4 train loss 0.54408604 train acc 0.792\n",
            "== Epoch 44 step 5 train loss 0.5330076 train acc 0.76\n",
            "== Epoch 44 step 6 train loss 0.5607903 train acc 0.748\n",
            "== Epoch 44 step 7 train loss 0.5548008 train acc 0.724\n",
            "== Epoch 44 step 8 train loss 0.56605035 train acc 0.748\n",
            "== Epoch 44 step 9 train loss 0.5556153 train acc 0.744\n",
            "== Epoch 44 step 10 train loss 0.5166443 train acc 0.78\n",
            "== Epoch 44 step 11 train loss 0.5263313 train acc 0.796\n",
            "== Epoch 44 step 12 train loss 0.57138336 train acc 0.748\n",
            "== Epoch 44 step 13 train loss 0.54006565 train acc 0.748\n",
            "== Epoch 44 step 14 train loss 0.5284412 train acc 0.82\n",
            "== Epoch 44 step 15 train loss 0.5543868 train acc 0.74\n",
            "== Epoch 44 step 16 train loss 0.52162665 train acc 0.768\n",
            "== Epoch 44 step 17 train loss 0.56862926 train acc 0.74\n",
            "== Epoch 44 step 18 train loss 0.55158246 train acc 0.776\n",
            "== Epoch 44 step 19 train loss 0.564684 train acc 0.708\n",
            "val acc 0.6744186046511628\n",
            "val loss 0.6182314\n",
            "Saving model at /tmp/tmpl4hmbw_e/torchmoji-checkpoint-ff996a33-fdc2-4d12-93c7-d89fc8e7551a.bin\n",
            "== Epoch 45 step 0 train loss 0.534433 train acc 0.784\n",
            "== Epoch 45 step 1 train loss 0.56848097 train acc 0.716\n",
            "== Epoch 45 step 2 train loss 0.55635864 train acc 0.768\n",
            "== Epoch 45 step 3 train loss 0.5267454 train acc 0.788\n",
            "== Epoch 45 step 4 train loss 0.53732663 train acc 0.796\n",
            "== Epoch 45 step 5 train loss 0.54407483 train acc 0.76\n",
            "== Epoch 45 step 6 train loss 0.5677801 train acc 0.744\n",
            "== Epoch 45 step 7 train loss 0.56589055 train acc 0.724\n",
            "== Epoch 45 step 8 train loss 0.5482001 train acc 0.748\n",
            "== Epoch 45 step 9 train loss 0.529345 train acc 0.744\n",
            "== Epoch 45 step 10 train loss 0.5376682 train acc 0.784\n",
            "== Epoch 45 step 11 train loss 0.50879604 train acc 0.796\n",
            "== Epoch 45 step 12 train loss 0.5506781 train acc 0.744\n",
            "== Epoch 45 step 13 train loss 0.5534612 train acc 0.752\n",
            "== Epoch 45 step 14 train loss 0.51926255 train acc 0.82\n",
            "== Epoch 45 step 15 train loss 0.558102 train acc 0.74\n",
            "== Epoch 45 step 16 train loss 0.51374984 train acc 0.768\n",
            "== Epoch 45 step 17 train loss 0.5536491 train acc 0.74\n",
            "== Epoch 45 step 18 train loss 0.54504365 train acc 0.78\n",
            "== Epoch 45 step 19 train loss 0.5526748 train acc 0.708\n",
            "val acc 0.6744186046511628\n",
            "val loss 0.61818326\n",
            "Saving model at /tmp/tmpl4hmbw_e/torchmoji-checkpoint-ff996a33-fdc2-4d12-93c7-d89fc8e7551a.bin\n",
            "== Epoch 46 step 0 train loss 0.54788953 train acc 0.784\n",
            "== Epoch 46 step 1 train loss 0.56040406 train acc 0.712\n",
            "== Epoch 46 step 2 train loss 0.5502498 train acc 0.768\n",
            "== Epoch 46 step 3 train loss 0.5139933 train acc 0.784\n",
            "== Epoch 46 step 4 train loss 0.54626393 train acc 0.796\n",
            "== Epoch 46 step 5 train loss 0.53226894 train acc 0.76\n",
            "== Epoch 46 step 6 train loss 0.5716258 train acc 0.744\n",
            "== Epoch 46 step 7 train loss 0.5518465 train acc 0.724\n",
            "== Epoch 46 step 8 train loss 0.53566873 train acc 0.748\n",
            "== Epoch 46 step 9 train loss 0.5428951 train acc 0.744\n",
            "== Epoch 46 step 10 train loss 0.5204316 train acc 0.784\n",
            "== Epoch 46 step 11 train loss 0.52485704 train acc 0.796\n",
            "== Epoch 46 step 12 train loss 0.55301183 train acc 0.748\n",
            "== Epoch 46 step 13 train loss 0.54056 train acc 0.756\n",
            "== Epoch 46 step 14 train loss 0.5160404 train acc 0.82\n",
            "== Epoch 46 step 15 train loss 0.536219 train acc 0.74\n",
            "== Epoch 46 step 16 train loss 0.5149962 train acc 0.768\n",
            "== Epoch 46 step 17 train loss 0.55449075 train acc 0.74\n",
            "== Epoch 46 step 18 train loss 0.5562249 train acc 0.784\n",
            "== Epoch 46 step 19 train loss 0.5664363 train acc 0.712\n",
            "val acc 0.6744186046511628\n",
            "val loss 0.61812603\n",
            "Saving model at /tmp/tmpl4hmbw_e/torchmoji-checkpoint-ff996a33-fdc2-4d12-93c7-d89fc8e7551a.bin\n",
            "== Epoch 47 step 0 train loss 0.53216064 train acc 0.784\n",
            "== Epoch 47 step 1 train loss 0.54967284 train acc 0.716\n",
            "== Epoch 47 step 2 train loss 0.55455774 train acc 0.78\n",
            "== Epoch 47 step 3 train loss 0.5236185 train acc 0.784\n",
            "== Epoch 47 step 4 train loss 0.5530693 train acc 0.796\n",
            "== Epoch 47 step 5 train loss 0.5253431 train acc 0.76\n",
            "== Epoch 47 step 6 train loss 0.56735504 train acc 0.744\n",
            "== Epoch 47 step 7 train loss 0.55098337 train acc 0.724\n",
            "== Epoch 47 step 8 train loss 0.53841895 train acc 0.748\n",
            "== Epoch 47 step 9 train loss 0.5500934 train acc 0.752\n",
            "== Epoch 47 step 10 train loss 0.5196656 train acc 0.784\n",
            "== Epoch 47 step 11 train loss 0.5170273 train acc 0.796\n",
            "== Epoch 47 step 12 train loss 0.55344874 train acc 0.752\n",
            "== Epoch 47 step 13 train loss 0.5295252 train acc 0.756\n",
            "== Epoch 47 step 14 train loss 0.5125234 train acc 0.82\n",
            "== Epoch 47 step 15 train loss 0.5601938 train acc 0.744\n",
            "== Epoch 47 step 16 train loss 0.5225374 train acc 0.772\n",
            "== Epoch 47 step 17 train loss 0.55744094 train acc 0.74\n",
            "== Epoch 47 step 18 train loss 0.5492973 train acc 0.792\n",
            "== Epoch 47 step 19 train loss 0.570514 train acc 0.712\n",
            "val acc 0.6744186046511628\n",
            "val loss 0.61796856\n",
            "Saving model at /tmp/tmpl4hmbw_e/torchmoji-checkpoint-ff996a33-fdc2-4d12-93c7-d89fc8e7551a.bin\n",
            "== Epoch 48 step 0 train loss 0.531289 train acc 0.788\n",
            "== Epoch 48 step 1 train loss 0.568555 train acc 0.716\n",
            "== Epoch 48 step 2 train loss 0.55050796 train acc 0.78\n",
            "== Epoch 48 step 3 train loss 0.52566487 train acc 0.788\n",
            "== Epoch 48 step 4 train loss 0.5367448 train acc 0.8\n",
            "== Epoch 48 step 5 train loss 0.5073533 train acc 0.76\n",
            "== Epoch 48 step 6 train loss 0.55419636 train acc 0.744\n",
            "== Epoch 48 step 7 train loss 0.538654 train acc 0.728\n",
            "== Epoch 48 step 8 train loss 0.5541038 train acc 0.748\n",
            "== Epoch 48 step 9 train loss 0.5399543 train acc 0.764\n",
            "== Epoch 48 step 10 train loss 0.53214955 train acc 0.784\n",
            "== Epoch 48 step 11 train loss 0.5223788 train acc 0.796\n",
            "== Epoch 48 step 12 train loss 0.5559577 train acc 0.752\n",
            "== Epoch 48 step 13 train loss 0.53369576 train acc 0.756\n",
            "== Epoch 48 step 14 train loss 0.5162736 train acc 0.82\n",
            "== Epoch 48 step 15 train loss 0.5848826 train acc 0.744\n",
            "== Epoch 48 step 16 train loss 0.52101606 train acc 0.78\n",
            "== Epoch 48 step 17 train loss 0.55432576 train acc 0.744\n",
            "== Epoch 48 step 18 train loss 0.5297317 train acc 0.792\n",
            "== Epoch 48 step 19 train loss 0.57102567 train acc 0.72\n",
            "val acc 0.6686046511627907\n",
            "val loss 0.6177127\n",
            "Saving model at /tmp/tmpl4hmbw_e/torchmoji-checkpoint-ff996a33-fdc2-4d12-93c7-d89fc8e7551a.bin\n",
            "== Epoch 49 step 0 train loss 0.54869306 train acc 0.792\n",
            "== Epoch 49 step 1 train loss 0.5446571 train acc 0.72\n",
            "== Epoch 49 step 2 train loss 0.53997624 train acc 0.78\n",
            "== Epoch 49 step 3 train loss 0.5010886 train acc 0.8\n",
            "== Epoch 49 step 4 train loss 0.52318615 train acc 0.804\n",
            "== Epoch 49 step 5 train loss 0.53240865 train acc 0.772\n",
            "== Epoch 49 step 6 train loss 0.5471985 train acc 0.748\n",
            "== Epoch 49 step 7 train loss 0.5549882 train acc 0.728\n",
            "== Epoch 49 step 8 train loss 0.5570417 train acc 0.752\n",
            "== Epoch 49 step 9 train loss 0.5364799 train acc 0.776\n",
            "== Epoch 49 step 10 train loss 0.520662 train acc 0.784\n",
            "== Epoch 49 step 11 train loss 0.5099552 train acc 0.796\n",
            "== Epoch 49 step 12 train loss 0.5590424 train acc 0.752\n",
            "== Epoch 49 step 13 train loss 0.55182 train acc 0.764\n",
            "== Epoch 49 step 14 train loss 0.5144355 train acc 0.82\n",
            "== Epoch 49 step 15 train loss 0.56824553 train acc 0.744\n",
            "== Epoch 49 step 16 train loss 0.51644605 train acc 0.792\n",
            "== Epoch 49 step 17 train loss 0.5635985 train acc 0.748\n",
            "== Epoch 49 step 18 train loss 0.56323487 train acc 0.796\n",
            "== Epoch 49 step 19 train loss 0.5592891 train acc 0.72\n",
            "val acc 0.6686046511627907\n",
            "val loss 0.61758953\n",
            "Saving model at /tmp/tmpl4hmbw_e/torchmoji-checkpoint-ff996a33-fdc2-4d12-93c7-d89fc8e7551a.bin\n",
            "== Epoch 50 step 0 train loss 0.51715314 train acc 0.792\n",
            "== Epoch 50 step 1 train loss 0.5698503 train acc 0.716\n",
            "== Epoch 50 step 2 train loss 0.54296064 train acc 0.776\n",
            "== Epoch 50 step 3 train loss 0.5102554 train acc 0.792\n",
            "== Epoch 50 step 4 train loss 0.53818935 train acc 0.804\n",
            "== Epoch 50 step 5 train loss 0.52832663 train acc 0.764\n",
            "== Epoch 50 step 6 train loss 0.54858804 train acc 0.748\n",
            "== Epoch 50 step 7 train loss 0.55331236 train acc 0.728\n",
            "== Epoch 50 step 8 train loss 0.53726465 train acc 0.756\n",
            "== Epoch 50 step 9 train loss 0.5427297 train acc 0.776\n",
            "== Epoch 50 step 10 train loss 0.5150963 train acc 0.784\n",
            "== Epoch 50 step 11 train loss 0.5122385 train acc 0.796\n",
            "== Epoch 50 step 12 train loss 0.55868095 train acc 0.752\n",
            "== Epoch 50 step 13 train loss 0.5405513 train acc 0.76\n",
            "== Epoch 50 step 14 train loss 0.50568163 train acc 0.82\n",
            "== Epoch 50 step 15 train loss 0.55476767 train acc 0.744\n",
            "== Epoch 50 step 16 train loss 0.5130645 train acc 0.792\n",
            "== Epoch 50 step 17 train loss 0.5454921 train acc 0.748\n",
            "== Epoch 50 step 18 train loss 0.53568256 train acc 0.792\n",
            "== Epoch 50 step 19 train loss 0.57309234 train acc 0.72\n",
            "val acc 0.6686046511627907\n",
            "val loss 0.6176493\n",
            "No improvement over previous best loss:  0.61758953\n",
            "== Epoch 51 step 0 train loss 0.5327955 train acc 0.792\n",
            "== Epoch 51 step 1 train loss 0.5714093 train acc 0.716\n",
            "== Epoch 51 step 2 train loss 0.5520195 train acc 0.776\n",
            "== Epoch 51 step 3 train loss 0.51984483 train acc 0.796\n",
            "== Epoch 51 step 4 train loss 0.543486 train acc 0.804\n",
            "== Epoch 51 step 5 train loss 0.5355787 train acc 0.764\n",
            "== Epoch 51 step 6 train loss 0.55781394 train acc 0.748\n",
            "== Epoch 51 step 7 train loss 0.55643004 train acc 0.728\n",
            "== Epoch 51 step 8 train loss 0.5614106 train acc 0.752\n",
            "== Epoch 51 step 9 train loss 0.53268087 train acc 0.776\n",
            "== Epoch 51 step 10 train loss 0.5085508 train acc 0.784\n",
            "== Epoch 51 step 11 train loss 0.52070653 train acc 0.796\n",
            "== Epoch 51 step 12 train loss 0.53577626 train acc 0.752\n",
            "== Epoch 51 step 13 train loss 0.5492559 train acc 0.76\n",
            "== Epoch 51 step 14 train loss 0.50261027 train acc 0.82\n",
            "== Epoch 51 step 15 train loss 0.54041535 train acc 0.744\n",
            "== Epoch 51 step 16 train loss 0.50520194 train acc 0.792\n",
            "== Epoch 51 step 17 train loss 0.5455525 train acc 0.748\n",
            "== Epoch 51 step 18 train loss 0.5505684 train acc 0.792\n",
            "== Epoch 51 step 19 train loss 0.5554025 train acc 0.72\n",
            "val acc 0.6627906976744186\n",
            "val loss 0.61797243\n",
            "No improvement over previous best loss:  0.61758953\n",
            "== Epoch 52 step 0 train loss 0.5269988 train acc 0.792\n",
            "== Epoch 52 step 1 train loss 0.55797684 train acc 0.716\n",
            "== Epoch 52 step 2 train loss 0.55088824 train acc 0.776\n",
            "== Epoch 52 step 3 train loss 0.50718737 train acc 0.796\n",
            "== Epoch 52 step 4 train loss 0.51293665 train acc 0.804\n",
            "== Epoch 52 step 5 train loss 0.52558726 train acc 0.768\n",
            "== Epoch 52 step 6 train loss 0.5613903 train acc 0.748\n",
            "== Epoch 52 step 7 train loss 0.5340345 train acc 0.728\n",
            "== Epoch 52 step 8 train loss 0.5498469 train acc 0.76\n",
            "== Epoch 52 step 9 train loss 0.5516818 train acc 0.776\n",
            "== Epoch 52 step 10 train loss 0.51981616 train acc 0.78\n",
            "== Epoch 52 step 11 train loss 0.52550393 train acc 0.796\n",
            "== Epoch 52 step 12 train loss 0.54441583 train acc 0.756\n",
            "== Epoch 52 step 13 train loss 0.5353592 train acc 0.764\n",
            "== Epoch 52 step 14 train loss 0.5036192 train acc 0.82\n",
            "== Epoch 52 step 15 train loss 0.54958296 train acc 0.748\n",
            "== Epoch 52 step 16 train loss 0.50870603 train acc 0.792\n",
            "== Epoch 52 step 17 train loss 0.56058645 train acc 0.752\n",
            "== Epoch 52 step 18 train loss 0.53606313 train acc 0.796\n",
            "== Epoch 52 step 19 train loss 0.5425962 train acc 0.72\n",
            "val acc 0.6627906976744186\n",
            "val loss 0.61811376\n",
            "No improvement over previous best loss:  0.61758953\n",
            "Finetuning Embedding(50000, 256)\n",
            "original val loss 0.61758953\n",
            "== Epoch 0 step 0 train loss 0.52891004 train acc 0.792\n",
            "== Epoch 0 step 1 train loss 0.5495347 train acc 0.72\n",
            "== Epoch 0 step 2 train loss 0.5460981 train acc 0.78\n",
            "== Epoch 0 step 3 train loss 0.52564955 train acc 0.8\n",
            "== Epoch 0 step 4 train loss 0.53699404 train acc 0.804\n",
            "== Epoch 0 step 5 train loss 0.51712966 train acc 0.768\n",
            "== Epoch 0 step 6 train loss 0.5517506 train acc 0.748\n",
            "== Epoch 0 step 7 train loss 0.5393672 train acc 0.732\n",
            "== Epoch 0 step 8 train loss 0.54883933 train acc 0.76\n",
            "== Epoch 0 step 9 train loss 0.5141076 train acc 0.784\n",
            "== Epoch 0 step 10 train loss 0.5220357 train acc 0.784\n",
            "== Epoch 0 step 11 train loss 0.50608647 train acc 0.796\n",
            "== Epoch 0 step 12 train loss 0.5410493 train acc 0.764\n",
            "== Epoch 0 step 13 train loss 0.52312744 train acc 0.772\n",
            "== Epoch 0 step 14 train loss 0.5159187 train acc 0.82\n",
            "== Epoch 0 step 15 train loss 0.53076273 train acc 0.76\n",
            "== Epoch 0 step 16 train loss 0.51640826 train acc 0.796\n",
            "== Epoch 0 step 17 train loss 0.5481363 train acc 0.772\n",
            "== Epoch 0 step 18 train loss 0.52163607 train acc 0.804\n",
            "== Epoch 0 step 19 train loss 0.54776406 train acc 0.728\n",
            "val acc 0.6627906976744186\n",
            "val loss 0.61838466\n",
            "No improvement over previous best loss:  0.61758953\n",
            "== Epoch 1 step 0 train loss 0.5012971 train acc 0.8\n",
            "== Epoch 1 step 1 train loss 0.541765 train acc 0.756\n",
            "== Epoch 1 step 2 train loss 0.5403697 train acc 0.796\n",
            "== Epoch 1 step 3 train loss 0.51468587 train acc 0.816\n",
            "== Epoch 1 step 4 train loss 0.5251195 train acc 0.82\n",
            "== Epoch 1 step 5 train loss 0.51248175 train acc 0.788\n",
            "== Epoch 1 step 6 train loss 0.52275395 train acc 0.776\n",
            "== Epoch 1 step 7 train loss 0.52890444 train acc 0.772\n",
            "== Epoch 1 step 8 train loss 0.51378334 train acc 0.8\n",
            "== Epoch 1 step 9 train loss 0.5205921 train acc 0.804\n",
            "== Epoch 1 step 10 train loss 0.49986228 train acc 0.816\n",
            "== Epoch 1 step 11 train loss 0.49650225 train acc 0.816\n",
            "== Epoch 1 step 12 train loss 0.52475923 train acc 0.784\n",
            "== Epoch 1 step 13 train loss 0.52519757 train acc 0.804\n",
            "== Epoch 1 step 14 train loss 0.4760166 train acc 0.84\n",
            "== Epoch 1 step 15 train loss 0.5260478 train acc 0.788\n",
            "== Epoch 1 step 16 train loss 0.47510836 train acc 0.812\n",
            "== Epoch 1 step 17 train loss 0.5444275 train acc 0.788\n",
            "== Epoch 1 step 18 train loss 0.52367866 train acc 0.808\n",
            "== Epoch 1 step 19 train loss 0.54164225 train acc 0.744\n",
            "val acc 0.6744186046511628\n",
            "val loss 0.61917835\n",
            "No improvement over previous best loss:  0.61758953\n",
            "== Epoch 2 step 0 train loss 0.49526796 train acc 0.808\n",
            "== Epoch 2 step 1 train loss 0.5185603 train acc 0.804\n",
            "== Epoch 2 step 2 train loss 0.52888817 train acc 0.82\n",
            "== Epoch 2 step 3 train loss 0.48768035 train acc 0.836\n",
            "== Epoch 2 step 4 train loss 0.48591655 train acc 0.832\n",
            "== Epoch 2 step 5 train loss 0.4938133 train acc 0.808\n",
            "== Epoch 2 step 6 train loss 0.50677556 train acc 0.792\n",
            "== Epoch 2 step 7 train loss 0.5225315 train acc 0.796\n",
            "== Epoch 2 step 8 train loss 0.5106126 train acc 0.824\n",
            "== Epoch 2 step 9 train loss 0.4995013 train acc 0.82\n",
            "== Epoch 2 step 10 train loss 0.48076135 train acc 0.836\n",
            "== Epoch 2 step 11 train loss 0.48299792 train acc 0.816\n",
            "== Epoch 2 step 12 train loss 0.49537817 train acc 0.792\n",
            "== Epoch 2 step 13 train loss 0.5007246 train acc 0.808\n",
            "== Epoch 2 step 14 train loss 0.479436 train acc 0.86\n",
            "== Epoch 2 step 15 train loss 0.50328195 train acc 0.816\n",
            "== Epoch 2 step 16 train loss 0.46517238 train acc 0.832\n",
            "== Epoch 2 step 17 train loss 0.5057116 train acc 0.812\n",
            "== Epoch 2 step 18 train loss 0.49316543 train acc 0.828\n",
            "== Epoch 2 step 19 train loss 0.51697046 train acc 0.788\n",
            "val acc 0.6744186046511628\n",
            "val loss 0.6199568\n",
            "No improvement over previous best loss:  0.61758953\n",
            "== Epoch 3 step 0 train loss 0.47453988 train acc 0.816\n",
            "== Epoch 3 step 1 train loss 0.50323176 train acc 0.82\n",
            "== Epoch 3 step 2 train loss 0.48847783 train acc 0.856\n",
            "== Epoch 3 step 3 train loss 0.46209425 train acc 0.852\n",
            "== Epoch 3 step 4 train loss 0.49192291 train acc 0.86\n",
            "== Epoch 3 step 5 train loss 0.4863639 train acc 0.82\n",
            "== Epoch 3 step 6 train loss 0.5079962 train acc 0.824\n",
            "== Epoch 3 step 7 train loss 0.50592744 train acc 0.808\n",
            "== Epoch 3 step 8 train loss 0.4829326 train acc 0.828\n",
            "== Epoch 3 step 9 train loss 0.47966027 train acc 0.832\n",
            "== Epoch 3 step 10 train loss 0.460409 train acc 0.86\n",
            "== Epoch 3 step 11 train loss 0.4605686 train acc 0.852\n",
            "== Epoch 3 step 12 train loss 0.48229635 train acc 0.812\n",
            "== Epoch 3 step 13 train loss 0.48345134 train acc 0.836\n",
            "== Epoch 3 step 14 train loss 0.45404148 train acc 0.888\n",
            "== Epoch 3 step 15 train loss 0.49512774 train acc 0.836\n",
            "== Epoch 3 step 16 train loss 0.45397955 train acc 0.844\n",
            "== Epoch 3 step 17 train loss 0.4832591 train acc 0.828\n",
            "== Epoch 3 step 18 train loss 0.48682964 train acc 0.852\n",
            "== Epoch 3 step 19 train loss 0.496748 train acc 0.812\n",
            "val acc 0.6802325581395349\n",
            "val loss 0.6208441\n",
            "No improvement over previous best loss:  0.61758953\n",
            "== Epoch 4 step 0 train loss 0.47800103 train acc 0.824\n",
            "== Epoch 4 step 1 train loss 0.5005661 train acc 0.824\n",
            "== Epoch 4 step 2 train loss 0.4762044 train acc 0.872\n",
            "== Epoch 4 step 3 train loss 0.45889807 train acc 0.876\n",
            "== Epoch 4 step 4 train loss 0.47242227 train acc 0.876\n",
            "== Epoch 4 step 5 train loss 0.46214825 train acc 0.848\n",
            "== Epoch 4 step 6 train loss 0.4807858 train acc 0.836\n",
            "== Epoch 4 step 7 train loss 0.48084727 train acc 0.832\n",
            "== Epoch 4 step 8 train loss 0.4781101 train acc 0.868\n",
            "== Epoch 4 step 9 train loss 0.46571425 train acc 0.864\n",
            "== Epoch 4 step 10 train loss 0.4489082 train acc 0.884\n",
            "== Epoch 4 step 11 train loss 0.45408738 train acc 0.868\n",
            "== Epoch 4 step 12 train loss 0.47797266 train acc 0.828\n",
            "== Epoch 4 step 13 train loss 0.46851745 train acc 0.848\n",
            "== Epoch 4 step 14 train loss 0.43981338 train acc 0.892\n",
            "== Epoch 4 step 15 train loss 0.4695141 train acc 0.852\n",
            "== Epoch 4 step 16 train loss 0.44081497 train acc 0.876\n",
            "== Epoch 4 step 17 train loss 0.47457132 train acc 0.848\n",
            "== Epoch 4 step 18 train loss 0.45213944 train acc 0.884\n",
            "== Epoch 4 step 19 train loss 0.48453605 train acc 0.84\n",
            "val acc 0.6744186046511628\n",
            "val loss 0.6216724\n",
            "No improvement over previous best loss:  0.61758953\n",
            "Finetuning LSTMHardSigmoid(256, 512, batch_first=True, bidirectional=True)\n",
            "original val loss 0.61758953\n",
            "== Epoch 0 step 0 train loss 0.53093255 train acc 0.792\n",
            "== Epoch 0 step 1 train loss 0.5553104 train acc 0.72\n",
            "== Epoch 0 step 2 train loss 0.54996693 train acc 0.78\n",
            "== Epoch 0 step 3 train loss 0.5102252 train acc 0.796\n",
            "== Epoch 0 step 4 train loss 0.5547448 train acc 0.804\n",
            "== Epoch 0 step 5 train loss 0.51206034 train acc 0.772\n",
            "== Epoch 0 step 6 train loss 0.5482468 train acc 0.748\n",
            "== Epoch 0 step 7 train loss 0.54707456 train acc 0.728\n",
            "== Epoch 0 step 8 train loss 0.55072826 train acc 0.756\n",
            "== Epoch 0 step 9 train loss 0.5308566 train acc 0.776\n",
            "== Epoch 0 step 10 train loss 0.5312215 train acc 0.784\n",
            "== Epoch 0 step 11 train loss 0.5312898 train acc 0.796\n",
            "== Epoch 0 step 12 train loss 0.5476814 train acc 0.756\n",
            "== Epoch 0 step 13 train loss 0.5411329 train acc 0.764\n",
            "== Epoch 0 step 14 train loss 0.506237 train acc 0.816\n",
            "== Epoch 0 step 15 train loss 0.555723 train acc 0.752\n",
            "== Epoch 0 step 16 train loss 0.5133387 train acc 0.792\n",
            "== Epoch 0 step 17 train loss 0.55210805 train acc 0.752\n",
            "== Epoch 0 step 18 train loss 0.5292393 train acc 0.796\n",
            "== Epoch 0 step 19 train loss 0.5573367 train acc 0.72\n",
            "val acc 0.6686046511627907\n",
            "val loss 0.61762434\n",
            "No improvement over previous best loss:  0.61758953\n",
            "== Epoch 1 step 0 train loss 0.51633483 train acc 0.792\n",
            "== Epoch 1 step 1 train loss 0.5443062 train acc 0.732\n",
            "== Epoch 1 step 2 train loss 0.5379023 train acc 0.784\n",
            "== Epoch 1 step 3 train loss 0.52695376 train acc 0.796\n",
            "== Epoch 1 step 4 train loss 0.522835 train acc 0.804\n",
            "== Epoch 1 step 5 train loss 0.5169706 train acc 0.772\n",
            "== Epoch 1 step 6 train loss 0.5451379 train acc 0.756\n",
            "== Epoch 1 step 7 train loss 0.54622495 train acc 0.732\n",
            "== Epoch 1 step 8 train loss 0.52194965 train acc 0.76\n",
            "== Epoch 1 step 9 train loss 0.5307287 train acc 0.788\n",
            "== Epoch 1 step 10 train loss 0.51674896 train acc 0.792\n",
            "== Epoch 1 step 11 train loss 0.5231959 train acc 0.796\n",
            "== Epoch 1 step 12 train loss 0.5341721 train acc 0.76\n",
            "== Epoch 1 step 13 train loss 0.53709054 train acc 0.772\n",
            "== Epoch 1 step 14 train loss 0.49514535 train acc 0.82\n",
            "== Epoch 1 step 15 train loss 0.5399504 train acc 0.764\n",
            "== Epoch 1 step 16 train loss 0.49286157 train acc 0.8\n",
            "== Epoch 1 step 17 train loss 0.52759516 train acc 0.756\n",
            "== Epoch 1 step 18 train loss 0.5364385 train acc 0.8\n",
            "== Epoch 1 step 19 train loss 0.5611215 train acc 0.716\n",
            "val acc 0.6686046511627907\n",
            "val loss 0.6178471\n",
            "No improvement over previous best loss:  0.61758953\n",
            "== Epoch 2 step 0 train loss 0.5106633 train acc 0.796\n",
            "== Epoch 2 step 1 train loss 0.5286114 train acc 0.756\n",
            "== Epoch 2 step 2 train loss 0.53091633 train acc 0.792\n",
            "== Epoch 2 step 3 train loss 0.50824815 train acc 0.812\n",
            "== Epoch 2 step 4 train loss 0.5268971 train acc 0.808\n",
            "== Epoch 2 step 5 train loss 0.50913256 train acc 0.784\n",
            "== Epoch 2 step 6 train loss 0.5373259 train acc 0.768\n",
            "== Epoch 2 step 7 train loss 0.5233741 train acc 0.756\n",
            "== Epoch 2 step 8 train loss 0.52960414 train acc 0.78\n",
            "== Epoch 2 step 9 train loss 0.52364546 train acc 0.8\n",
            "== Epoch 2 step 10 train loss 0.49216974 train acc 0.8\n",
            "== Epoch 2 step 11 train loss 0.48700592 train acc 0.796\n",
            "== Epoch 2 step 12 train loss 0.5438185 train acc 0.768\n",
            "== Epoch 2 step 13 train loss 0.529786 train acc 0.784\n",
            "== Epoch 2 step 14 train loss 0.50098205 train acc 0.836\n",
            "== Epoch 2 step 15 train loss 0.53047836 train acc 0.772\n",
            "== Epoch 2 step 16 train loss 0.4790471 train acc 0.804\n",
            "== Epoch 2 step 17 train loss 0.53979355 train acc 0.78\n",
            "== Epoch 2 step 18 train loss 0.5140036 train acc 0.808\n",
            "== Epoch 2 step 19 train loss 0.51447886 train acc 0.74\n",
            "val acc 0.6627906976744186\n",
            "val loss 0.6180249\n",
            "No improvement over previous best loss:  0.61758953\n",
            "== Epoch 3 step 0 train loss 0.51497614 train acc 0.796\n",
            "== Epoch 3 step 1 train loss 0.5326768 train acc 0.776\n",
            "== Epoch 3 step 2 train loss 0.5250097 train acc 0.796\n",
            "== Epoch 3 step 3 train loss 0.5108817 train acc 0.816\n",
            "== Epoch 3 step 4 train loss 0.5329069 train acc 0.828\n",
            "== Epoch 3 step 5 train loss 0.5093601 train acc 0.792\n",
            "== Epoch 3 step 6 train loss 0.5029927 train acc 0.784\n",
            "== Epoch 3 step 7 train loss 0.5299165 train acc 0.76\n",
            "== Epoch 3 step 8 train loss 0.5071835 train acc 0.796\n",
            "== Epoch 3 step 9 train loss 0.51041037 train acc 0.804\n",
            "== Epoch 3 step 10 train loss 0.488723 train acc 0.804\n",
            "== Epoch 3 step 11 train loss 0.49192634 train acc 0.812\n",
            "== Epoch 3 step 12 train loss 0.53445834 train acc 0.772\n",
            "== Epoch 3 step 13 train loss 0.50149256 train acc 0.796\n",
            "== Epoch 3 step 14 train loss 0.49774468 train acc 0.84\n",
            "== Epoch 3 step 15 train loss 0.5204243 train acc 0.78\n",
            "== Epoch 3 step 16 train loss 0.47594014 train acc 0.816\n",
            "== Epoch 3 step 17 train loss 0.51663005 train acc 0.792\n",
            "== Epoch 3 step 18 train loss 0.51030535 train acc 0.82\n",
            "== Epoch 3 step 19 train loss 0.5506013 train acc 0.744\n",
            "val acc 0.6686046511627907\n",
            "val loss 0.61827993\n",
            "No improvement over previous best loss:  0.61758953\n",
            "== Epoch 4 step 0 train loss 0.49564272 train acc 0.8\n",
            "== Epoch 4 step 1 train loss 0.52434164 train acc 0.788\n",
            "== Epoch 4 step 2 train loss 0.52236205 train acc 0.804\n",
            "== Epoch 4 step 3 train loss 0.49771556 train acc 0.824\n",
            "== Epoch 4 step 4 train loss 0.52139175 train acc 0.832\n",
            "== Epoch 4 step 5 train loss 0.49526381 train acc 0.796\n",
            "== Epoch 4 step 6 train loss 0.51229906 train acc 0.792\n",
            "== Epoch 4 step 7 train loss 0.50818866 train acc 0.776\n",
            "== Epoch 4 step 8 train loss 0.5234303 train acc 0.808\n",
            "== Epoch 4 step 9 train loss 0.5080018 train acc 0.808\n",
            "== Epoch 4 step 10 train loss 0.483166 train acc 0.812\n",
            "== Epoch 4 step 11 train loss 0.49808922 train acc 0.824\n",
            "== Epoch 4 step 12 train loss 0.5016026 train acc 0.78\n",
            "== Epoch 4 step 13 train loss 0.50089777 train acc 0.808\n",
            "== Epoch 4 step 14 train loss 0.47473553 train acc 0.848\n",
            "== Epoch 4 step 15 train loss 0.5092325 train acc 0.796\n",
            "== Epoch 4 step 16 train loss 0.47362658 train acc 0.828\n",
            "== Epoch 4 step 17 train loss 0.52464193 train acc 0.796\n",
            "== Epoch 4 step 18 train loss 0.51383287 train acc 0.82\n",
            "== Epoch 4 step 19 train loss 0.5137358 train acc 0.752\n",
            "val acc 0.6686046511627907\n",
            "val loss 0.618592\n",
            "No improvement over previous best loss:  0.61758953\n",
            "Finetuning LSTMHardSigmoid(1024, 512, batch_first=True, bidirectional=True)\n",
            "original val loss 0.61758953\n",
            "== Epoch 0 step 0 train loss 0.53199184 train acc 0.792\n",
            "== Epoch 0 step 1 train loss 0.5507712 train acc 0.72\n",
            "== Epoch 0 step 2 train loss 0.53111553 train acc 0.78\n",
            "== Epoch 0 step 3 train loss 0.52753484 train acc 0.796\n",
            "== Epoch 0 step 4 train loss 0.5157345 train acc 0.804\n",
            "== Epoch 0 step 5 train loss 0.52873945 train acc 0.772\n",
            "== Epoch 0 step 6 train loss 0.5517646 train acc 0.748\n",
            "== Epoch 0 step 7 train loss 0.5442988 train acc 0.728\n",
            "== Epoch 0 step 8 train loss 0.55046755 train acc 0.756\n",
            "== Epoch 0 step 9 train loss 0.5377003 train acc 0.776\n",
            "== Epoch 0 step 10 train loss 0.5134445 train acc 0.784\n",
            "== Epoch 0 step 11 train loss 0.5149553 train acc 0.796\n",
            "== Epoch 0 step 12 train loss 0.55114824 train acc 0.756\n",
            "== Epoch 0 step 13 train loss 0.5519655 train acc 0.764\n",
            "== Epoch 0 step 14 train loss 0.5065801 train acc 0.816\n",
            "== Epoch 0 step 15 train loss 0.5446762 train acc 0.748\n",
            "== Epoch 0 step 16 train loss 0.5063791 train acc 0.792\n",
            "== Epoch 0 step 17 train loss 0.54965067 train acc 0.752\n",
            "== Epoch 0 step 18 train loss 0.54793 train acc 0.796\n",
            "== Epoch 0 step 19 train loss 0.5563203 train acc 0.72\n",
            "val acc 0.6686046511627907\n",
            "val loss 0.6177671\n",
            "No improvement over previous best loss:  0.61758953\n",
            "== Epoch 1 step 0 train loss 0.5251608 train acc 0.792\n",
            "== Epoch 1 step 1 train loss 0.5608429 train acc 0.72\n",
            "== Epoch 1 step 2 train loss 0.5448342 train acc 0.784\n",
            "== Epoch 1 step 3 train loss 0.5125936 train acc 0.796\n",
            "== Epoch 1 step 4 train loss 0.51968145 train acc 0.804\n",
            "== Epoch 1 step 5 train loss 0.5209586 train acc 0.772\n",
            "== Epoch 1 step 6 train loss 0.5352197 train acc 0.752\n",
            "== Epoch 1 step 7 train loss 0.5463529 train acc 0.736\n",
            "== Epoch 1 step 8 train loss 0.5387221 train acc 0.756\n",
            "== Epoch 1 step 9 train loss 0.5331903 train acc 0.784\n",
            "== Epoch 1 step 10 train loss 0.5070844 train acc 0.792\n",
            "== Epoch 1 step 11 train loss 0.5105538 train acc 0.796\n",
            "== Epoch 1 step 12 train loss 0.524914 train acc 0.756\n",
            "== Epoch 1 step 13 train loss 0.5260604 train acc 0.768\n",
            "== Epoch 1 step 14 train loss 0.5067007 train acc 0.824\n",
            "== Epoch 1 step 15 train loss 0.54311395 train acc 0.752\n",
            "== Epoch 1 step 16 train loss 0.49928993 train acc 0.796\n",
            "== Epoch 1 step 17 train loss 0.52412486 train acc 0.76\n",
            "== Epoch 1 step 18 train loss 0.54194677 train acc 0.8\n",
            "== Epoch 1 step 19 train loss 0.5523516 train acc 0.72\n",
            "val acc 0.6686046511627907\n",
            "val loss 0.6182959\n",
            "No improvement over previous best loss:  0.61758953\n",
            "== Epoch 2 step 0 train loss 0.515974 train acc 0.796\n",
            "== Epoch 2 step 1 train loss 0.5368729 train acc 0.736\n",
            "== Epoch 2 step 2 train loss 0.54203147 train acc 0.78\n",
            "== Epoch 2 step 3 train loss 0.5069647 train acc 0.812\n",
            "== Epoch 2 step 4 train loss 0.5112588 train acc 0.804\n",
            "== Epoch 2 step 5 train loss 0.51452976 train acc 0.78\n",
            "== Epoch 2 step 6 train loss 0.5418728 train acc 0.76\n",
            "== Epoch 2 step 7 train loss 0.54065037 train acc 0.748\n",
            "== Epoch 2 step 8 train loss 0.5378369 train acc 0.772\n",
            "== Epoch 2 step 9 train loss 0.51272905 train acc 0.796\n",
            "== Epoch 2 step 10 train loss 0.49670267 train acc 0.792\n",
            "== Epoch 2 step 11 train loss 0.5055104 train acc 0.796\n",
            "== Epoch 2 step 12 train loss 0.5347755 train acc 0.764\n",
            "== Epoch 2 step 13 train loss 0.5124475 train acc 0.772\n",
            "== Epoch 2 step 14 train loss 0.50130504 train acc 0.832\n",
            "== Epoch 2 step 15 train loss 0.52827924 train acc 0.756\n",
            "== Epoch 2 step 16 train loss 0.5018397 train acc 0.8\n",
            "== Epoch 2 step 17 train loss 0.5324655 train acc 0.768\n",
            "== Epoch 2 step 18 train loss 0.5099929 train acc 0.804\n",
            "== Epoch 2 step 19 train loss 0.5313801 train acc 0.732\n",
            "val acc 0.6686046511627907\n",
            "val loss 0.619015\n",
            "No improvement over previous best loss:  0.61758953\n",
            "== Epoch 3 step 0 train loss 0.51415 train acc 0.796\n",
            "== Epoch 3 step 1 train loss 0.5303081 train acc 0.752\n",
            "== Epoch 3 step 2 train loss 0.5414276 train acc 0.788\n",
            "== Epoch 3 step 3 train loss 0.49258137 train acc 0.816\n",
            "== Epoch 3 step 4 train loss 0.5035666 train acc 0.816\n",
            "== Epoch 3 step 5 train loss 0.5003161 train acc 0.788\n",
            "== Epoch 3 step 6 train loss 0.546917 train acc 0.772\n",
            "== Epoch 3 step 7 train loss 0.5398917 train acc 0.756\n",
            "== Epoch 3 step 8 train loss 0.53497326 train acc 0.796\n",
            "== Epoch 3 step 9 train loss 0.5230763 train acc 0.804\n",
            "== Epoch 3 step 10 train loss 0.49244142 train acc 0.804\n",
            "== Epoch 3 step 11 train loss 0.49682206 train acc 0.796\n",
            "== Epoch 3 step 12 train loss 0.5170478 train acc 0.776\n",
            "== Epoch 3 step 13 train loss 0.5291567 train acc 0.784\n",
            "== Epoch 3 step 14 train loss 0.48547634 train acc 0.836\n",
            "== Epoch 3 step 15 train loss 0.52577347 train acc 0.772\n",
            "== Epoch 3 step 16 train loss 0.49552256 train acc 0.808\n",
            "== Epoch 3 step 17 train loss 0.5281694 train acc 0.784\n",
            "== Epoch 3 step 18 train loss 0.526791 train acc 0.816\n",
            "== Epoch 3 step 19 train loss 0.54118836 train acc 0.74\n",
            "val acc 0.6627906976744186\n",
            "val loss 0.6197231\n",
            "No improvement over previous best loss:  0.61758953\n",
            "== Epoch 4 step 0 train loss 0.4979448 train acc 0.808\n",
            "== Epoch 4 step 1 train loss 0.53822166 train acc 0.764\n",
            "== Epoch 4 step 2 train loss 0.5223638 train acc 0.796\n",
            "== Epoch 4 step 3 train loss 0.48435175 train acc 0.82\n",
            "== Epoch 4 step 4 train loss 0.50157946 train acc 0.828\n",
            "== Epoch 4 step 5 train loss 0.4960654 train acc 0.792\n",
            "== Epoch 4 step 6 train loss 0.5176973 train acc 0.792\n",
            "== Epoch 4 step 7 train loss 0.51304704 train acc 0.772\n",
            "== Epoch 4 step 8 train loss 0.511859 train acc 0.808\n",
            "== Epoch 4 step 9 train loss 0.50192875 train acc 0.804\n",
            "== Epoch 4 step 10 train loss 0.48845416 train acc 0.816\n",
            "== Epoch 4 step 11 train loss 0.49695465 train acc 0.812\n",
            "== Epoch 4 step 12 train loss 0.5268022 train acc 0.788\n",
            "== Epoch 4 step 13 train loss 0.50882167 train acc 0.796\n",
            "== Epoch 4 step 14 train loss 0.48852888 train acc 0.848\n",
            "== Epoch 4 step 15 train loss 0.50613844 train acc 0.784\n",
            "== Epoch 4 step 16 train loss 0.461273 train acc 0.82\n",
            "== Epoch 4 step 17 train loss 0.519889 train acc 0.792\n",
            "== Epoch 4 step 18 train loss 0.5179901 train acc 0.82\n",
            "== Epoch 4 step 19 train loss 0.5072518 train acc 0.748\n",
            "val acc 0.6569767441860465\n",
            "val loss 0.6208315\n",
            "No improvement over previous best loss:  0.61758953\n",
            "Finetuning Attention(2304, return attention=False)\n",
            "original val loss 0.61758953\n",
            "== Epoch 0 step 0 train loss 0.5374821 train acc 0.792\n",
            "== Epoch 0 step 1 train loss 0.54553926 train acc 0.716\n",
            "== Epoch 0 step 2 train loss 0.5624176 train acc 0.776\n",
            "== Epoch 0 step 3 train loss 0.5319957 train acc 0.796\n",
            "== Epoch 0 step 4 train loss 0.52638525 train acc 0.804\n",
            "== Epoch 0 step 5 train loss 0.50799024 train acc 0.764\n",
            "== Epoch 0 step 6 train loss 0.5599293 train acc 0.748\n",
            "== Epoch 0 step 7 train loss 0.5411828 train acc 0.728\n",
            "== Epoch 0 step 8 train loss 0.5661439 train acc 0.756\n",
            "== Epoch 0 step 9 train loss 0.5504502 train acc 0.772\n",
            "== Epoch 0 step 10 train loss 0.51278675 train acc 0.784\n",
            "== Epoch 0 step 11 train loss 0.52607214 train acc 0.796\n",
            "== Epoch 0 step 12 train loss 0.53518665 train acc 0.752\n",
            "== Epoch 0 step 13 train loss 0.53201914 train acc 0.76\n",
            "== Epoch 0 step 14 train loss 0.49667522 train acc 0.82\n",
            "== Epoch 0 step 15 train loss 0.53861886 train acc 0.744\n",
            "== Epoch 0 step 16 train loss 0.5011036 train acc 0.792\n",
            "== Epoch 0 step 17 train loss 0.5449018 train acc 0.748\n",
            "== Epoch 0 step 18 train loss 0.55498534 train acc 0.796\n",
            "== Epoch 0 step 19 train loss 0.5575886 train acc 0.72\n",
            "val acc 0.6686046511627907\n",
            "val loss 0.6177036\n",
            "No improvement over previous best loss:  0.61758953\n",
            "== Epoch 1 step 0 train loss 0.5424674 train acc 0.792\n",
            "== Epoch 1 step 1 train loss 0.5504391 train acc 0.716\n",
            "== Epoch 1 step 2 train loss 0.54108864 train acc 0.776\n",
            "== Epoch 1 step 3 train loss 0.52090126 train acc 0.796\n",
            "== Epoch 1 step 4 train loss 0.5251758 train acc 0.804\n",
            "== Epoch 1 step 5 train loss 0.53780943 train acc 0.764\n",
            "== Epoch 1 step 6 train loss 0.5536071 train acc 0.748\n",
            "== Epoch 1 step 7 train loss 0.5366404 train acc 0.728\n",
            "== Epoch 1 step 8 train loss 0.55164075 train acc 0.756\n",
            "== Epoch 1 step 9 train loss 0.54698235 train acc 0.772\n",
            "== Epoch 1 step 10 train loss 0.50513387 train acc 0.784\n",
            "== Epoch 1 step 11 train loss 0.5253084 train acc 0.796\n",
            "== Epoch 1 step 12 train loss 0.5561571 train acc 0.752\n",
            "== Epoch 1 step 13 train loss 0.5457042 train acc 0.76\n",
            "== Epoch 1 step 14 train loss 0.511325 train acc 0.824\n",
            "== Epoch 1 step 15 train loss 0.5481233 train acc 0.744\n",
            "== Epoch 1 step 16 train loss 0.5068189 train acc 0.792\n",
            "== Epoch 1 step 17 train loss 0.5426493 train acc 0.748\n",
            "== Epoch 1 step 18 train loss 0.5409826 train acc 0.796\n",
            "== Epoch 1 step 19 train loss 0.5608683 train acc 0.72\n",
            "val acc 0.6686046511627907\n",
            "val loss 0.6178319\n",
            "No improvement over previous best loss:  0.61758953\n",
            "== Epoch 2 step 0 train loss 0.52034646 train acc 0.792\n",
            "== Epoch 2 step 1 train loss 0.55066013 train acc 0.716\n",
            "== Epoch 2 step 2 train loss 0.5570426 train acc 0.776\n",
            "== Epoch 2 step 3 train loss 0.52544445 train acc 0.796\n",
            "== Epoch 2 step 4 train loss 0.5416872 train acc 0.804\n",
            "== Epoch 2 step 5 train loss 0.5138451 train acc 0.764\n",
            "== Epoch 2 step 6 train loss 0.5442702 train acc 0.748\n",
            "== Epoch 2 step 7 train loss 0.53672004 train acc 0.728\n",
            "== Epoch 2 step 8 train loss 0.5684047 train acc 0.756\n",
            "== Epoch 2 step 9 train loss 0.5296891 train acc 0.772\n",
            "== Epoch 2 step 10 train loss 0.51367986 train acc 0.784\n",
            "== Epoch 2 step 11 train loss 0.51381487 train acc 0.796\n",
            "== Epoch 2 step 12 train loss 0.54523426 train acc 0.752\n",
            "== Epoch 2 step 13 train loss 0.53595704 train acc 0.76\n",
            "== Epoch 2 step 14 train loss 0.5118422 train acc 0.824\n",
            "== Epoch 2 step 15 train loss 0.5665234 train acc 0.744\n",
            "== Epoch 2 step 16 train loss 0.49849665 train acc 0.792\n",
            "== Epoch 2 step 17 train loss 0.55240417 train acc 0.748\n",
            "== Epoch 2 step 18 train loss 0.5357211 train acc 0.796\n",
            "== Epoch 2 step 19 train loss 0.5598009 train acc 0.72\n",
            "val acc 0.6744186046511628\n",
            "val loss 0.6179772\n",
            "No improvement over previous best loss:  0.61758953\n",
            "== Epoch 3 step 0 train loss 0.5395063 train acc 0.792\n",
            "== Epoch 3 step 1 train loss 0.5473336 train acc 0.716\n",
            "== Epoch 3 step 2 train loss 0.5447463 train acc 0.776\n",
            "== Epoch 3 step 3 train loss 0.5186564 train acc 0.796\n",
            "== Epoch 3 step 4 train loss 0.5323808 train acc 0.804\n",
            "== Epoch 3 step 5 train loss 0.5177673 train acc 0.764\n",
            "== Epoch 3 step 6 train loss 0.55401057 train acc 0.748\n",
            "== Epoch 3 step 7 train loss 0.5453398 train acc 0.728\n",
            "== Epoch 3 step 8 train loss 0.5478542 train acc 0.756\n",
            "== Epoch 3 step 9 train loss 0.53258216 train acc 0.772\n",
            "== Epoch 3 step 10 train loss 0.51030904 train acc 0.784\n",
            "== Epoch 3 step 11 train loss 0.51715046 train acc 0.796\n",
            "== Epoch 3 step 12 train loss 0.54598683 train acc 0.752\n",
            "== Epoch 3 step 13 train loss 0.5308275 train acc 0.76\n",
            "== Epoch 3 step 14 train loss 0.49318904 train acc 0.824\n",
            "== Epoch 3 step 15 train loss 0.5482909 train acc 0.744\n",
            "== Epoch 3 step 16 train loss 0.51005834 train acc 0.792\n",
            "== Epoch 3 step 17 train loss 0.53879136 train acc 0.748\n",
            "== Epoch 3 step 18 train loss 0.53561586 train acc 0.796\n",
            "== Epoch 3 step 19 train loss 0.56405485 train acc 0.72\n",
            "val acc 0.6744186046511628\n",
            "val loss 0.6181084\n",
            "No improvement over previous best loss:  0.61758953\n",
            "== Epoch 4 step 0 train loss 0.5290992 train acc 0.792\n",
            "== Epoch 4 step 1 train loss 0.5621444 train acc 0.716\n",
            "== Epoch 4 step 2 train loss 0.54090464 train acc 0.776\n",
            "== Epoch 4 step 3 train loss 0.5177712 train acc 0.796\n",
            "== Epoch 4 step 4 train loss 0.5343039 train acc 0.804\n",
            "== Epoch 4 step 5 train loss 0.50788826 train acc 0.764\n",
            "== Epoch 4 step 6 train loss 0.52997303 train acc 0.748\n",
            "== Epoch 4 step 7 train loss 0.5579609 train acc 0.728\n",
            "== Epoch 4 step 8 train loss 0.5330066 train acc 0.756\n",
            "== Epoch 4 step 9 train loss 0.5407714 train acc 0.772\n",
            "== Epoch 4 step 10 train loss 0.5175016 train acc 0.784\n",
            "== Epoch 4 step 11 train loss 0.5203639 train acc 0.796\n",
            "== Epoch 4 step 12 train loss 0.5544662 train acc 0.752\n",
            "== Epoch 4 step 13 train loss 0.5340049 train acc 0.76\n",
            "== Epoch 4 step 14 train loss 0.51409715 train acc 0.824\n",
            "== Epoch 4 step 15 train loss 0.54236907 train acc 0.744\n",
            "== Epoch 4 step 16 train loss 0.52109945 train acc 0.792\n",
            "== Epoch 4 step 17 train loss 0.55686086 train acc 0.748\n",
            "== Epoch 4 step 18 train loss 0.5270283 train acc 0.796\n",
            "== Epoch 4 step 19 train loss 0.55712205 train acc 0.72\n",
            "val acc 0.6744186046511628\n",
            "val loss 0.6182441\n",
            "No improvement over previous best loss:  0.61758953\n",
            "Finetuning all layers\n",
            "original val loss 0.61758953\n",
            "== Epoch 0 step 0 train loss 0.54050595 train acc 0.792\n",
            "== Epoch 0 step 1 train loss 0.55579484 train acc 0.72\n",
            "== Epoch 0 step 2 train loss 0.55565137 train acc 0.78\n",
            "== Epoch 0 step 3 train loss 0.5303294 train acc 0.804\n",
            "== Epoch 0 step 4 train loss 0.52855265 train acc 0.804\n",
            "== Epoch 0 step 5 train loss 0.5124663 train acc 0.772\n",
            "== Epoch 0 step 6 train loss 0.55502915 train acc 0.756\n",
            "== Epoch 0 step 7 train loss 0.5290899 train acc 0.736\n",
            "== Epoch 0 step 8 train loss 0.5282714 train acc 0.768\n",
            "== Epoch 0 step 9 train loss 0.5292363 train acc 0.792\n",
            "== Epoch 0 step 10 train loss 0.510093 train acc 0.796\n",
            "== Epoch 0 step 11 train loss 0.519508 train acc 0.796\n",
            "== Epoch 0 step 12 train loss 0.53297126 train acc 0.764\n",
            "== Epoch 0 step 13 train loss 0.5154389 train acc 0.788\n",
            "== Epoch 0 step 14 train loss 0.48810625 train acc 0.832\n",
            "== Epoch 0 step 15 train loss 0.54337937 train acc 0.776\n",
            "== Epoch 0 step 16 train loss 0.50820994 train acc 0.804\n",
            "== Epoch 0 step 17 train loss 0.54056543 train acc 0.78\n",
            "== Epoch 0 step 18 train loss 0.53896904 train acc 0.812\n",
            "== Epoch 0 step 19 train loss 0.53525037 train acc 0.736\n",
            "val acc 0.6627906976744186\n",
            "val loss 0.6187363\n",
            "No improvement over previous best loss:  0.61758953\n",
            "== Epoch 1 step 0 train loss 0.4820606 train acc 0.808\n",
            "== Epoch 1 step 1 train loss 0.51101243 train acc 0.796\n",
            "== Epoch 1 step 2 train loss 0.51485467 train acc 0.82\n",
            "== Epoch 1 step 3 train loss 0.46551573 train acc 0.844\n",
            "== Epoch 1 step 4 train loss 0.506157 train acc 0.836\n",
            "== Epoch 1 step 5 train loss 0.48407444 train acc 0.8\n",
            "== Epoch 1 step 6 train loss 0.49293035 train acc 0.796\n",
            "== Epoch 1 step 7 train loss 0.49488342 train acc 0.796\n",
            "== Epoch 1 step 8 train loss 0.5096075 train acc 0.824\n",
            "== Epoch 1 step 9 train loss 0.5028583 train acc 0.82\n",
            "== Epoch 1 step 10 train loss 0.46293512 train acc 0.844\n",
            "== Epoch 1 step 11 train loss 0.47719356 train acc 0.832\n",
            "== Epoch 1 step 12 train loss 0.509901 train acc 0.804\n",
            "== Epoch 1 step 13 train loss 0.4881724 train acc 0.82\n",
            "== Epoch 1 step 14 train loss 0.46241418 train acc 0.868\n",
            "== Epoch 1 step 15 train loss 0.49196357 train acc 0.824\n",
            "== Epoch 1 step 16 train loss 0.4762759 train acc 0.84\n",
            "== Epoch 1 step 17 train loss 0.5000967 train acc 0.82\n",
            "== Epoch 1 step 18 train loss 0.4856211 train acc 0.828\n",
            "== Epoch 1 step 19 train loss 0.50838983 train acc 0.788\n",
            "val acc 0.6686046511627907\n",
            "val loss 0.6209595\n",
            "No improvement over previous best loss:  0.61758953\n",
            "== Epoch 2 step 0 train loss 0.46599403 train acc 0.84\n",
            "== Epoch 2 step 1 train loss 0.482891 train acc 0.832\n",
            "== Epoch 2 step 2 train loss 0.47818658 train acc 0.868\n",
            "== Epoch 2 step 3 train loss 0.45494416 train acc 0.868\n",
            "== Epoch 2 step 4 train loss 0.47085568 train acc 0.864\n",
            "== Epoch 2 step 5 train loss 0.46841377 train acc 0.844\n",
            "== Epoch 2 step 6 train loss 0.4830733 train acc 0.844\n",
            "== Epoch 2 step 7 train loss 0.46801656 train acc 0.836\n",
            "== Epoch 2 step 8 train loss 0.46694225 train acc 0.864\n",
            "== Epoch 2 step 9 train loss 0.46994144 train acc 0.872\n",
            "== Epoch 2 step 10 train loss 0.44272158 train acc 0.868\n",
            "== Epoch 2 step 11 train loss 0.43511915 train acc 0.872\n",
            "== Epoch 2 step 12 train loss 0.48780915 train acc 0.84\n",
            "== Epoch 2 step 13 train loss 0.46127415 train acc 0.848\n",
            "== Epoch 2 step 14 train loss 0.42739058 train acc 0.9\n",
            "== Epoch 2 step 15 train loss 0.48546362 train acc 0.856\n",
            "== Epoch 2 step 16 train loss 0.4399036 train acc 0.884\n",
            "== Epoch 2 step 17 train loss 0.47101676 train acc 0.852\n",
            "== Epoch 2 step 18 train loss 0.44402483 train acc 0.868\n",
            "== Epoch 2 step 19 train loss 0.45795137 train acc 0.852\n",
            "val acc 0.6686046511627907\n",
            "val loss 0.6243145\n",
            "No improvement over previous best loss:  0.61758953\n",
            "== Epoch 3 step 0 train loss 0.44773754 train acc 0.848\n",
            "== Epoch 3 step 1 train loss 0.45930997 train acc 0.88\n",
            "== Epoch 3 step 2 train loss 0.44679987 train acc 0.904\n",
            "== Epoch 3 step 3 train loss 0.4182843 train acc 0.904\n",
            "== Epoch 3 step 4 train loss 0.43251964 train acc 0.884\n",
            "== Epoch 3 step 5 train loss 0.4252559 train acc 0.884\n",
            "== Epoch 3 step 6 train loss 0.42314738 train acc 0.856\n",
            "== Epoch 3 step 7 train loss 0.4549737 train acc 0.876\n",
            "== Epoch 3 step 8 train loss 0.42562163 train acc 0.884\n",
            "== Epoch 3 step 9 train loss 0.4299836 train acc 0.892\n",
            "== Epoch 3 step 10 train loss 0.42148802 train acc 0.904\n",
            "== Epoch 3 step 11 train loss 0.41302353 train acc 0.888\n",
            "== Epoch 3 step 12 train loss 0.4240887 train acc 0.872\n",
            "== Epoch 3 step 13 train loss 0.4303342 train acc 0.868\n",
            "== Epoch 3 step 14 train loss 0.39638817 train acc 0.912\n",
            "== Epoch 3 step 15 train loss 0.4414298 train acc 0.876\n",
            "== Epoch 3 step 16 train loss 0.39740315 train acc 0.9\n",
            "== Epoch 3 step 17 train loss 0.41817343 train acc 0.876\n",
            "== Epoch 3 step 18 train loss 0.4265598 train acc 0.912\n",
            "== Epoch 3 step 19 train loss 0.44202083 train acc 0.864\n",
            "val acc 0.6627906976744186\n",
            "val loss 0.6289212\n",
            "No improvement over previous best loss:  0.61758953\n",
            "== Epoch 4 step 0 train loss 0.3990448 train acc 0.884\n",
            "== Epoch 4 step 1 train loss 0.42867306 train acc 0.9\n",
            "== Epoch 4 step 2 train loss 0.40721473 train acc 0.924\n",
            "== Epoch 4 step 3 train loss 0.3745871 train acc 0.928\n",
            "== Epoch 4 step 4 train loss 0.41636226 train acc 0.924\n",
            "== Epoch 4 step 5 train loss 0.38255224 train acc 0.9\n",
            "== Epoch 4 step 6 train loss 0.40746295 train acc 0.876\n",
            "== Epoch 4 step 7 train loss 0.39378464 train acc 0.908\n",
            "== Epoch 4 step 8 train loss 0.39699212 train acc 0.904\n",
            "== Epoch 4 step 9 train loss 0.3869352 train acc 0.912\n",
            "== Epoch 4 step 10 train loss 0.366312 train acc 0.924\n",
            "== Epoch 4 step 11 train loss 0.3674433 train acc 0.92\n",
            "== Epoch 4 step 12 train loss 0.3849915 train acc 0.908\n",
            "== Epoch 4 step 13 train loss 0.38565484 train acc 0.896\n",
            "== Epoch 4 step 14 train loss 0.35382503 train acc 0.928\n",
            "== Epoch 4 step 15 train loss 0.41810855 train acc 0.9\n",
            "== Epoch 4 step 16 train loss 0.35353377 train acc 0.924\n",
            "== Epoch 4 step 17 train loss 0.40019915 train acc 0.9\n",
            "== Epoch 4 step 18 train loss 0.3791521 train acc 0.924\n",
            "== Epoch 4 step 19 train loss 0.40379006 train acc 0.9\n",
            "val acc 0.6569767441860465\n",
            "val loss 0.6352817\n",
            "No improvement over previous best loss:  0.61758953\n",
            "Acc: 0.6686046511627907\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive',force_remount=True)"
      ],
      "metadata": {
        "id": "5ybjzTvNHUUI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d7afafd-c358-40f9-da19-8072db73b529"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    }
  ]
}