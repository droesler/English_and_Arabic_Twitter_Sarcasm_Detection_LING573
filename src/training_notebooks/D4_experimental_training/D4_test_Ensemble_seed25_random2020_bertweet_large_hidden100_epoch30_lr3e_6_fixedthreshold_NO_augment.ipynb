{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "D4_test_Ensemble_seed25_random2020_bertweet_large_hidden100_epoch30_lr3e_6_fixedthreshold_NO_augment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "69c398c685bd422ba234f46285a1a112": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_94dfb46f7e2a496d8fa4e886e42aaa52",
              "IPY_MODEL_097af6d22dc444728fb5cc35da5496ee",
              "IPY_MODEL_291788e9aa244c36bf1f9c2af4922e16"
            ],
            "layout": "IPY_MODEL_9c13d908777f4a8a91fea12db7c18428"
          }
        },
        "94dfb46f7e2a496d8fa4e886e42aaa52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33b29c185a684b479c2dd2fc06cb242f",
            "placeholder": "​",
            "style": "IPY_MODEL_11a5e45afa6542248255021c51bd568e",
            "value": "Downloading: 100%"
          }
        },
        "097af6d22dc444728fb5cc35da5496ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa7a7d70740741f7bdccf8967e44eb80",
            "max": 614,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_deb35564672b4d9e80f1092e4c726975",
            "value": 614
          }
        },
        "291788e9aa244c36bf1f9c2af4922e16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_250f7fb7652d4077940f30440495ca89",
            "placeholder": "​",
            "style": "IPY_MODEL_abc8a9499a2a49b4b6ed6684f79c1a6b",
            "value": " 614/614 [00:00&lt;00:00, 10.4kB/s]"
          }
        },
        "9c13d908777f4a8a91fea12db7c18428": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33b29c185a684b479c2dd2fc06cb242f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11a5e45afa6542248255021c51bd568e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa7a7d70740741f7bdccf8967e44eb80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "deb35564672b4d9e80f1092e4c726975": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "250f7fb7652d4077940f30440495ca89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abc8a9499a2a49b4b6ed6684f79c1a6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c613fe376d224674a7e66dae20df0a16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ecd11980aa704d3cb9d65c2499040af1",
              "IPY_MODEL_aa8d4553d3624f46be82dd213e27eebc",
              "IPY_MODEL_2858d2a1786143b3b3b0793b753e42e8"
            ],
            "layout": "IPY_MODEL_f761f5c8f1634ad89aa5b386ea00f677"
          }
        },
        "ecd11980aa704d3cb9d65c2499040af1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b26c4ca9304c4096a43d102d5770313e",
            "placeholder": "​",
            "style": "IPY_MODEL_e7253c2bfc3a4d14b345995d48713720",
            "value": "Downloading: 100%"
          }
        },
        "aa8d4553d3624f46be82dd213e27eebc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8126b909bb324a47b4229920bf6657d2",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_25b9e9c0cbcf4b6fbf0f2bbbe92bf171",
            "value": 898823
          }
        },
        "2858d2a1786143b3b3b0793b753e42e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9dc1ac7af7784e65a9700e1e04a31d8f",
            "placeholder": "​",
            "style": "IPY_MODEL_ef8be7c200414820b7e94ce7909ba40a",
            "value": " 878k/878k [00:00&lt;00:00, 2.57MB/s]"
          }
        },
        "f761f5c8f1634ad89aa5b386ea00f677": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b26c4ca9304c4096a43d102d5770313e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7253c2bfc3a4d14b345995d48713720": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8126b909bb324a47b4229920bf6657d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25b9e9c0cbcf4b6fbf0f2bbbe92bf171": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9dc1ac7af7784e65a9700e1e04a31d8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef8be7c200414820b7e94ce7909ba40a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ccb90dabcdbd4d24ba12b688167af4ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7d777ab9689c4f7cb9e497b8e8c1de31",
              "IPY_MODEL_99f05422fb524d0597ea0ebd86f46917",
              "IPY_MODEL_e00e02590c02490e99b7669f4091bc43"
            ],
            "layout": "IPY_MODEL_33a8877eb5d14ffb938040bbbcbae9d6"
          }
        },
        "7d777ab9689c4f7cb9e497b8e8c1de31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91e5bed92c474c00a3dbac5191322278",
            "placeholder": "​",
            "style": "IPY_MODEL_72c9c6c2e06b4f6494f5faad4e989138",
            "value": "Downloading: 100%"
          }
        },
        "99f05422fb524d0597ea0ebd86f46917": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c0f674b7ab04262b0b546d44d529d1c",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_115c00ef6ffa4624b95275e7d258e71a",
            "value": 456318
          }
        },
        "e00e02590c02490e99b7669f4091bc43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01ed50018e2a41468a001f5471118f7c",
            "placeholder": "​",
            "style": "IPY_MODEL_67e5811320d04049a185e92f9e71af5a",
            "value": " 446k/446k [00:00&lt;00:00, 4.71MB/s]"
          }
        },
        "33a8877eb5d14ffb938040bbbcbae9d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91e5bed92c474c00a3dbac5191322278": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72c9c6c2e06b4f6494f5faad4e989138": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c0f674b7ab04262b0b546d44d529d1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "115c00ef6ffa4624b95275e7d258e71a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "01ed50018e2a41468a001f5471118f7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67e5811320d04049a185e92f9e71af5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "adf69052d0914a36a891ce67bf9fb3da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fac69e84bb8f4ef19d5aabf63899db43",
              "IPY_MODEL_9c6811421207412eb3d7f79750440e2d",
              "IPY_MODEL_4a26272a605f42b5b494a5e1b876292f"
            ],
            "layout": "IPY_MODEL_c4cd679887b54535b57e421a79508ec2"
          }
        },
        "fac69e84bb8f4ef19d5aabf63899db43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b815ba354358480a8b300e15ab722fbe",
            "placeholder": "​",
            "style": "IPY_MODEL_4db505f748584be6aed8c4a6cab1b4bb",
            "value": "Downloading: 100%"
          }
        },
        "9c6811421207412eb3d7f79750440e2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98ac42dc45a74f2d9956295961a46c29",
            "max": 1422008553,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_88a61e2b0433495291e041e0f58da880",
            "value": 1422008553
          }
        },
        "4a26272a605f42b5b494a5e1b876292f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d45a3c2ada4646de85675a0fb7ca7aa1",
            "placeholder": "​",
            "style": "IPY_MODEL_2d11fc24e7c34329857ad9b9b04dfe2b",
            "value": " 1.32G/1.32G [00:33&lt;00:00, 43.7MB/s]"
          }
        },
        "c4cd679887b54535b57e421a79508ec2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b815ba354358480a8b300e15ab722fbe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4db505f748584be6aed8c4a6cab1b4bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "98ac42dc45a74f2d9956295961a46c29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88a61e2b0433495291e041e0f58da880": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d45a3c2ada4646de85675a0fb7ca7aa1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d11fc24e7c34329857ad9b9b04dfe2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# BERTweet fine-tuned + Torchmoji fusion classifier for sarcasm detection\n",
        "\n",
        "Based on the notebook: https://chriskhanhtran.github.io/_posts/2019-12-25-bert-for-sentiment-analysis/"
      ],
      "metadata": {
        "id": "bIffiNzWb22r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fish for target GPU\n",
        "\n",
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():       \n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
        "    print('Device name:', torch.cuda.get_device_name(0))\n",
        "\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQw1h9VloVJW",
        "outputId": "09cf3404-9f58-4ad2-fc84-044e566cbcc6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "Device name: Tesla P100-PCIE-16GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installs"
      ],
      "metadata": {
        "id": "6mhPadkqcpXd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install emoji==0.6.0\n",
        "!pip install numpy==1.21.5\n",
        "!pip install torch==1.10.0+cu111 torchvision==0.11.0+cu111 torchaudio==0.10.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip install scipy==1.5.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tHNV0tLpbuYS",
        "outputId": "6471e4ed-aca7-44f5-c6e0-3bdb64e29e1a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.19.2-py3-none-any.whl (4.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.6.0-py3-none-any.whl (84 kB)\n",
            "\u001b[K     |████████████████████████████████| 84 kB 2.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 46.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 38.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.6.0 pyyaml-6.0 tokenizers-0.12.1 transformers-4.19.2\n",
            "Collecting emoji==0.6.0\n",
            "  Downloading emoji-0.6.0.tar.gz (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 3.2 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-0.6.0-py3-none-any.whl size=49734 sha256=5ae7b07d669139e3fc88082a00b9c52eeae16a1f31bd7b9f354c81af48312607\n",
            "  Stored in directory: /root/.cache/pip/wheels/4e/bf/6b/2e22b3708d14bf6384f862db539b044d6931bd6b14ad3c9adc\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji\n",
            "Successfully installed emoji-0.6.0\n",
            "Collecting numpy==1.21.5\n",
            "  Downloading numpy-1.21.5-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.7 MB 5.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0+zzzcolab20220506162203 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed numpy-1.21.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.10.0+cu111\n",
            "  Downloading https://download.pytorch.org/whl/cu111/torch-1.10.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (2137.6 MB)\n",
            "\u001b[K     |████████████▌                   | 834.1 MB 85.2 MB/s eta 0:00:16tcmalloc: large alloc 1147494400 bytes == 0x39aba000 @  0x7f909399a615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n",
            "\u001b[K     |███████████████▉                | 1055.7 MB 1.3 MB/s eta 0:13:33tcmalloc: large alloc 1434370048 bytes == 0x7e110000 @  0x7f909399a615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n",
            "\u001b[K     |████████████████████            | 1336.2 MB 38.1 MB/s eta 0:00:22tcmalloc: large alloc 1792966656 bytes == 0x2f42000 @  0x7f909399a615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n",
            "\u001b[K     |█████████████████████████▎      | 1691.1 MB 81.3 MB/s eta 0:00:06tcmalloc: large alloc 2241208320 bytes == 0x6dd2a000 @  0x7f909399a615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n",
            "\u001b[K     |████████████████████████████████| 2137.6 MB 40.0 MB/s eta 0:00:01tcmalloc: large alloc 2137645056 bytes == 0xf368c000 @  0x7f90939991e7 0x4a3940 0x4a39cc 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x593dd7 0x511e2c 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x548ae9\n",
            "tcmalloc: large alloc 2672058368 bytes == 0x1e71ae000 @  0x7f909399a615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x593dd7 0x511e2c 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576\n",
            "\u001b[K     |████████████████████████████████| 2137.6 MB 404 bytes/s \n",
            "\u001b[?25hCollecting torchvision==0.11.0+cu111\n",
            "  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.11.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (21.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 21.9 MB 371 kB/s \n",
            "\u001b[?25hCollecting torchaudio==0.10.0\n",
            "  Downloading https://download.pytorch.org/whl/rocm4.1/torchaudio-0.10.0%2Brocm4.1-cp37-cp37m-linux_x86_64.whl (2.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.7 MB 57.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.10.0+cu111) (4.2.0)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.11.0+cu111) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.11.0+cu111) (1.21.5)\n",
            "Installing collected packages: torch, torchvision, torchaudio\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.11.0+cu113\n",
            "    Uninstalling torch-1.11.0+cu113:\n",
            "      Successfully uninstalled torch-1.11.0+cu113\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.12.0+cu113\n",
            "    Uninstalling torchvision-0.12.0+cu113:\n",
            "      Successfully uninstalled torchvision-0.12.0+cu113\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 0.11.0+cu113\n",
            "    Uninstalling torchaudio-0.11.0+cu113:\n",
            "      Successfully uninstalled torchaudio-0.11.0+cu113\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.12.0 requires torch==1.11.0, but you have torch 1.10.0+cu111 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.10.0+cu111 torchaudio-0.10.0+rocm4.1 torchvision-0.11.0+cu111\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scipy==1.5.2\n",
            "  Downloading scipy-1.5.2-cp37-cp37m-manylinux1_x86_64.whl (25.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 25.9 MB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from scipy==1.5.2) (1.21.5)\n",
            "Installing collected packages: scipy\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed scipy-1.5.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Restart the runtime after installs!**"
      ],
      "metadata": {
        "id": "gii2Cl3YraPD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "ROwDbjkKhsnf"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7BiHWYaihMK"
      },
      "source": [
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import random\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import emoji\n",
        "   \n",
        "from sklearn.metrics import precision_recall_curve # NEW\n",
        "\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check GPU for reproducibility"
      ],
      "metadata": {
        "id": "DHT5XWKjbcr9"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VOf1V1ijWYs",
        "outputId": "1b210d85-f174-40d0-fc69-cee5c805462f"
      },
      "source": [
        "# setup GPU\n",
        "if torch.cuda.is_available():       \n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
        "    print('Device name:', torch.cuda.get_device_name(0))\n",
        "\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "Device name: Tesla P100-PCIE-16GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load dataset"
      ],
      "metadata": {
        "id": "dOWFeUqJg30O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = pd.read_csv('/content/balanced_train_En_seed25.csv')\n",
        "training_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "K8qoU-0TRZW3",
        "outputId": "ebcd3229-d3b6-4a31-a4fe-74ad5f3d15a4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Unnamed: 0  Unnamed: 0.1  \\\n",
              "0           1689          1689   \n",
              "1            501           501   \n",
              "2            646           646   \n",
              "3            683           683   \n",
              "4           1735          1735   \n",
              "...          ...           ...   \n",
              "1557        1767          1767   \n",
              "1558         159           159   \n",
              "1559         529           529   \n",
              "1560         357           357   \n",
              "1561        1500          1500   \n",
              "\n",
              "                                                  tweet  sarcastic  \\\n",
              "0     I can't count the amount of times over the yea...          0   \n",
              "1     @MarkHendyHR Only joking... keep it real. HR p...          1   \n",
              "2     I like making food and then not eating it to a...          1   \n",
              "3     @OldUnclePunch Yes, because we really have tha...          1   \n",
              "4     I finished my MBio in Biomedical science this ...          0   \n",
              "...                                                 ...        ...   \n",
              "1557  my greatest downfall is having an upset stomac...          0   \n",
              "1558  Just getting some WD40 on my letter box to hel...          1   \n",
              "1559          do i like him or is his hair just curly??          1   \n",
              "1560      No joke, air-fried Twisted Teas are THE BEST.          1   \n",
              "1561  Looking at my bank account wondering where all...          0   \n",
              "\n",
              "                                               rephrase  sarcasm  irony  \\\n",
              "0                                                   NaN      NaN    NaN   \n",
              "1     Only joking. Keep it real. HR professionals do...      1.0    0.0   \n",
              "2       I hate when I make food and then don't eat it.       1.0    0.0   \n",
              "3       We don’t have any influence to those in power.       1.0    0.0   \n",
              "4                                                   NaN      NaN    NaN   \n",
              "...                                                 ...      ...    ...   \n",
              "1557                                                NaN      NaN    NaN   \n",
              "1558  Fed up of seeing forced romance, don't be told...      0.0    1.0   \n",
              "1559            People with curly hair are attractive.       1.0    0.0   \n",
              "1560                         Twisted Teas are the best.      0.0    1.0   \n",
              "1561                                                NaN      NaN    NaN   \n",
              "\n",
              "      satire  understatement  overstatement  rhetorical_question  \n",
              "0        NaN             NaN            NaN                  NaN  \n",
              "1        0.0             0.0            0.0                  0.0  \n",
              "2        0.0             0.0            0.0                  0.0  \n",
              "3        0.0             0.0            0.0                  0.0  \n",
              "4        NaN             NaN            NaN                  NaN  \n",
              "...      ...             ...            ...                  ...  \n",
              "1557     NaN             NaN            NaN                  NaN  \n",
              "1558     0.0             0.0            0.0                  0.0  \n",
              "1559     0.0             0.0            0.0                  0.0  \n",
              "1560     0.0             0.0            0.0                  0.0  \n",
              "1561     NaN             NaN            NaN                  NaN  \n",
              "\n",
              "[1562 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-df94fbdd-1612-44c8-9a72-a35e4554d2e4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>tweet</th>\n",
              "      <th>sarcastic</th>\n",
              "      <th>rephrase</th>\n",
              "      <th>sarcasm</th>\n",
              "      <th>irony</th>\n",
              "      <th>satire</th>\n",
              "      <th>understatement</th>\n",
              "      <th>overstatement</th>\n",
              "      <th>rhetorical_question</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1689</td>\n",
              "      <td>1689</td>\n",
              "      <td>I can't count the amount of times over the yea...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>501</td>\n",
              "      <td>501</td>\n",
              "      <td>@MarkHendyHR Only joking... keep it real. HR p...</td>\n",
              "      <td>1</td>\n",
              "      <td>Only joking. Keep it real. HR professionals do...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>646</td>\n",
              "      <td>646</td>\n",
              "      <td>I like making food and then not eating it to a...</td>\n",
              "      <td>1</td>\n",
              "      <td>I hate when I make food and then don't eat it.</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>683</td>\n",
              "      <td>683</td>\n",
              "      <td>@OldUnclePunch Yes, because we really have tha...</td>\n",
              "      <td>1</td>\n",
              "      <td>We don’t have any influence to those in power.</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1735</td>\n",
              "      <td>1735</td>\n",
              "      <td>I finished my MBio in Biomedical science this ...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1557</th>\n",
              "      <td>1767</td>\n",
              "      <td>1767</td>\n",
              "      <td>my greatest downfall is having an upset stomac...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1558</th>\n",
              "      <td>159</td>\n",
              "      <td>159</td>\n",
              "      <td>Just getting some WD40 on my letter box to hel...</td>\n",
              "      <td>1</td>\n",
              "      <td>Fed up of seeing forced romance, don't be told...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1559</th>\n",
              "      <td>529</td>\n",
              "      <td>529</td>\n",
              "      <td>do i like him or is his hair just curly??</td>\n",
              "      <td>1</td>\n",
              "      <td>People with curly hair are attractive.</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1560</th>\n",
              "      <td>357</td>\n",
              "      <td>357</td>\n",
              "      <td>No joke, air-fried Twisted Teas are THE BEST.</td>\n",
              "      <td>1</td>\n",
              "      <td>Twisted Teas are the best.</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1561</th>\n",
              "      <td>1500</td>\n",
              "      <td>1500</td>\n",
              "      <td>Looking at my bank account wondering where all...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1562 rows × 11 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-df94fbdd-1612-44c8-9a72-a35e4554d2e4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-df94fbdd-1612-44c8-9a72-a35e4554d2e4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-df94fbdd-1612-44c8-9a72-a35e4554d2e4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "positive_augment_training_data = pd.read_csv('/content/sarcastic_all_no_hashtags.csv', lineterminator='\\n')\n",
        "positive_augment_training_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "6VXwmgNwIWH4",
        "outputId": "85e8fb15-50cc-4ce3-f096-014b1d31043e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Unnamed: 0 Unnamed: 0.1  \\\n",
              "0               0            0   \n",
              "1               1            1   \n",
              "2               2            2   \n",
              "3               3            3   \n",
              "4               4            4   \n",
              "...           ...          ...   \n",
              "28023       28023        28006   \n",
              "28024       28024        28007   \n",
              "28025       28025        28008   \n",
              "28026       28026        28009   \n",
              "28027       28027        28010   \n",
              "\n",
              "                                                   tweet  label  \n",
              "0      @cityofdenver, been driving/sliding all around...      1  \n",
              "1      This. This is the news that matters: http://t....      1  \n",
              "2      @empressivegeek LOL, you guys are lawyers righ...      1  \n",
              "3      The start of another super busy week. So pumped.       1  \n",
              "4      I'm gonna start knitting again.. Because it's ...      1  \n",
              "...                                                  ...    ...  \n",
              "28023  @dangainor @SuePendleton2 @piersmorgan pahahah...      1  \n",
              "28024  @jennapoole11 wait till the game at White Hous...      1  \n",
              "28025  Well well I didn't know it was snowing with al...      1  \n",
              "28026  Just want to thank all of my friends for showi...      1  \n",
              "28027  What are these bowls I see popping up in my fe...      1  \n",
              "\n",
              "[28028 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d472b130-eaf7-4ded-bfce-a03e96919da9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>@cityofdenver, been driving/sliding all around...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>This. This is the news that matters: http://t....</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>@empressivegeek LOL, you guys are lawyers righ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>The start of another super busy week. So pumped.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>I'm gonna start knitting again.. Because it's ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28023</th>\n",
              "      <td>28023</td>\n",
              "      <td>28006</td>\n",
              "      <td>@dangainor @SuePendleton2 @piersmorgan pahahah...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28024</th>\n",
              "      <td>28024</td>\n",
              "      <td>28007</td>\n",
              "      <td>@jennapoole11 wait till the game at White Hous...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28025</th>\n",
              "      <td>28025</td>\n",
              "      <td>28008</td>\n",
              "      <td>Well well I didn't know it was snowing with al...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28026</th>\n",
              "      <td>28026</td>\n",
              "      <td>28009</td>\n",
              "      <td>Just want to thank all of my friends for showi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28027</th>\n",
              "      <td>28027</td>\n",
              "      <td>28010</td>\n",
              "      <td>What are these bowls I see popping up in my fe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>28028 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d472b130-eaf7-4ded-bfce-a03e96919da9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d472b130-eaf7-4ded-bfce-a03e96919da9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d472b130-eaf7-4ded-bfce-a03e96919da9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "negative_augment_training_data = pd.read_csv('/content/negative_all.csv', lineterminator='\\n')\n",
        "negative_augment_training_data"
      ],
      "metadata": {
        "id": "C49HZKHAIyj_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "03a254ad-f336-4f20-e03a-e5aeb5def1e5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Unnamed: 0  Unnamed: 0.1  \\\n",
              "0               0             0   \n",
              "1               1             1   \n",
              "2               2             2   \n",
              "3               3             3   \n",
              "4               4             4   \n",
              "...           ...           ...   \n",
              "31747       31747         31747   \n",
              "31748       31748         31748   \n",
              "31749       31749         31749   \n",
              "31750       31750         31750   \n",
              "31751       31751         31751   \n",
              "\n",
              "                                                   tweet  label  \n",
              "0      @ChrisGreenBean I thought you speak about a gu...      0  \n",
              "1      fancis moves into a different plane at age 32 ...      0  \n",
              "2      Elmer http://t.co/u8nP9vqu3Z via @comiXology O...      0  \n",
              "3      [needrestart] https://t.co/HlZA2TDymo Thomas L...      0  \n",
              "4      Webinar with Landatel for Spanish customers - ...      0  \n",
              "...                                                  ...    ...  \n",
              "31747  @blingyeol we should! That'd be awesome :'3 I ...      0  \n",
              "31748  The Polaroid iM1836 copycat camera is now gone...      0  \n",
              "31749  Woke up around 9, 20 min later smoke like is t...      0  \n",
              "31750  Czech glass beads handmade shamballa bracelet ...      0  \n",
              "31751  My small christmas tree #christmas #navidad #t...      0  \n",
              "\n",
              "[31752 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9e00e6d7-c693-4e74-92b2-8fe432f68262\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>@ChrisGreenBean I thought you speak about a gu...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>fancis moves into a different plane at age 32 ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>Elmer http://t.co/u8nP9vqu3Z via @comiXology O...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>[needrestart] https://t.co/HlZA2TDymo Thomas L...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>Webinar with Landatel for Spanish customers - ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31747</th>\n",
              "      <td>31747</td>\n",
              "      <td>31747</td>\n",
              "      <td>@blingyeol we should! That'd be awesome :'3 I ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31748</th>\n",
              "      <td>31748</td>\n",
              "      <td>31748</td>\n",
              "      <td>The Polaroid iM1836 copycat camera is now gone...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31749</th>\n",
              "      <td>31749</td>\n",
              "      <td>31749</td>\n",
              "      <td>Woke up around 9, 20 min later smoke like is t...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31750</th>\n",
              "      <td>31750</td>\n",
              "      <td>31750</td>\n",
              "      <td>Czech glass beads handmade shamballa bracelet ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31751</th>\n",
              "      <td>31751</td>\n",
              "      <td>31751</td>\n",
              "      <td>My small christmas tree #christmas #navidad #t...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>31752 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9e00e6d7-c693-4e74-92b2-8fe432f68262')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9e00e6d7-c693-4e74-92b2-8fe432f68262 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9e00e6d7-c693-4e74-92b2-8fe432f68262');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validation_data = pd.read_csv('/content/balanced_validation_En_seed25.csv')\n",
        "validation_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "GB5iColL4hTw",
        "outputId": "31700b8c-17d8-47d2-da35-a8c6421589b0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Unnamed: 0  Unnamed: 0.1  \\\n",
              "0          2932          2932   \n",
              "1             6             6   \n",
              "2          1069          1069   \n",
              "3           598           598   \n",
              "4           183           183   \n",
              "..          ...           ...   \n",
              "167        1132          1132   \n",
              "168          92            92   \n",
              "169        1762          1762   \n",
              "170         299           299   \n",
              "171        2622          2622   \n",
              "\n",
              "                                                 tweet  sarcastic  \\\n",
              "0    At what height in the sky does the Chicago bea...          0   \n",
              "1    Why would Alexa's recipe for Yorkshire pudding...          1   \n",
              "2    I don't remember the last time a Sixers game g...          0   \n",
              "3    I never feel more empowered than when I’m list...          1   \n",
              "4                                  @PlayStationUK Nice          1   \n",
              "..                                                 ...        ...   \n",
              "167   Just had my windows cleaned and I feel posh lmao          0   \n",
              "168                  @rits_meg @freedomsenpai hot loli          1   \n",
              "169  My favorite thing is that literally ONLY my @W...          0   \n",
              "170  Is this first Cybex isokinetic dynamometer? @D...          1   \n",
              "171  Rumors of an October lockdown circulating only...          0   \n",
              "\n",
              "                                              rephrase  sarcasm  irony  \\\n",
              "0                                                  NaN      NaN    NaN   \n",
              "1                              Great recipe from Alexa      0.0    1.0   \n",
              "2                                                  NaN      NaN    NaN   \n",
              "3    I never feel more cheesy than when I am listen...      1.0    0.0   \n",
              "4                         These aren't very good games      1.0    0.0   \n",
              "..                                                 ...      ...    ...   \n",
              "167                                                NaN      NaN    NaN   \n",
              "168                     great art, involve rinako-chan      1.0    0.0   \n",
              "169                                                NaN      NaN    NaN   \n",
              "170     That’s an interesting machine. Is it very old?      1.0    0.0   \n",
              "171                                                NaN      NaN    NaN   \n",
              "\n",
              "     satire  understatement  overstatement  rhetorical_question  \n",
              "0       NaN             NaN            NaN                  NaN  \n",
              "1       0.0             0.0            0.0                  1.0  \n",
              "2       NaN             NaN            NaN                  NaN  \n",
              "3       1.0             0.0            0.0                  0.0  \n",
              "4       0.0             0.0            0.0                  0.0  \n",
              "..      ...             ...            ...                  ...  \n",
              "167     NaN             NaN            NaN                  NaN  \n",
              "168     0.0             0.0            0.0                  0.0  \n",
              "169     NaN             NaN            NaN                  NaN  \n",
              "170     0.0             0.0            0.0                  1.0  \n",
              "171     NaN             NaN            NaN                  NaN  \n",
              "\n",
              "[172 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7f3509e1-9476-4c20-b5a9-067dbc964871\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>tweet</th>\n",
              "      <th>sarcastic</th>\n",
              "      <th>rephrase</th>\n",
              "      <th>sarcasm</th>\n",
              "      <th>irony</th>\n",
              "      <th>satire</th>\n",
              "      <th>understatement</th>\n",
              "      <th>overstatement</th>\n",
              "      <th>rhetorical_question</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2932</td>\n",
              "      <td>2932</td>\n",
              "      <td>At what height in the sky does the Chicago bea...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>Why would Alexa's recipe for Yorkshire pudding...</td>\n",
              "      <td>1</td>\n",
              "      <td>Great recipe from Alexa</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1069</td>\n",
              "      <td>1069</td>\n",
              "      <td>I don't remember the last time a Sixers game g...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>598</td>\n",
              "      <td>598</td>\n",
              "      <td>I never feel more empowered than when I’m list...</td>\n",
              "      <td>1</td>\n",
              "      <td>I never feel more cheesy than when I am listen...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>183</td>\n",
              "      <td>183</td>\n",
              "      <td>@PlayStationUK Nice</td>\n",
              "      <td>1</td>\n",
              "      <td>These aren't very good games</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>167</th>\n",
              "      <td>1132</td>\n",
              "      <td>1132</td>\n",
              "      <td>Just had my windows cleaned and I feel posh lmao</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>168</th>\n",
              "      <td>92</td>\n",
              "      <td>92</td>\n",
              "      <td>@rits_meg @freedomsenpai hot loli</td>\n",
              "      <td>1</td>\n",
              "      <td>great art, involve rinako-chan</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>169</th>\n",
              "      <td>1762</td>\n",
              "      <td>1762</td>\n",
              "      <td>My favorite thing is that literally ONLY my @W...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>170</th>\n",
              "      <td>299</td>\n",
              "      <td>299</td>\n",
              "      <td>Is this first Cybex isokinetic dynamometer? @D...</td>\n",
              "      <td>1</td>\n",
              "      <td>That’s an interesting machine. Is it very old?</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>171</th>\n",
              "      <td>2622</td>\n",
              "      <td>2622</td>\n",
              "      <td>Rumors of an October lockdown circulating only...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>172 rows × 11 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7f3509e1-9476-4c20-b5a9-067dbc964871')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7f3509e1-9476-4c20-b5a9-067dbc964871 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7f3509e1-9476-4c20-b5a9-067dbc964871');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = pd.read_csv('/content/task_A_En_test.csv')\n",
        "test_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "Pzn6sz7GC_V_",
        "outputId": "94afeb77-68da-4213-e124-dcee7b8fd096"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   text  sarcastic\n",
              "0     Size on the the Toulouse team, That pack is mo...          0\n",
              "1                                              Pinball!          0\n",
              "2     So the Scottish Government want people to get ...          1\n",
              "3     villainous pro tip : change the device name on...          0\n",
              "4                       I would date any of these men 🥺          0\n",
              "...                                                 ...        ...\n",
              "1395  I’ve just seen this and felt it deserved a Ret...          0\n",
              "1396               Omg how an earth is that a pen !!! 🤡          0\n",
              "1397          Bringing Kanye and drake to a tl near you          0\n",
              "1398  I love it when women are referred to as \"girl ...          1\n",
              "1399  The fact that people still don't get that you ...          1\n",
              "\n",
              "[1400 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9f1eab83-c7d4-41e3-b339-633bc3118395\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>sarcastic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Size on the the Toulouse team, That pack is mo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Pinball!</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>So the Scottish Government want people to get ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>villainous pro tip : change the device name on...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I would date any of these men 🥺</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1395</th>\n",
              "      <td>I’ve just seen this and felt it deserved a Ret...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1396</th>\n",
              "      <td>Omg how an earth is that a pen !!! 🤡</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1397</th>\n",
              "      <td>Bringing Kanye and drake to a tl near you</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1398</th>\n",
              "      <td>I love it when women are referred to as \"girl ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1399</th>\n",
              "      <td>The fact that people still don't get that you ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1400 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9f1eab83-c7d4-41e3-b339-633bc3118395')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9f1eab83-c7d4-41e3-b339-633bc3118395 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9f1eab83-c7d4-41e3-b339-633bc3118395');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set label to use in binary classifcation\n",
        "LABEL_TO_CLASSIFY = 'sarcastic'"
      ],
      "metadata": {
        "id": "0ZihzvZICeNA"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reduce the size of the augmentation data to to make processing faster\n",
        "\n",
        "NUM_TO_SAMPLE = 800\n",
        "\n",
        "sampled_positives = positive_augment_training_data.sample(n=NUM_TO_SAMPLE, random_state=2020)\n",
        "sampled_negatives = negative_augment_training_data.sample(n=NUM_TO_SAMPLE, random_state=2020)\n",
        "\n",
        "augment_training_data = pd.concat([sampled_positives, sampled_negatives]).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "RwIUcZYVK8W9"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_aug_train = augment_training_data['tweet'].astype('str')\n",
        "y_aug_train = augment_training_data['label'].astype('int')"
      ],
      "metadata": {
        "id": "3p4DjmeXI3sI"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get training and validation input(X) and label(y) sets\n",
        "X_train = training_data['tweet']\n",
        "X_val = validation_data['tweet']\n",
        "\n",
        "y_train = training_data[LABEL_TO_CLASSIFY]\n",
        "y_val = validation_data[LABEL_TO_CLASSIFY]\n",
        "\n",
        "# X_train = pd.concat([X_train, X_aug_train]).reset_index(drop=True)\n",
        "# y_train = pd.concat([y_train, y_aug_train]).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "9d4-Y8FX421y"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = test_data['text']\n",
        "y_test = test_data['sarcastic']"
      ],
      "metadata": {
        "id": "h_nl-biSDhaF"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define BERTweet preprocessing\n",
        "BERTweet-large does not have pre-processing built into its huggingface tokenizer, so we have to do it ourselves here. This code is from: https://github.com/VinAIResearch/BERTweet/blob/master/TweetNormalizer.py"
      ],
      "metadata": {
        "id": "6tcmVxBFeM3L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define preprocessing function for BERTweet-large (not needed for base version)\n",
        "\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from emoji import demojize\n",
        "\n",
        "bertweet_preprocessing_tokenizer = TweetTokenizer()\n",
        "\n",
        "def normalizeToken(token):\n",
        "    lowercased_token = token.lower()\n",
        "    if token.startswith(\"@\"):\n",
        "        return \"@USER\"\n",
        "    elif lowercased_token.startswith(\"http\") or lowercased_token.startswith(\"www\"):\n",
        "        return \"HTTPURL\"\n",
        "    elif len(token) == 1:\n",
        "        return demojize(token)\n",
        "    else:\n",
        "        if token == \"’\":\n",
        "            return \"'\"\n",
        "        elif token == \"…\":\n",
        "            return \"...\"\n",
        "        else:\n",
        "            return token\n",
        "\n",
        "def normalizeTweet(tweet):\n",
        "    tokens = bertweet_preprocessing_tokenizer.tokenize(tweet.replace(\"’\", \"'\").replace(\"…\", \"...\"))\n",
        "    normTweet = \" \".join([normalizeToken(token) for token in tokens])\n",
        "\n",
        "    normTweet = (\n",
        "        normTweet.replace(\"cannot \", \"can not \")\n",
        "        .replace(\"n't \", \" n't \")\n",
        "        .replace(\"n 't \", \" n't \")\n",
        "        .replace(\"ca n't\", \"can't\")\n",
        "        .replace(\"ai n't\", \"ain't\")\n",
        "    )\n",
        "    normTweet = (\n",
        "        normTweet.replace(\"'m \", \" 'm \")\n",
        "        .replace(\"'re \", \" 're \")\n",
        "        .replace(\"'s \", \" 's \")\n",
        "        .replace(\"'ll \", \" 'll \")\n",
        "        .replace(\"'d \", \" 'd \")\n",
        "        .replace(\"'ve \", \" 've \")\n",
        "    )\n",
        "    normTweet = (\n",
        "        normTweet.replace(\" p . m .\", \"  p.m.\")\n",
        "        .replace(\" p . m \", \" p.m \")\n",
        "        .replace(\" a . m .\", \" a.m.\")\n",
        "        .replace(\" a . m \", \" a.m \")\n",
        "    )\n",
        "\n",
        "    return \" \".join(normTweet.split())"
      ],
      "metadata": {
        "id": "jgoIsywMbSeg"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenize the BERTweet inputs\n",
        "Normalization is set to false because we are doing it using the 'normalizeTweet' function above."
      ],
      "metadata": {
        "id": "Y-F3UyPG9dvJ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FOnxtpPkxWt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "69c398c685bd422ba234f46285a1a112",
            "94dfb46f7e2a496d8fa4e886e42aaa52",
            "097af6d22dc444728fb5cc35da5496ee",
            "291788e9aa244c36bf1f9c2af4922e16",
            "9c13d908777f4a8a91fea12db7c18428",
            "33b29c185a684b479c2dd2fc06cb242f",
            "11a5e45afa6542248255021c51bd568e",
            "fa7a7d70740741f7bdccf8967e44eb80",
            "deb35564672b4d9e80f1092e4c726975",
            "250f7fb7652d4077940f30440495ca89",
            "abc8a9499a2a49b4b6ed6684f79c1a6b",
            "c613fe376d224674a7e66dae20df0a16",
            "ecd11980aa704d3cb9d65c2499040af1",
            "aa8d4553d3624f46be82dd213e27eebc",
            "2858d2a1786143b3b3b0793b753e42e8",
            "f761f5c8f1634ad89aa5b386ea00f677",
            "b26c4ca9304c4096a43d102d5770313e",
            "e7253c2bfc3a4d14b345995d48713720",
            "8126b909bb324a47b4229920bf6657d2",
            "25b9e9c0cbcf4b6fbf0f2bbbe92bf171",
            "9dc1ac7af7784e65a9700e1e04a31d8f",
            "ef8be7c200414820b7e94ce7909ba40a",
            "ccb90dabcdbd4d24ba12b688167af4ab",
            "7d777ab9689c4f7cb9e497b8e8c1de31",
            "99f05422fb524d0597ea0ebd86f46917",
            "e00e02590c02490e99b7669f4091bc43",
            "33a8877eb5d14ffb938040bbbcbae9d6",
            "91e5bed92c474c00a3dbac5191322278",
            "72c9c6c2e06b4f6494f5faad4e989138",
            "1c0f674b7ab04262b0b546d44d529d1c",
            "115c00ef6ffa4624b95275e7d258e71a",
            "01ed50018e2a41468a001f5471118f7c",
            "67e5811320d04049a185e92f9e71af5a"
          ]
        },
        "outputId": "d45c3a9a-c3f1-4ea1-9b8e-28d595fdd7f4"
      },
      "source": [
        "# Load the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-large\", normalization=False, use_fast=False)\n",
        "\n",
        "# Define function to do BERT family preprocessing\n",
        "def preprocessing_for_bert(data):\n",
        "    \"\"\"Perform required preprocessing steps for pretrained BERT.\n",
        "    @param    data (np.array): Array of texts to be processed.\n",
        "    @return   input_ids (torch.Tensor): Tensor of token ids to be fed to a model.\n",
        "    @return   attention_masks (torch.Tensor): Tensor of indices specifying which\n",
        "                  tokens should be attended to by the model.\n",
        "    \"\"\"\n",
        "    # Create empty lists to store outputs\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    # For every sentence...\n",
        "    for sent in data:\n",
        "        # `encode_plus` will:\n",
        "        #    (1) Tokenize the sentence\n",
        "        #    (2) Add the `[CLS]` and `[SEP]` token to the start and end\n",
        "        #    (3) Truncate/Pad sentence to max length\n",
        "        #    (4) Map tokens to their IDs\n",
        "        #    (5) Create attention mask\n",
        "        #    (6) Return a dictionary of outputs\n",
        "        encoded_sent = tokenizer.encode_plus(\n",
        "            text=sent,\n",
        "            add_special_tokens=True,        # Add `[CLS]` and `[SEP]`\n",
        "            max_length=MAX_LEN,                  # Max length to truncate/pad\n",
        "            padding='max_length',         # Pad sentence to max length\n",
        "            #return_tensors='pt',           # Return PyTorch tensor\n",
        "            return_attention_mask=True,      # Return attention mask\n",
        "            truncation=True\n",
        "            )\n",
        "        \n",
        "        # Add the outputs to the lists\n",
        "        input_ids.append(encoded_sent.get('input_ids'))\n",
        "        attention_masks.append(encoded_sent.get('attention_mask'))\n",
        "\n",
        "    # Convert lists to tensors\n",
        "    input_ids = torch.tensor(input_ids)\n",
        "    attention_masks = torch.tensor(attention_masks)\n",
        "\n",
        "    return input_ids, attention_masks"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/614 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "69c398c685bd422ba234f46285a1a112"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c613fe376d224674a7e66dae20df0a16"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ccb90dabcdbd4d24ba12b688167af4ab"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bf0MGhN2k-8M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "outputId": "8502b4dc-6536-4a88-8fb8-834e700e9348"
      },
      "source": [
        "# Analyze post lengths after processing. This block is not required.\n",
        "\n",
        "all_posts = pd.concat([training_data, validation_data])['tweet']\n",
        "\n",
        "# all_posts = augment_training_data['text']\n",
        "\n",
        "# preprocess tweets using BERTweet normalizer\n",
        "all_posts = [normalizeTweet(sent) for sent in all_posts]\n",
        "\n",
        "# Encode our concatenated data\n",
        "encoded_posts = [tokenizer.encode(sent, add_special_tokens=True) for sent in all_posts]\n",
        "\n",
        "# get length of all the messages in the train set\n",
        "seq_len = [len(i) for i in encoded_posts]\n",
        "\n",
        "print(\"\\nLength of encoded posts:\")\n",
        "pd.Series(seq_len).hist(bins = 30)\n",
        "\n",
        "pd.Series(seq_len).describe()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Length of encoded posts:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    1734.000000\n",
              "mean       28.310265\n",
              "std        15.434860\n",
              "min         4.000000\n",
              "25%        17.000000\n",
              "50%        25.000000\n",
              "75%        36.000000\n",
              "max       105.000000\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FcudmvtlDUV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d88ca12a-5bed-41a0-d929-8077e020f3be"
      },
      "source": [
        "# Specify `MAX_LEN`\n",
        "MAX_LEN = 100\n",
        "\n",
        "# Print sentence 1 and its encoded token ids\n",
        "normalized_example = normalizeTweet(X_train[0])\n",
        "token_ids = list(preprocessing_for_bert([normalized_example])[0].squeeze().numpy())\n",
        "print('Original: ', X_train[0])\n",
        "print('Normalized tweet:', normalized_example)\n",
        "print('Token IDs: ', token_ids)\n",
        "\n",
        "# normalize all tweets for BERTweet\n",
        "for index, value in X_train.iteritems():\n",
        "  X_train.at[index] = normalizeTweet(value)\n",
        "for index, value in X_val.iteritems():\n",
        "  X_val.at[index] = normalizeTweet(value)\n",
        "\n",
        "# Run function `preprocessing_for_bert` on the train set and the validation set\n",
        "pretrain_inputs, pretrain_masks = preprocessing_for_bert(X_aug_train)\n",
        "train_inputs, train_masks = preprocessing_for_bert(X_train)\n",
        "val_inputs, val_masks = preprocessing_for_bert(X_val)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  I can't count the amount of times over the years I've just forgotten I have my nose pierced and I've just been reminded again by a tiktok\n",
            "Normalized tweet: I can't count the amount of times over the years I 've just forgotten I have my nose pierced and I 've just been reminded again by a tiktok\n",
            "Token IDs:  [0, 100, 64, 75, 3212, 5, 1280, 9, 498, 81, 5, 107, 38, 128, 548, 95, 9885, 38, 33, 127, 8658, 40227, 8, 38, 128, 548, 95, 57, 9180, 456, 30, 10, 326, 967, 90, 1638, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for index, value in X_test.iteritems():\n",
        "  X_test.at[index] = normalizeTweet(value)\n",
        "\n",
        "test_inputs, test_masks = preprocessing_for_bert(X_test)"
      ],
      "metadata": {
        "id": "0osOyNqcDu4_"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create dataloaders"
      ],
      "metadata": {
        "id": "JEOvUl8Wi7_g"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-GcEK4ZlM5T"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# Convert other data types to torch.Tensor\n",
        "train_labels = torch.tensor(y_train.values)\n",
        "val_labels = torch.tensor(y_val.values)\n",
        "\n",
        "pretrain_labels = torch.tensor(y_aug_train.values)\n",
        "\n",
        "# For fine-tuning BERT, the authors recommend a batch size of 16 or 32.\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoaders for our augment pretraining set\n",
        "pretrain_data = TensorDataset(pretrain_inputs, pretrain_masks, pretrain_labels)\n",
        "pretrain_sampler = RandomSampler(pretrain_data)\n",
        "pretrain_dataloader = DataLoader(pretrain_data, sampler=pretrain_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoaders for our training set\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoaders for our validation set\n",
        "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels = torch.tensor(y_test.values)\n",
        "\n",
        "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
        "test_sampler = SequentialSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)\n"
      ],
      "metadata": {
        "id": "MCLGVuKvD8-n"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define model class"
      ],
      "metadata": {
        "id": "X4zmPtVQjF6D"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNpW1NyHlUkT"
      },
      "source": [
        "class BertClassifier(nn.Module):\n",
        "    \"\"\"Bert Model for Classification Tasks.\n",
        "    \"\"\"\n",
        "    def __init__(self, freeze_bert=False):\n",
        "        \"\"\"\n",
        "        @param    bert: a BertModel object\n",
        "        @param    classifier: a torch.nn.Module classifier\n",
        "        @param    freeze_bert (bool): Set `False` to fine-tune the BERT model\n",
        "        \"\"\"\n",
        "        super(BertClassifier, self).__init__()\n",
        "\n",
        "        # Specify hidden size of BERT, hidden size of our classifier, and number of labels\n",
        "        D_in, H, D_out = 1024, 100, 2\n",
        "\n",
        "        # Instantiate BERT model\n",
        "        self.bert = AutoModel.from_pretrained(\"vinai/bertweet-large\")\n",
        "\n",
        "        # Instantiate an one-layer feed-forward classifier\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(D_in, H),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.33),\n",
        "            nn.Linear(H, D_out)\n",
        "        )\n",
        "\n",
        "        # Freeze the BERT model\n",
        "        if freeze_bert:\n",
        "            for param in self.bert.parameters():\n",
        "                param.requires_grad = False\n",
        "        \n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        \"\"\"\n",
        "        Feed input to BERT and the classifier to compute logits.\n",
        "        @param    input_ids (torch.Tensor): an input tensor with shape (batch_size,\n",
        "                      max_length)\n",
        "        @param    attention_mask (torch.Tensor): a tensor that hold attention mask\n",
        "                      information with shape (batch_size, max_length)\n",
        "        @return   logits (torch.Tensor): an output tensor with shape (batch_size,\n",
        "                      num_labels)\n",
        "        \"\"\"\n",
        "        # Feed input to BERT\n",
        "        bert_outputs = self.bert(input_ids=input_ids,\n",
        "                            attention_mask=attention_mask)\n",
        "        \n",
        "        # Extract the last hidden state of the token `[CLS]` for classification task\n",
        "        last_hidden_state_cls = bert_outputs[0][:, 0, :]\n",
        "\n",
        "        # Feed input to classifier to compute logits\n",
        "        logits = self.classifier(last_hidden_state_cls)\n",
        "\n",
        "        return logits"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzyKG7FmlZnc"
      },
      "source": [
        "def initialize_model(current_train_dataloader, epochs=5, learning_rate=1e-3):\n",
        "    \"\"\"Initialize the Bert Classifier, the optimizer and the learning rate scheduler.\n",
        "    \"\"\"\n",
        "    # Instantiate Bert Classifier\n",
        "    bert_classifier = BertClassifier(freeze_bert=False)\n",
        "\n",
        "    # Tell PyTorch to run the model on GPU\n",
        "    bert_classifier.to(device)\n",
        "\n",
        "    # Create the optimizer\n",
        "    optimizer = AdamW(bert_classifier.parameters(),\n",
        "                      lr=learning_rate,    # Default learning rate is 1e-3\n",
        "                      eps=1e-8,    # Default epsilon value is 1e-6\n",
        "                      weight_decay=.01\n",
        "                      )\n",
        "   \n",
        "    # Total number of training steps\n",
        "    total_steps = len(current_train_dataloader) * epochs\n",
        "\n",
        "    # Set up the learning rate scheduler\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                                num_warmup_steps=0, # Default value\n",
        "                                                num_training_steps=total_steps)\n",
        "    return bert_classifier, optimizer, scheduler"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def re_initialize_optimizer(current_train_dataloader, epochs=5, learning_rate=1e-3):\n",
        "    \n",
        "    # Create the optimizer\n",
        "    optimizer = AdamW(bert_classifier.parameters(),\n",
        "                      lr=learning_rate,    # Default learning rate is 1e-3\n",
        "                      eps=1e-8,    # Default epsilon value is 1e-6\n",
        "                      weight_decay=.01\n",
        "                      )\n",
        "    \n",
        "    # Total number of training steps\n",
        "    total_steps = len(current_train_dataloader) * epochs\n",
        "\n",
        "    # Set up the learning rate scheduler\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                                num_warmup_steps=0, # Default value\n",
        "                                                num_training_steps=total_steps)\n",
        "    return optimizer, scheduler"
      ],
      "metadata": {
        "id": "ESRC4_WePQEM"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define training and evaluation loops"
      ],
      "metadata": {
        "id": "eV2hf43bjj-H"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfQI_6cflcLU"
      },
      "source": [
        "# Specify loss function\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "def train(model, train_dataloader, val_dataloader=None, epochs=4, evaluation=False):\n",
        "    \"\"\"Train the BertClassifier model.\n",
        "    \"\"\"\n",
        "\n",
        "    # set initial best positive F1 score to negative infinity\n",
        "    best_pos_f1 = -float('inf')\n",
        "    best_val_accuracy = -float('inf')\n",
        "    best_epoch = 0\n",
        "\n",
        "    # Start training loop\n",
        "    print(\"Start training...\\n\")\n",
        "    for epoch_i in range(epochs):\n",
        "\n",
        "        # Print the header of the result table\n",
        "        print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n",
        "        print(\"-\"*70)\n",
        "\n",
        "        # Measure the elapsed time of each epoch\n",
        "        t0_epoch, t0_batch = time.time(), time.time()\n",
        "\n",
        "        # Reset tracking variables at the beginning of each epoch\n",
        "        total_loss, batch_loss, batch_counts = 0, 0, 0\n",
        "\n",
        "        # Put the model into the training mode\n",
        "        model.train()\n",
        "\n",
        "        # For each batch of training data...\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            batch_counts +=1\n",
        "            # Load batch to GPU\n",
        "            b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "            # Zero out any previously calculated gradients\n",
        "            model.zero_grad()\n",
        "\n",
        "            # Perform a forward pass. This will return logits.\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "\n",
        "            # Compute loss and accumulate the loss values\n",
        "            loss = loss_fn(logits, b_labels)\n",
        "            batch_loss += loss.item()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Perform a backward pass to calculate gradients\n",
        "            loss.backward()\n",
        "\n",
        "            # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "            # Update parameters and the learning rate\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            # Print the loss values and time elapsed for every 20 batches\n",
        "            if (step % 20 == 0 and step != 0) or (step == len(train_dataloader) - 1):\n",
        "                # Calculate time elapsed for 20 batches\n",
        "                time_elapsed = time.time() - t0_batch\n",
        "\n",
        "                # Print training results\n",
        "                print(f\"{epoch_i + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {'-':^10} | {'-':^9} | {time_elapsed:^9.2f}\")\n",
        "\n",
        "                # Reset batch tracking variables\n",
        "                batch_loss, batch_counts = 0, 0\n",
        "                t0_batch = time.time()\n",
        "\n",
        "        # Calculate the average loss over the entire training data\n",
        "        avg_train_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "        print(\"-\"*70)\n",
        "\n",
        "        if evaluation == True:\n",
        "            # After the completion of each training epoch, measure the model's performance\n",
        "            # on our validation set.\n",
        "            val_loss, val_accuracy, best_pos_eval_f1_score, best_threshold = evaluate(model, val_dataloader)\n",
        "\n",
        "            #save the best model\n",
        "            if best_pos_eval_f1_score > best_pos_f1:\n",
        "                best_pos_f1 = best_pos_eval_f1_score\n",
        "                best_epoch = epoch_i + 1\n",
        "                torch.save(model.state_dict(), 'saved_weights.pt')\n",
        "\n",
        "                # store best threshold in log file\n",
        "                with open(\"best_threshold.txt\", mode=\"w\", newline=\"\\n\", encoding=\"utf-8\") as output_file:\n",
        "                  output_file.write(str(best_threshold))\n",
        "\n",
        "            # Print performance over the entire training data\n",
        "            time_elapsed = time.time() - t0_epoch\n",
        "            \n",
        "            print(f\"{epoch_i + 1:^7} | {'-':^7} | {avg_train_loss:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n",
        "            print(\"-\"*70)\n",
        "            print('Best positive F1 score for current epoch:', best_pos_eval_f1_score, 'Best threshold:', best_threshold, 'Epoch of best model:', best_epoch)\n",
        "        print(\"\\n\")\n",
        "    \n",
        "    print(\"Training complete!\")\n",
        "\n",
        "def evaluate(model, val_dataloader):\n",
        "    \"\"\"After the completion of each training epoch, measure the model's performance\n",
        "    on our validation set.\n",
        "    \"\"\"\n",
        "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
        "    # the test time.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables\n",
        "    val_accuracy = []\n",
        "    val_loss = []\n",
        "    all_eval_logits = []\n",
        "\n",
        "    # For each batch in our validation set...\n",
        "    for batch in val_dataloader:      \n",
        "        # Load batch to GPU\n",
        "        b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        # Compute logits\n",
        "        with torch.no_grad():\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "\n",
        "        all_eval_logits.append(logits.cpu())\n",
        "\n",
        "        # Compute batch loss\n",
        "        loss = loss_fn(logits, b_labels)\n",
        "        val_loss.append(loss.item())\n",
        "\n",
        "        # Get the predictions\n",
        "        preds = torch.argmax(logits, dim=1).flatten()\n",
        "\n",
        "        # Calculate the accuracy rate\n",
        "        accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n",
        "        val_accuracy.append(accuracy)\n",
        "\n",
        "    # Compute the average accuracy and loss over the validation set.\n",
        "    val_loss = np.mean(val_loss)\n",
        "    val_accuracy = np.mean(val_accuracy)\n",
        "\n",
        "    # Concatenate logits from each batch\n",
        "    all_eval_logits = torch.cat(all_eval_logits, dim=0)\n",
        "\n",
        "    # Apply softmax to calculate probabilities\n",
        "    all_probs = F.softmax(all_eval_logits, dim=1).cpu().numpy()\n",
        "\n",
        "    # get positive probs only to calculate best threshold for positive f1\n",
        "    pos_probs = all_probs[:, 1]\n",
        "    precision, recall, thresholds = precision_recall_curve(y_val, pos_probs)\n",
        "\n",
        "    # calculate f1 for the positive class, ignore divide by zero warnings\n",
        "    with np.errstate(invalid='ignore'):\n",
        "      pos_f1_score = (2 * precision * recall) / (precision + recall)\n",
        "\n",
        "    # retrieve the best threshold for the best positive f1 score\n",
        "    ix = np.argmax(np.nan_to_num(pos_f1_score))\n",
        "    best_f1_score = pos_f1_score[ix]\n",
        "    best_threshold = thresholds[ix]\n",
        "\n",
        "    return val_loss, val_accuracy, best_f1_score, best_threshold"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define predictor function"
      ],
      "metadata": {
        "id": "q3kYsL6T3Q8g"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzFc_hBloDW5"
      },
      "source": [
        "def bert_predict(model, test_dataloader):\n",
        "    \"\"\"Perform a forward pass on the trained BERT model to predict probabilities\n",
        "    on the test set.\n",
        "    \"\"\"\n",
        "    # Put the model into the evaluation mode.\n",
        "    model.eval()\n",
        "\n",
        "    all_logits = []\n",
        "\n",
        "    # For each batch in our test set...\n",
        "    for batch in test_dataloader:\n",
        "        # Load batch to GPU\n",
        "        # The '_' value is for labels, which we do not need\n",
        "        b_input_ids, b_attn_mask, _ = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        # Compute logits\n",
        "        with torch.no_grad():\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "        all_logits.append(logits)\n",
        "    \n",
        "    # Concatenate logits from each batch\n",
        "    all_logits = torch.cat(all_logits, dim=0)\n",
        "\n",
        "    # Apply softmax to calculate probabilities\n",
        "    probs = F.softmax(all_logits, dim=1).cpu().numpy()\n",
        "\n",
        "    return probs"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXyU05lBjxIG"
      },
      "source": [
        "# AUC/Accuracy evaluation function\n",
        "\n",
        "from sklearn.metrics import accuracy_score, roc_curve, auc\n",
        "\n",
        "def evaluate_roc(probs, y_true):\n",
        "    \"\"\"\n",
        "    - Print AUC and accuracy on the test set\n",
        "    - Plot ROC\n",
        "    @params    probs (np.array): an array of predicted probabilities with shape (len(y_true), 2)\n",
        "    @params    y_true (np.array): an array of the true values with shape (len(y_true),)\n",
        "    \"\"\"\n",
        "    preds = probs[:, 1]\n",
        "    fpr, tpr, threshold = roc_curve(y_true, preds)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    print(f'AUC: {roc_auc:.4f}')\n",
        "       \n",
        "    # Get accuracy over the test set\n",
        "    y_pred = np.where(preds >= 0.5, 1, 0)\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    print(f'Accuracy: {accuracy*100:.2f}%')\n",
        "    \n",
        "    # Plot ROC AUC\n",
        "    plt.title('Receiver Operating Characteristic')\n",
        "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "    plt.legend(loc = 'lower right')\n",
        "    plt.plot([0, 1], [0, 1],'r--')\n",
        "    plt.xlim([0, 1])\n",
        "    plt.ylim([0, 1])\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.show()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define function for setting random seed"
      ],
      "metadata": {
        "id": "oAR3Djky2HRA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed_value=42):\n",
        "    \"\"\"Set seed for reproducibility.\n",
        "    \"\"\"\n",
        "    random.seed(seed_value)\n",
        "    np.random.seed(seed_value)\n",
        "    torch.manual_seed(seed_value)\n",
        "    torch.cuda.manual_seed_all(seed_value)"
      ],
      "metadata": {
        "id": "efx0kBeX2GbZ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train model"
      ],
      "metadata": {
        "id": "OU1yfUNCkNfk"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSlg5lXblmH6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "adf69052d0914a36a891ce67bf9fb3da",
            "fac69e84bb8f4ef19d5aabf63899db43",
            "9c6811421207412eb3d7f79750440e2d",
            "4a26272a605f42b5b494a5e1b876292f",
            "c4cd679887b54535b57e421a79508ec2",
            "b815ba354358480a8b300e15ab722fbe",
            "4db505f748584be6aed8c4a6cab1b4bb",
            "98ac42dc45a74f2d9956295961a46c29",
            "88a61e2b0433495291e041e0f58da880",
            "d45a3c2ada4646de85675a0fb7ca7aa1",
            "2d11fc24e7c34329857ad9b9b04dfe2b"
          ]
        },
        "outputId": "93020966-c918-4ec5-cf1b-d33c6eeaacc5"
      },
      "source": [
        "set_seed(42)    # Set seed for reproducibility\n",
        "EPOCHS = 30\n",
        "LEARNING_RATE = 3e-6\n",
        "\n",
        "bert_classifier, optimizer, scheduler = initialize_model(train_dataloader, epochs=EPOCHS, learning_rate=LEARNING_RATE)\n",
        "train(bert_classifier, train_dataloader, val_dataloader, epochs=EPOCHS, evaluation=True)\n",
        "\n",
        "# bert_classifier, optimizer, scheduler = initialize_model(pretrain_dataloader, epochs=EPOCHS, learning_rate=LEARNING_RATE)\n",
        "# BEST_THRESHOLD_FOR_BEST_MODEL = train(bert_classifier, pretrain_dataloader, val_dataloader, epochs=EPOCHS, evaluation=True)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.32G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "adf69052d0914a36a891ce67bf9fb3da"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at vinai/bertweet-large were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.decoder.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at vinai/bertweet-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start training...\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   1    |   20    |   0.708643   |     -      |     -     |   20.94  \n",
            "   1    |   40    |   0.700075   |     -      |     -     |   19.94  \n",
            "   1    |   48    |   0.700015   |     -      |     -     |   7.83   \n",
            "----------------------------------------------------------------------\n",
            "   1    |    -    |   0.703737   |  0.692926  |   48.44   |   54.77  \n",
            "----------------------------------------------------------------------\n",
            "Best positive F1 score for current epoch: 0.6692913385826772 Best threshold: 0.46586636 Epoch of best model: 1\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   2    |   20    |   0.694254   |     -      |     -     |   20.94  \n",
            "   2    |   40    |   0.699408   |     -      |     -     |   19.93  \n",
            "   2    |   48    |   0.689816   |     -      |     -     |   7.83   \n",
            "----------------------------------------------------------------------\n",
            "   2    |    -    |   0.695633   |  0.696387  |   51.56   |   50.42  \n",
            "----------------------------------------------------------------------\n",
            "Best positive F1 score for current epoch: 0.6666666666666666 Best threshold: 0.49146 Epoch of best model: 1\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   3    |   20    |   0.691739   |     -      |     -     |   20.93  \n",
            "   3    |   40    |   0.695201   |     -      |     -     |   19.93  \n",
            "   3    |   48    |   0.677994   |     -      |     -     |   7.88   \n",
            "----------------------------------------------------------------------\n",
            "   3    |    -    |   0.690908   |  0.691800  |   56.42   |   55.16  \n",
            "----------------------------------------------------------------------\n",
            "Best positive F1 score for current epoch: 0.6719367588932806 Best threshold: 0.4763108 Epoch of best model: 3\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   4    |   20    |   0.686796   |     -      |     -     |   20.95  \n",
            "   4    |   40    |   0.687938   |     -      |     -     |   19.92  \n",
            "   4    |   48    |   0.666069   |     -      |     -     |   7.83   \n",
            "----------------------------------------------------------------------\n",
            "   4    |    -    |   0.683878   |  0.674362  |   61.63   |   55.21  \n",
            "----------------------------------------------------------------------\n",
            "Best positive F1 score for current epoch: 0.6893617021276595 Best threshold: 0.4708497 Epoch of best model: 4\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   5    |   20    |   0.661050   |     -      |     -     |   20.93  \n",
            "   5    |   40    |   0.611611   |     -      |     -     |   19.93  \n",
            "   5    |   48    |   0.594608   |     -      |     -     |   7.88   \n",
            "----------------------------------------------------------------------\n",
            "   5    |    -    |   0.630023   |  0.594315  |   65.62   |   55.24  \n",
            "----------------------------------------------------------------------\n",
            "Best positive F1 score for current epoch: 0.7083333333333334 Best threshold: 0.43627864 Epoch of best model: 5\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   6    |   20    |   0.528566   |     -      |     -     |   20.93  \n",
            "   6    |   40    |   0.516567   |     -      |     -     |   19.93  \n",
            "   6    |   48    |   0.588572   |     -      |     -     |   7.83   \n",
            "----------------------------------------------------------------------\n",
            "   6    |    -    |   0.533465   |  0.564525  |   71.88   |   55.21  \n",
            "----------------------------------------------------------------------\n",
            "Best positive F1 score for current epoch: 0.7437185929648241 Best threshold: 0.28437582 Epoch of best model: 6\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   7    |   20    |   0.492118   |     -      |     -     |   20.93  \n",
            "   7    |   40    |   0.487619   |     -      |     -     |   19.94  \n",
            "   7    |   48    |   0.492278   |     -      |     -     |   7.83   \n",
            "----------------------------------------------------------------------\n",
            "   7    |    -    |   0.490308   |  0.574200  |   69.97   |   55.18  \n",
            "----------------------------------------------------------------------\n",
            "Best positive F1 score for current epoch: 0.7461139896373057 Best threshold: 0.23488162 Epoch of best model: 7\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   8    |   20    |   0.412283   |     -      |     -     |   20.95  \n",
            "   8    |   40    |   0.386440   |     -      |     -     |   19.93  \n",
            "   8    |   48    |   0.410219   |     -      |     -     |   7.84   \n",
            "----------------------------------------------------------------------\n",
            "   8    |    -    |   0.401398   |  0.638736  |   73.44   |   50.45  \n",
            "----------------------------------------------------------------------\n",
            "Best positive F1 score for current epoch: 0.7346938775510204 Best threshold: 0.12839304 Epoch of best model: 7\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   9    |   20    |   0.331159   |     -      |     -     |   20.92  \n",
            "   9    |   40    |   0.383610   |     -      |     -     |   19.92  \n",
            "   9    |   48    |   0.374805   |     -      |     -     |   7.83   \n",
            "----------------------------------------------------------------------\n",
            "   9    |    -    |   0.359693   |  0.676616  |   69.10   |   50.39  \n",
            "----------------------------------------------------------------------\n",
            "Best positive F1 score for current epoch: 0.7393364928909953 Best threshold: 0.17628302 Epoch of best model: 7\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  10    |   20    |   0.349129   |     -      |     -     |   20.92  \n",
            "  10    |   40    |   0.278907   |     -      |     -     |   19.93  \n",
            "  10    |   48    |   0.258490   |     -      |     -     |   7.84   \n",
            "----------------------------------------------------------------------\n",
            "  10    |    -    |   0.305669   |  0.759143  |   68.58   |   50.41  \n",
            "----------------------------------------------------------------------\n",
            "Best positive F1 score for current epoch: 0.736842105263158 Best threshold: 0.11869107 Epoch of best model: 7\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  11    |   20    |   0.239738   |     -      |     -     |   20.91  \n",
            "  11    |   40    |   0.271565   |     -      |     -     |   19.92  \n",
            "  11    |   48    |   0.247255   |     -      |     -     |   7.84   \n",
            "----------------------------------------------------------------------\n",
            "  11    |    -    |   0.253956   |  0.845169  |   68.23   |   50.40  \n",
            "----------------------------------------------------------------------\n",
            "Best positive F1 score for current epoch: 0.7411167512690354 Best threshold: 0.05862821 Epoch of best model: 7\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  12    |   20    |   0.207817   |     -      |     -     |   20.92  \n",
            "  12    |   40    |   0.231969   |     -      |     -     |   19.94  \n",
            "  12    |   48    |   0.245459   |     -      |     -     |   7.84   \n",
            "----------------------------------------------------------------------\n",
            "  12    |    -    |   0.223820   |  0.743772  |   72.57   |   55.26  \n",
            "----------------------------------------------------------------------\n",
            "Best positive F1 score for current epoch: 0.7547169811320754 Best threshold: 0.057317182 Epoch of best model: 12\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  13    |   20    |   0.192188   |     -      |     -     |   20.97  \n",
            "  13    |   40    |   0.177185   |     -      |     -     |   19.93  \n",
            "  13    |   48    |   0.230766   |     -      |     -     |   7.83   \n",
            "----------------------------------------------------------------------\n",
            "  13    |    -    |   0.192363   |  0.894849  |   69.62   |   50.45  \n",
            "----------------------------------------------------------------------\n",
            "Best positive F1 score for current epoch: 0.7454545454545454 Best threshold: 0.027332915 Epoch of best model: 12\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  14    |   20    |   0.167009   |     -      |     -     |   20.91  \n",
            "  14    |   40    |   0.183078   |     -      |     -     |   19.92  \n",
            "  14    |   48    |   0.209530   |     -      |     -     |   7.85   \n",
            "----------------------------------------------------------------------\n",
            "  14    |    -    |   0.180510   |  0.931174  |   71.70   |   50.40  \n",
            "----------------------------------------------------------------------\n",
            "Best positive F1 score for current epoch: 0.7354260089686099 Best threshold: 0.016807837 Epoch of best model: 12\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  15    |   20    |   0.152472   |     -      |     -     |   20.91  \n",
            "  15    |   40    |   0.144006   |     -      |     -     |   19.92  \n",
            "  15    |   48    |   0.153431   |     -      |     -     |   7.84   \n",
            "----------------------------------------------------------------------\n",
            "  15    |    -    |   0.149173   |  1.141466  |   69.62   |   50.39  \n",
            "----------------------------------------------------------------------\n",
            "Best positive F1 score for current epoch: 0.7323943661971831 Best threshold: 0.016396616 Epoch of best model: 12\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  16    |   20    |   0.156241   |     -      |     -     |   20.91  \n",
            "  16    |   40    |   0.122223   |     -      |     -     |   19.92  \n",
            "  16    |   48    |   0.142894   |     -      |     -     |   7.84   \n",
            "----------------------------------------------------------------------\n",
            "  16    |    -    |   0.140177   |  1.123544  |   70.66   |   50.39  \n",
            "----------------------------------------------------------------------\n",
            "Best positive F1 score for current epoch: 0.7439613526570048 Best threshold: 0.018607581 Epoch of best model: 12\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  17    |   20    |   0.114337   |     -      |     -     |   20.92  \n",
            "  17    |   40    |   0.112844   |     -      |     -     |   19.93  \n",
            "  17    |   48    |   0.110140   |     -      |     -     |   7.84   \n",
            "----------------------------------------------------------------------\n",
            "  17    |    -    |   0.113042   |  0.969748  |   71.70   |   50.41  \n",
            "----------------------------------------------------------------------\n",
            "Best positive F1 score for current epoch: 0.7486631016042781 Best threshold: 0.033435524 Epoch of best model: 12\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  18    |   20    |   0.114410   |     -      |     -     |   20.91  \n",
            "  18    |   40    |   0.089209   |     -      |     -     |   19.93  \n",
            "  18    |   48    |   0.032899   |     -      |     -     |   7.82   \n",
            "----------------------------------------------------------------------\n",
            "  18    |    -    |   0.090816   |  1.199008  |   67.19   |   50.38  \n",
            "----------------------------------------------------------------------\n",
            "Best positive F1 score for current epoch: 0.7340425531914895 Best threshold: 0.024437923 Epoch of best model: 12\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  19    |   20    |   0.077907   |     -      |     -     |   20.91  \n",
            "  19    |   40    |   0.094029   |     -      |     -     |   19.93  \n",
            "  19    |   48    |   0.073944   |     -      |     -     |   7.83   \n",
            "----------------------------------------------------------------------\n",
            "  19    |    -    |   0.083840   |  1.292806  |   70.66   |   50.38  \n",
            "----------------------------------------------------------------------\n",
            "Best positive F1 score for current epoch: 0.736842105263158 Best threshold: 0.01217263 Epoch of best model: 12\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  20    |   20    |   0.095781   |     -      |     -     |   20.90  \n",
            "  20    |   40    |   0.067701   |     -      |     -     |   19.94  \n",
            "  20    |   48    |   0.083082   |     -      |     -     |   7.84   \n",
            "----------------------------------------------------------------------\n",
            "  20    |    -    |   0.082247   |  1.446132  |   68.23   |   50.41  \n",
            "----------------------------------------------------------------------\n",
            "Best positive F1 score for current epoch: 0.7384615384615384 Best threshold: 0.005742861 Epoch of best model: 12\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  21    |   20    |   0.054092   |     -      |     -     |   20.91  \n",
            "  21    |   40    |   0.091401   |     -      |     -     |   19.92  \n",
            "  21    |   48    |   0.139403   |     -      |     -     |   7.85   \n",
            "----------------------------------------------------------------------\n",
            "  21    |    -    |   0.083249   |  1.315890  |   70.66   |   50.41  \n",
            "----------------------------------------------------------------------\n",
            "Best positive F1 score for current epoch: 0.736842105263158 Best threshold: 0.0067805233 Epoch of best model: 12\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  22    |   20    |   0.071440   |     -      |     -     |   20.92  \n",
            "  22    |   40    |   0.070871   |     -      |     -     |   19.92  \n",
            "  22    |   48    |   0.058911   |     -      |     -     |   7.83   \n",
            "----------------------------------------------------------------------\n",
            "  22    |    -    |   0.069162   |  1.340348  |   71.18   |   50.39  \n",
            "----------------------------------------------------------------------\n",
            "Best positive F1 score for current epoch: 0.7292817679558011 Best threshold: 0.011639332 Epoch of best model: 12\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  23    |   20    |   0.066698   |     -      |     -     |   20.91  \n",
            "  23    |   40    |   0.063694   |     -      |     -     |   19.92  \n",
            "  23    |   48    |   0.029568   |     -      |     -     |   7.84   \n",
            "----------------------------------------------------------------------\n",
            "  23    |    -    |   0.059410   |  1.537649  |   69.27   |   50.39  \n",
            "----------------------------------------------------------------------\n",
            "Best positive F1 score for current epoch: 0.73 Best threshold: 0.0046164826 Epoch of best model: 12\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  24    |   20    |   0.053991   |     -      |     -     |   20.90  \n",
            "  24    |   40    |   0.064412   |     -      |     -     |   19.91  \n",
            "  24    |   48    |   0.049898   |     -      |     -     |   7.83   \n",
            "----------------------------------------------------------------------\n",
            "  24    |    -    |   0.057576   |  1.544233  |   69.62   |   50.37  \n",
            "----------------------------------------------------------------------\n",
            "Best positive F1 score for current epoch: 0.7236842105263159 Best threshold: 0.9932487 Epoch of best model: 12\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  25    |   20    |   0.053671   |     -      |     -     |   20.93  \n",
            "  25    |   40    |   0.052650   |     -      |     -     |   19.92  \n",
            "  25    |   48    |   0.037760   |     -      |     -     |   7.83   \n",
            "----------------------------------------------------------------------\n",
            "  25    |    -    |   0.050657   |  1.571678  |   71.53   |   50.41  \n",
            "----------------------------------------------------------------------\n",
            "Best positive F1 score for current epoch: 0.7373737373737375 Best threshold: 0.0026364631 Epoch of best model: 12\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  26    |   20    |   0.069929   |     -      |     -     |   20.91  \n",
            "  26    |   40    |   0.048363   |     -      |     -     |   19.94  \n",
            "  26    |   48    |   0.038136   |     -      |     -     |   7.83   \n",
            "----------------------------------------------------------------------\n",
            "  26    |    -    |   0.055936   |  1.610463  |   70.14   |   50.40  \n",
            "----------------------------------------------------------------------\n",
            "Best positive F1 score for current epoch: 0.7309644670050761 Best threshold: 0.002663978 Epoch of best model: 12\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  27    |   20    |   0.039461   |     -      |     -     |   20.91  \n",
            "  27    |   40    |   0.054591   |     -      |     -     |   19.93  \n",
            "  27    |   48    |   0.064019   |     -      |     -     |   7.83   \n",
            "----------------------------------------------------------------------\n",
            "  27    |    -    |   0.049646   |  1.617145  |   69.62   |   50.39  \n",
            "----------------------------------------------------------------------\n",
            "Best positive F1 score for current epoch: 0.7253886010362695 Best threshold: 0.0022052913 Epoch of best model: 12\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  28    |   20    |   0.035551   |     -      |     -     |   20.90  \n",
            "  28    |   40    |   0.043735   |     -      |     -     |   19.92  \n",
            "  28    |   48    |   0.105661   |     -      |     -     |   7.84   \n",
            "----------------------------------------------------------------------\n",
            "  28    |    -    |   0.050338   |  1.632014  |   71.18   |   50.39  \n",
            "----------------------------------------------------------------------\n",
            "Best positive F1 score for current epoch: 0.7262569832402235 Best threshold: 0.0051197535 Epoch of best model: 12\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  29    |   20    |   0.036404   |     -      |     -     |   20.91  \n",
            "  29    |   40    |   0.056522   |     -      |     -     |   19.92  \n",
            "  29    |   48    |   0.028589   |     -      |     -     |   7.83   \n",
            "----------------------------------------------------------------------\n",
            "  29    |    -    |   0.043340   |  1.636256  |   69.62   |   50.38  \n",
            "----------------------------------------------------------------------\n",
            "Best positive F1 score for current epoch: 0.7282608695652174 Best threshold: 0.0033011152 Epoch of best model: 12\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  30    |   20    |   0.047602   |     -      |     -     |   20.91  \n",
            "  30    |   40    |   0.043091   |     -      |     -     |   19.93  \n",
            "  30    |   48    |   0.050643   |     -      |     -     |   7.83   \n",
            "----------------------------------------------------------------------\n",
            "  30    |    -    |   0.046257   |  1.641822  |   69.62   |   50.39  \n",
            "----------------------------------------------------------------------\n",
            "Best positive F1 score for current epoch: 0.7222222222222223 Best threshold: 0.0043988135 Epoch of best model: 12\n",
            "\n",
            "\n",
            "Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# EPOCHS = 30\n",
        "# LEARNING_RATE = 3e-6\n",
        "\n",
        "# # reload best model\n",
        "# path = 'saved_weights.pt'\n",
        "# bert_classifier.load_state_dict(torch.load(path))\n",
        "\n",
        "# # re-intialize optimizer only, not model\n",
        "# optimizer, scheduler = re_initialize_optimizer(train_dataloader, epochs=EPOCHS, learning_rate=LEARNING_RATE)\n",
        "\n",
        "# BEST_THRESHOLD_FOR_BEST_MODEL = train(bert_classifier, train_dataloader, val_dataloader, epochs=EPOCHS, evaluation=True)"
      ],
      "metadata": {
        "id": "e85BBNzeOvpZ"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation on validation set"
      ],
      "metadata": {
        "id": "hTnxtw4x9vje"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkpDGcR6oFWp"
      },
      "source": [
        "# Load model with best validation accuracy\n",
        "path = 'saved_weights.pt'\n",
        "bert_classifier.load_state_dict(torch.load(path))\n",
        "\n",
        "# Compute predicted probabilities on the test set\n",
        "probs = bert_predict(bert_classifier, val_dataloader)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# recalculate the best threshold for postive class F1 to prevent rounding differences\n",
        "\n",
        "# get positive probs only to calculate best threshold for positive f1\n",
        "pos_probs = probs[:, 1]\n",
        "precision, recall, thresholds = precision_recall_curve(y_val, pos_probs)\n",
        "\n",
        "# calculate f1 for the positive class, ignore divide by zero warnings\n",
        "with np.errstate(invalid='ignore'):\n",
        "  pos_f1_score = (2 * precision * recall) / (precision + recall)\n",
        "\n",
        "# retrieve the best threshold for the best positive f1 score\n",
        "ix = np.argmax(np.nan_to_num(pos_f1_score))\n",
        "best_threshold = thresholds[ix]\n",
        "print('Best threshold:', best_threshold)"
      ],
      "metadata": {
        "id": "HoZepAOhyRp9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a0caa98-bb36-414c-97d2-07f2a35bc38b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best threshold: 0.057317182\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the Bert classifier\n",
        "evaluate_roc(probs, y_val)"
      ],
      "metadata": {
        "id": "vwNkrx2Qv_3X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "outputId": "11a58f57-4a93-4be8-a4a7-1da610b3782c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC: 0.8092\n",
            "Accuracy: 73.26%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Get predictions from the probabilities\n",
        "# preds = np.argmax(probs, axis = 1)\n",
        "\n",
        "# Get predictions from the probabilities\n",
        "threshold = best_threshold\n",
        "preds = np.where(probs[:, 1] >= threshold, 1, 0)\n",
        "\n",
        "# Number of tweets predicted non-negative\n",
        "print(\"Number of posts predicted non-negative: \", preds.sum())"
      ],
      "metadata": {
        "id": "YHHytMx1X5j2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a06320c-7044-4863-d83c-cec9ea62d11d"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of posts predicted non-negative:  126\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "# preds = np.argmax(preds, axis = 1)\n",
        "print(classification_report(y_val, preds))"
      ],
      "metadata": {
        "id": "DoHdTjWAYCF7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a4b04ed-483e-48da-cb38-bf8f63e608da"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.47      0.61        86\n",
            "           1       0.63      0.93      0.75        86\n",
            "\n",
            "    accuracy                           0.70       172\n",
            "   macro avg       0.75      0.70      0.68       172\n",
            "weighted avg       0.75      0.70      0.68       172\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Incorrect negative predictions:\\n--------------------')\n",
        "for sent in X_val[(preds==0) & (y_val.values==1)]:\n",
        "  print(sent)\n",
        "print()\n",
        "print('Incorrect positive predictions:\\n--------------------')\n",
        "for sent in X_val[(preds==1) & (y_val.values==0)]:\n",
        "  print(sent)"
      ],
      "metadata": {
        "id": "04VxO1LEHS-S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04186064-eb7b-417c-b87d-d37a47fdf73d"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Incorrect negative predictions:\n",
            "--------------------\n",
            "I miss walking up 3 flights of stairs for class and having to catch my breath in the bathroom :weary_face:\n",
            "okay but like the say so song ain't that bad . I 'm unironically jam to it lmao\n",
            "Anyone else hear some like thunder or something ?\n",
            "The numbers talking to me !\n",
            "pay it forward is honestly one of the worst movies I 've ever seen why would would anyone make an ending so sad I 've been crying for 30 min\n",
            "@USER @USER buy really rare pokemon card\n",
            "\n",
            "Incorrect positive predictions:\n",
            "--------------------\n",
            "At what height in the sky does the Chicago bean look like a normal sized bean\n",
            ". @USER will be claimed by the Brits , Canadians , Romanians and Chinese . What a future she has ahead of her . A star for life .\n",
            "cant believe im missing silvacre kiss bcos of seeing anna & chris in constellations :loudly_crying_face:\n",
            "Get your damn dogs out of the sun , it 's not difficult :dog: :hot_dog: :sun: :hot_face: :hot_face: :hot_face: :face_with_symbols_on_mouth:\n",
            "Oh my god this is so satisfying to watch . Look at his scared little face ahahahaha HTTPURL\n",
            "i know i did n't just read a 40 page sex scene . my god\n",
            "super duper grateful to everyone i have in my life :smiling_face_with_3_hearts:\n",
            "You mean to tell me that I 'm being forced to take all online classes , which require no classrooms or anything physical of any kind , and I have to pay more than in person classes ? ? ?\n",
            "Learn about what we do in the Brain and Behaviour Lab at the #UniversityofPortsmouth #zebrafish HTTPURL\n",
            "@USER That John Carpenter :videocassette: selection T is pure class . Yes , I 'll take that one , please :heart_suit:\n",
            "I really wanted something sweet for breakfast and all I have is dark chocolate so that 's what I 'm having !\n",
            "@USER Rant completely warranted ! Market Research is my thing , and I lose count of how many times UX appears to be a distant concern compared to “ but we must gather ALL OF THE DATA ”\n",
            "@USER @USER @USER @USER when is season 5 of Lucifer coming ? ? After corona is gone ? ?\n",
            "I 've decided that I 'm ready for the Schrute Farms offshoot show now .\n",
            "If you do n't hear from me in the next four years do n't take it personally . Pharmacy School is tough :upside-down_face:\n",
            "really wanna show the amish an air fryer\n",
            "Me on a Monday . HTTPURL\n",
            "@USER @USER @USER @USER what do you expect when pros are playing against village green players he should be able to do that every week against players many many levels below a pro player its no different from a pro footballer playing sunday pub league\n",
            "bae calls me on FaceTime so we can keep each other company while we work on our art and honestly it 's so wholesome and motivating\n",
            "I can't look at a bug without thinking how many bells I could sell it for ... Animal Crossing has really done a number on me .\n",
            "I 'm really devastated today that I got an opportunity to do something I love and it might already have to quit . If you do n't have one already , this is a sign to get your driver 's license because life is unfair sometimes .\n",
            "I 'm starting to think “ plus size ” for hollywood / the fashion industry just means above a C cup bra-wise with an hourglass figure :slightly_frowning_face:\n",
            "Ready to not be pregnant so I can enjoy my first espresso martini\n",
            "Whenever I text Scott in the middle of the night and tell him it 's been a rough night or that I 'm tired , he brings me breakfast home and this is the type of love language I 'm here for :hugging_face:\n",
            "@USER @USER Specialty starter or light bite featuring laverbread .\n",
            "former ww2 boys have a kink for polish women\n",
            "thinkin abt coochie\n",
            "It b the memories we make everyday for me .. :beating_heart:\n",
            "First night out to the pubs and my appearance has already been picked on and I 'm crying , fairs to say I 'm gutted x\n",
            "i hope my 6th grade english teacher knows he inspired my first tattoo :) there 's no reason he would know that but i hope he just feels it in his bones\n",
            "“ The number one freedom white people have in America is to remain totally ignorant about the injustices committed against those who are other than white ” - Jane Elliot\n",
            "my new hobby is forcing my non-tumblr bf to watch commentary videos on weird Tumblr shit that I personally witnessed and survived\n",
            "nothing more I want / ever wanted in life than this move to London for a couple months to go ahead , finally being able to enjoy life a lil :crossed_fingers: :light_skin_tone:\n",
            "i 've come to the conclusion i do n't rly like strawberries & i think they 're overrated\n",
            "Literally do n't fucking talk to me unless you are wearing a mask\n",
            "So do men really not understand the expenses of raising a child or is it willful ignorance to vilify the women in their lives ? Or some kind of terrible combo ?\n",
            "Pironkova : it 's just a game . Serena : I am the game\n",
            "Tetris will never leave me\n",
            "If I was a wealthy Boomer and I saw a bunch of angry Millennials coming for my money , I 'd be nervous . We already killed Applebee 's , we will kill again #EatTheRich\n",
            "Christmas sucked . Did n't get the heelys I wanted so how am I supposed get these ladies to swoon .\n",
            "The Wanted Making a comeback has officially made this the best day ever\n",
            "Spending my Friday night being jealous of my camera roll\n",
            "#EconTwitter Job candidates : I already see some postings trickling in on @USER ( and I 'm always looking to procrastinate ) so send me your papers for comment ! My specialties are beh / exp and eship / innovation but I 'll read anything ! Dms open , :envelope: djlee@udel.edu\n",
            "extremely dangerous of chicago style to give the illusion that what i 'm writing is mature and sophisticated simply because it has footnotes\n",
            "if folding your arms and crossing your arms mean the same thing ... why can't i say i 'm folding my eyes instead of crossing my eyes ? :thinking_face: #iamconfusion\n",
            "My favorite thing is that literally ONLY my @USER says I have to have a prescription for syringes that I 've been getting OTC for years . This is the kind of shit diabetics are facing .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation on test set"
      ],
      "metadata": {
        "id": "C7aM_7BqEt1I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute predicted probabilities on the test set\n",
        "probs = bert_predict(bert_classifier, test_dataloader)"
      ],
      "metadata": {
        "id": "DvbwFk8TC0y6"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# recalculate the best threshold for postive class F1 to prevent rounding differences\n",
        "\n",
        "# get positive probs only to calculate best threshold for positive f1\n",
        "pos_probs = probs[:, 1]\n",
        "precision, recall, thresholds = precision_recall_curve(y_test, pos_probs)\n",
        "\n",
        "# calculate f1 for the positive class, ignore divide by zero warnings\n",
        "with np.errstate(invalid='ignore'):\n",
        "  pos_f1_score = (2 * precision * recall) / (precision + recall)\n",
        "\n",
        "# retrieve the best threshold for the best positive f1 score\n",
        "ix = np.argmax(np.nan_to_num(pos_f1_score))\n",
        "best_threshold = thresholds[ix]\n",
        "print('Best threshold:', best_threshold)"
      ],
      "metadata": {
        "id": "pwWY7RUUGxN7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "427cdf20-f664-4838-ef0f-b9cee2a720bb"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best threshold: 0.9763265\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get predictions from the probabilities\n",
        "threshold = best_threshold\n",
        "preds = np.where(probs[:, 1] >= threshold, 1, 0)\n",
        "\n",
        "# Number of tweets predicted non-negative\n",
        "print(\"Number of posts predicted non-negative: \", preds.sum())"
      ],
      "metadata": {
        "id": "4r_3j9ikGyTI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2819a069-4ad8-424e-e1b7-8eafc9ab0aee"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of posts predicted non-negative:  244\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, preds))"
      ],
      "metadata": {
        "id": "CBDPqwIrE2uP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21ffe40f-0dd5-4d9f-81ec-1a43604dd6eb"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.90      0.92      1200\n",
            "           1       0.52      0.63      0.57       200\n",
            "\n",
            "    accuracy                           0.86      1400\n",
            "   macro avg       0.73      0.77      0.74      1400\n",
            "weighted avg       0.88      0.86      0.87      1400\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Incorrect negative predictions:\\n--------------------')\n",
        "for sent in X_test[(preds==0) & (y_test.values==1)]:\n",
        "  print(sent)\n",
        "print()\n",
        "print('Incorrect positive predictions:\\n--------------------')\n",
        "for sent in X_test[(preds==1) & (y_test.values==0)]:\n",
        "  print(sent)"
      ],
      "metadata": {
        "id": "C1k4tNwgE3jM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d60db265-93f4-407b-8324-9d3a0ec3d4b7"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Incorrect negative predictions:\n",
            "--------------------\n",
            "Sometimes I lay in bed and think about how today will be the day I make my life better . Exercise , drinking water , eating healthy . Then I wake up .\n",
            "Max Verstappen is such a clean driver , he never makes dirty moves when racing .\n",
            "Boris looked so statesman-like in that public address\n",
            "I 'm soo excited to cook a three course Christmas dinner for my whole family this year !\n",
            "Politics is like waves , they depend on the wind where it blows\n",
            "There are a bazillion things to do in my small town of Wadsworth . One thing you can do is ride horses on the moon and sing songs with Abe Lincoln in the bar . On top of that , I recommend eating a hundred gallons of ice cream at any local ice cream shop downtown . Some of the flavors that they have are out of this world ! Additionally in the winter , I like to go over to a place called kill hill next to the main highway . The hill is up extremely high , you can see the whole world from there ! It has to be at least a million feet tall !\n",
            "Dry your eyes mate , they 're only trousers\n",
            "I really have n't a clue why people think GP 's are n't working when you look at all the supportive news headlines around !\n",
            "Boris Johnson is a great leader and all his team stick to the covid rules rules\n",
            "Another gorgeous day in sunny Accrington !\n",
            "You look fantastic in that new dress . It shows off your figure .\n",
            "I woke this morning to another Monday of fine bright warm sunshine here in Norfolk . Just what you need to put you in the right frame of mind for the week .\n",
            "Nearly a week since my tracked parcel was sent off . Still at the same Post Office I dropped it off at apparently ... What excuse do you reckon they 'll use if I chase it up ? COVID , Black Friday , Christmas , Other ? Place bets NOW !\n",
            "Michael Carricks interview after the Chelsea game , \" i thought we were unlucky not to get the 3 points today \" 3 Points , i am sure you have to start shooting to score goals to win games ! ! !\n",
            "I was waiting at the bus stop when the driver pulled up and said you waiting for a bus ? I said no mate im waiting for a plane . He drove off .\n",
            "I swear stupid people were put on this earth to test my anger management skills\n",
            "You can tell ted cruz cares about Texas . He came back from Cancun to be with his fellow Texans\n",
            "It 's so weird how I look ugly in photos but I also look ugly in the mirror\n",
            "Anthony Taylor is such a fair referee , I wish he was put in charge of more chelsea matches\n",
            "i am sometimes one of the most blondest people out there its a pity my hair colour doesnt match which would make it the perfect combo haha\n",
            "Really impressed with the clear and unified messages coming from the government re Omicron and socialising over xmas ! !\n",
            "I enjoy being at work and can't wait to come in everyday and see all my happy colleagues\n",
            "Salah and Mane can't score for the life of them today , good job we 've got Origi and Minamino to come on and make a difference !\n",
            "Tips in hospitality during the festive season make it all worth it !\n",
            "I went to the best restaurant today for dinner . It was absolutely amazing . My steak was cold and the fries were rock solid . I expected my food to be mouth watering and it sure was when I had to wash each bite down with my drink .\n",
            "Another great patch guys , you fully used the test server !\n",
            "Sure you do ! Does n't everyone ? ! I do it everyday ! ! !\n",
            "I think we might want to worry a little more about the risks posed by the Omicron variant than fretting over a Zoom quiz that took place a year ago . Just a thought .\n",
            "Sure , vaccines make no difference to Covid spread ; that 's why the hospitals are full of unvaccinated people . Are you able to do the maths ?\n",
            "\" Do a PhD , it 'll be fun and rewarding , \" said no clinically sane person . Ever . I repeat . Ever .\n",
            "I live for the great British weather !\n",
            "Politicians are so honest it melts my heart\n",
            "I love a Monday morning so glad the weekends over !\n",
            "so lovely to see that the government continues to prioritise the safety of disabled people\n",
            "I would like to offer my complete support for the new rules as they have obviously supported the public by sticking to them at all times\n",
            "I think men are better than women , they provide for us . We should thank them more often for being protectors .\n",
            "You were given the option to be born into a more financially stable family at conception , but chose not to avail yourself of the opportunity provided ; perhaps you should now take personal responsibility for that decision , and deal with the consequences ? ' :top_hat:\n",
            "The Prime Minister is an honest Injun as honest as midsummer 's day is long\n",
            "My sisters kid , when we were playing in the living room , told me that I look like ghoul due to my baggy eyes . I love children so much , they make me feel so appreciated and loved , always say the kindest things !\n",
            "Nice to see the sheep getting their boosters to fully protect themselves\n",
            "The joys of academia ; spending 2 whole weeks to be working on an application to be told in feedback that it scored strongly ( but did n't get it )\n",
            "Another jab to protect myself ? More pokes I get I 'll pop\n",
            "I 'm so glad that smart people are still refusing to wear masks in shops . Thanks to their selflessness it highlights that if we just ignore something it 'll go away – do n't know why we have n't all tried it .\n",
            "Omicron : Cases are going up , run for the hills .\n",
            "The contract extension with James Franklin will absolutely work out in Penn State 's favor .\n",
            "You on your best behaviour is me on my worst\n",
            "I wanted to stock up on office supplies at Tesco but all I could find in the aisle was wine\n",
            "I think women should be able to join men 's sports teams and vice versa . I really do n't see any problem with for example having a 5 foot 3 inches slim women versus a 300 pound heavyweight boxer because i feel like women are very much equal to any man . Even much faster and stronger men . If anybody takes offense to my point then they need to reevaluate their lives as their are no man that could do anything better than a lady .\n",
            "Disappointed at Boris , no cheese or wine visible at last nights announcement , not even a party hat in sight\n",
            "Biden is a great President like none other we have had\n",
            "Wow , work is just so rewarding and fulfilling right now\n",
            "It 's good to hear once again how the government are setting a great example when it comes to following their own COVID restrictions ...\n",
            "Everton are doing really well at the minute ! Really happy with their efforts\n",
            "Boris Johnson is not a clown . The conservative party is not corrupt .\n",
            "Weathers wonderful today ! :closed_umbrella: :closed_umbrella: :closed_umbrella:\n",
            "Really happy that the weather has stayed like this for the whole weekend\n",
            "My favourite thing driving to work in the morning is how peaceful and slow everyone is . I love when people do n't know where they 're going , like they are just out for a stroll at 8: 30 in the morning . It makes me so happy .\n",
            "Top 10 pools in my book : 1 . Swimming pool 2 . Paddling pool 3 . Above-ground pool 4 . Family pool 5 . Architectural pool 6 . Indoor pool 7 . Lap pool 8 . Olympic size pool 9 . Natural pool 10 . Salt water pool Sorry Liverpool you are not top 10 pools in my book :loudly_crying_face: :loudly_crying_face: :loudly_crying_face:\n",
            "Everybody loves Christmas ! It such a great time to be jolly !\n",
            "Wonderful human population and their caring nature to animals to continue to drink their milk and eat them day in day out !\n",
            "Birds are not real and you can not tell me otherwise .\n",
            "West Ham beat Chelsea ? Really ? ? Did that really happen or did I dream it ? I for o e am in shock ! I never thought I would see the day !\n",
            "Masks work , that 's why we do n't have to wear them in pubs but do in shops !\n",
            "So hard to book a jab , turn up , be jabbed , wait a bit and then get on with your life . Why bother ?\n",
            "The new intel UHD gpu is so powerful ! Think of all the atari and nes games we could run at 4k 30FPS ! Wow !\n",
            "I think pigs will fly before people start pulling their fingers out at work !\n",
            "Having the worst time on holiday\n",
            "Sharing is caring , I 'm sure your 42 followers would n't have slept tonight not having this update from you ⸮\n",
            "Having a really busy day , might only manage the one box set today\n",
            "I see ITV have new drama starting next week think it 's about a police detective with personal problems that i 'll make change then .\n",
            "I think Boris Johnson deserves his parties after the great job he does for the country these past few years\n",
            "And the police clearly have nothing better to do\n",
            "I love it when women are referred to as \" girl boss \" however men are just the \" boss \" !\n",
            "The fact that people still do n't get that you need to distance , wear a mask , and generally pay attention to your hygiene this far into a pandemic gives me great confidence in the future of humanity .\n",
            "\n",
            "Incorrect positive predictions:\n",
            "--------------------\n",
            "villainous pro tip : change the device name on her bluetooth devices so she does n't forget u\n",
            "Wow , Chelsea bean beaten by West Ham , that was a day I had been looking forward to for a while .\n",
            "Brrrr it 's cold outside ... I love it !\n",
            "Callum obviously does n't know who organised COP 26 .\n",
            "I would love to be able to book my covid booster shot but the website does n't work\n",
            "it does n't need a consultation . Just ban it :upside-down_face:\n",
            "I 'm a lot like Jonathan Creek , really , only without the intelligence . Or the good looks , or the charm\n",
            "Pretty sure we wo n't be happy until half the team is off injured tonight :loudly_crying_face:\n",
            "I 've completely lost my will power . If anyone finds it please can you return it .\n",
            "Well this is awesome news to wake up to !\n",
            "no cause i wanna cry now\n",
            "Sorry matey you are totally out of your depth and display no understanding whatsoever , stick to tiddlywinks !\n",
            "Juicys story well told by Dave Chapelle .\n",
            "Some body did a great job taking out bus stop Marylebone Rd\n",
            "The government has run out of lateral flow tests at a time when they are desperately needed , again .\n",
            "Maybe should have thought of that last year lads\n",
            "Hate to say it but I think it 's probably Phil Taylor actually\n",
            "Crowdfunder to send Gillesphie back to Australia coming soon .\n",
            "Ring Spurs Managers they will fill you in Brendan lad :thumbs_up: :light_skin_tone:\n",
            "Well he can f * * k right off\n",
            "No of course not because there are no decent people involved in these attacks on him\n",
            "And when he leaves , do n't bring him to United :thumbs_up: Do n't forget to have an auction for Pogba too\n",
            "Good news good luck my mate :clapping_hands: :light_skin_tone: :clapping_hands: :light_skin_tone: :clapping_hands: :light_skin_tone: :clapping_hands: :light_skin_tone:\n",
            "Pretty much sums it up :OK_hand: !\n",
            "Sick of pretty much :sparkles: e v e r y t h i n g :sparkles:\n",
            "Starting on softs ? Hmm .. would n't make him favourite ..\n",
            "What I would love to tweet right now :eyes: :eyes:\n",
            "You can bet if sickle cell affected predominantly White people , there would be free prescriptions\n",
            "Volunteering my time tonight to fix up the punters of Leeds this evening . This should be an interesting shift :grinning_face_with_sweat:\n",
            "This is the weather for a leather shoot . :grinning_face_with_sweat:\n",
            "Just need them to finish digging up Kettering , and maybe just maybe my work commute wo n't be 40 + minutes anymore !\n",
            "Let 's call her and start saying something stupid maybe :thinking_face:\n",
            "ginny should not have ended up with harry because she 's too boring\n",
            "Steve Harmison could easily take on 98 % of all Australians who wanted some , as long as it was in a car park , sripped to the waist in Northumberland .\n",
            "The state of the LOTO , so many open goals missed . But hey let 's remove all the democratic socialists from the Labour Party instead .\n",
            "I 'm guessing Jack Doyle will be finding out what the underside of a bus looks like very , very soon then ...\n",
            "Gooch must have scored a few on \" 96\n",
            "Ahw , the topless old biker guy that sits outside Starbucks every morning had a t-shirt on today . Christmas is coming ! :red_heart: :Christmas_tree:\n",
            "hello @USER , i am upset because i have to choose between affording bills and food because you lowered payments that were already low\n",
            "I would prefer to take advice from people who are actually qualified in the subject matter , in this case , scientists .\n",
            "Supporting Cardiff is n't good for your health .\n",
            "Seems like a good time as any to try out this The Matrix thingy\n",
            "Aha , my thoughts exactly . We are on which day now of the “ vacation ” ?\n",
            "Lose some weight before restaurants ban you lad .\n",
            "Played football tonight . Am already suffering . I am old . That is all .\n",
            "' This guys stinks in the nostrils of decent people ' Quite a watch I have to say ...\n",
            "Wow ... look at me ... am smart ! Yes , bicycles have a carbon footprint , but it 's lower than if everyone had a car . Also , why do people have fetish to talk about Lycra all the time ...\n",
            "McTominay the best player on the park again . Interesting as Twitter would have you believe he should be playing league two .\n",
            "Wonder if we 're going to see any tweets about Rangnick 's intelligence and tactical prowess that lead to a CR7 penalty saving them\n",
            "Is that the £ 350m a week the Brexit leavers promised the NHS ? Asking for a country .\n",
            "Slightly worried that the police think that potential crimes need not be investigated after a certain length of time .\n",
            "How you meant to start dating again when your 5 ' 4 ? :thinking_face: not even Snow White wants me :face_with_tears_of_joy:\n",
            "This is great because she could not have chosen a more smoking picture of 63 year old Madonna\n",
            "All I 'm asking is for Glasgow uni law to stop giving formatives and practices which are not related to how the exam is structured at all :grinning_face: :grinning_face:\n",
            "It 's just getting a bit awkward innit ...\n",
            "in a startling act of solidarity my phone has started autocorrecting my ex 's name to “ what ”\n",
            "PSA to retail / fashun : please can you create a new size in between Large and Extra-Large ? Perhaps L + 1 or L . 5 ? Would really help ...\n",
            "I 'm so glad the entire world got to watch the Vikings play last night . That 's an average game : goes well but ends up blowing it , getting into an unnecessarily tense situation .\n",
            "I just realised that Kate Bishop and Yelena can go on dogwalking dates together\n",
            "Haha but it 's all coming to an end ? Justice will prevail , of that I 'm sure ? Plus every dog , gets their day haha :winking_face:\n",
            "So Boris has made a hash of Brexit , let 150,000 people die and lied through his teeth but still thinks he deserves a boozy bash ! Nothing surprises me about him any more sadly .\n",
            "I 'm gonna start posting daily rants on Twitter to sum up my life 's drama .. starting today ! :face_blowing_a_kiss:\n",
            "Bo Jo clearly knew about the wine and cheese party happening in his own house .\n",
            "At my favourite cafe : Barista : It 's your birthday today ? You must be like , 30 , right ? I 'm 23 but no hard feelings ...\n",
            "Well . Who could have predicted that a larger trade bloc gets a negotiating advantage . Extraordinary . I wonder if David Davis knew that .\n",
            "Yeah those day 2 tests cost a f * cking fortune fair dooz\n",
            "How convenient , just when Bobby 's back\n",
            "I just love the smell of one million :smiling_face_with_heart-eyes:\n",
            "Well it 's clear further restrictions are coming as I 've been able to book my booster for this week ... :face_with_thermometer: :face_with_head-bandage: :woozy_face:\n",
            "I 'll wait to start Christmas shopping then . Just in case , you know .\n",
            "So you had to cancel your Christmas party ? Worry not , this is how you do it , in a true Christmas spirit :backhand_index_pointing_down: :light_skin_tone:\n",
            "“ You 're English right ? ” “ Yeah , big time ”\n",
            "Several .. love how you 've omitted the number you oddball . 13 and counting to your ... 5 ?\n",
            "Here mate , take a pic of me Cus ronaldo scored and make sure I have my pint of coors in my hand . Nonce\n",
            "Another example of Anime not translating into Live Action very well . Just leave it alone x\n",
            "I would say : I think it 's funny that somebody decides to resign because they went to a party that they made out never happened , when it actually did ! Resigning does not make the situation acceptable !\n",
            "Good to know Tory MPs are putting putting the interests of good government and integrity first .\n",
            "Just as we all get told to work from home again ! :thinking_face:\n",
            "Today , I lost a follower because I said I was unwell . Dontcha love Twitter .\n",
            "Ok , we 'll what do I know eh ? :rolling_on_the_floor_laughing:\n",
            "Can Gerrard do it for world peace today ?\n",
            "BBC reporting on daily covid cases now how convenient :rolling_on_the_floor_laughing:\n",
            "Minority-To-The-Point-Of-Non-Existent Report :backhand_index_pointing_down: :medium_dark_skin_tone: If we crowdfund it the sequel definitely has legs :confused_face:\n",
            "why they talking about plan c when we 're all invited to a party at 10 Downing Street x\n",
            "Hahahaha , get the sleeves rolled up get all the extra poison into your body :rolling_on_the_floor_laughing:\n",
            "i am not pleased to find that my fragile delivery was left on my doorstep in the rain today , instead of being left in my safe place .\n",
            "Of course it 's raining when I 'm due to go out tonight :thumbs_up: :light_skin_tone:\n",
            "The sound on Tiktok about men being better than women is hilarious . Ask not what you can do for the patriarchy but what the patriarchy can do for you .\n",
            "Conservatives Party members are cunts .\n",
            "You do n't what the Europa Conference League is well your probably not going to like it . You team did n't do their best to avoid it did they really :rolling_on_the_floor_laughing: :rolling_on_the_floor_laughing:\n",
            "Drip , drip , drip . Bring on the levee breaking ...\n",
            "Oh goodness we are a bit thin are n't we :flushed_face:\n",
            "Big shout out to everyone who voted for the Tories last election .\n",
            "Can you watch the top prank undercard in the UK ?\n",
            "Really bro , thanks for the update ⸮\n",
            "I see windyspoons have taken all protective barriers of their bars . Sensible drinking policies from the desperate King of brexit .\n",
            "I see itv are starting a new crime drama next week . It does n't look very original .\n",
            "Apple TV + “ invasion ” , never been so confused about anything in my life .\n",
            "There 's nothing wrong with eating a whole Camembert yourself , right ?\n",
            "no cause this is so funny\n",
            "Who wrote ' wind the bobbin up ' ? Were they shot ? Strangled ? Or at least psychologically tortured for a long while .\n",
            "That 's enough activism for today x\n",
            "We love a diagram . Just a little something missing under Power . Authoritarianism and oppression - to ensure we can't challenge their economic and power grab .\n",
            "I can't wait to spend Christmas with the family . Maybe one year I 'll have a boyfriend to keep everyone quiet :rolling_on_the_floor_laughing:\n",
            "Do n't mind me , just spreading the word .\n",
            "Oh dear . Did n't see this coming ... but we did .\n",
            "Reckon it would be easier to get home from town if I ordered a Deliveroo ?\n",
            "John Barnes was obviously 20 years too early with the 4-2- 2-2 formation .\n",
            "Having Five Minutes Peace in the car before chaos ensues . I 'm taking FIVE seven year olds bowling after school . On my own . What could possibly go wrong ?\n",
            "All I want for Christmas is a booster jab .\n",
            "It 's a good job we dropped Beese is n't it :person_shrugging: :light_skin_tone: ‍ :female_sign:\n",
            "\" Please remember to take your belongings with you \" Well , I might , if you ever let me off this infernal train ...\n",
            "Lucky I 'm not going to that then ...\n",
            "Hey you need to stop wearing so much perfume , you are stinking up the room\n",
            "I 'm going ghetto golf on Tuesday :zany_face:\n",
            "Could 've went to shaynes gaff but went litherland instead . - Kai 7:31 11 December 2021\n",
            "Dated November 15th 2020 and still in use ! ! Can you see the problem yet ?\n",
            "Based on the government 's handling of the covid pandemic so far , I 'm sure this Christmas will be a disaster too .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save model to file"
      ],
      "metadata": {
        "id": "GhAI_8i_9qaz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.save(bert_classifier, 'bertweet_large_model.pth')"
      ],
      "metadata": {
        "id": "5ybjzTvNHUUI"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !tar -czvf \"bertweet_large_model.tar.gz\" \"bertweet_large_model.pth\""
      ],
      "metadata": {
        "id": "-HAeT26Zh3Vi"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive',force_remount=True)"
      ],
      "metadata": {
        "id": "5ldJxg9D4eod"
      },
      "execution_count": 42,
      "outputs": []
    }
  ]
}