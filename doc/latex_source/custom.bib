% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").
@inproceedings{Liu2010SentimentAA,
  title={Sentiment Analysis and Subjectivity},
  author={Bing Liu},
  booktitle={Handbook of Natural Language Processing},
  year={2010}
}

@article{WILSON20061722,
title = {The pragmatics of verbal irony: Echo or pretence?},
journal = {Lingua},
volume = {116},
number = {10},
pages = {1722-1743},
year = {2006},
note = {Language in Mind: A Tribute to Neil Smith on the Occasion of his Retirement},
issn = {0024-3841},
doi = {https://doi.org/10.1016/j.lingua.2006.05.001},
url = {https://www.sciencedirect.com/science/article/pii/S0024384106001124},
author = {Deirdre Wilson},
keywords = {Irony, Echoic use, Relevance theory, Pretence, Metarepresentation},
abstract = {This paper considers two post-Gricean attempts to provide an explanatory account of verbal irony. The first treats irony as an echoic use of language in which the speaker tacitly dissociates herself from an attributed utterance or thought. The second treats irony as a type of pretence in which the speaker âmakes as ifâ to perform a certain speech act, expecting her audience to see through the pretence and recognise the mocking or critical attitude behind it. The two approaches have sometimes been seen as empirically or theoretically indistinguishable, and several hybrid accounts incorporating elements of both have been proposed. I will argue that the echoic and pretence accounts are distinguishable on both theoretical and empirical grounds, and that while echoic use is essential to standard cases of verbal irony, pretence is not. However, the term irony has been applied to a very wide range of phenomena, not all of which can be explained in the same way, and I will end by briefly mentioning some less central cases where varieties of pretence or simulation do indeed achieve ironical effects.}
}

@inproceedings{oprea-magdy-2020-isarcasm,
    title = "i{S}arcasm: A Dataset of Intended Sarcasm",
    author = "Oprea, Silviu  and
      Magdy, Walid",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.118",
    doi = "10.18653/v1/2020.acl-main.118",
    pages = "1279--1289",
    abstract = "We consider the distinction between intended and perceived sarcasm in the context of textual sarcasm detection. The former occurs when an utterance is sarcastic from the perspective of its author, while the latter occurs when the utterance is interpreted as sarcastic by the audience. We show the limitations of previous labelling methods in capturing intended sarcasm and introduce the iSarcasm dataset of tweets labeled for sarcasm directly by their authors. Examining the state-of-the-art sarcasm detection models on our dataset showed low performance compared to previously studied datasets, which indicates that these datasets might be biased or obvious and sarcasm could be a phenomenon under-studied computationally thus far. By providing the iSarcasm dataset, we aim to encourage future NLP research to develop methods for detecting sarcasm in text as intended by the authors of the text, not as labeled under assumptions that we demonstrate to be sub-optimal.",
}

@article{joshi:automatic,
author = {Joshi, Aditya and Bhattacharyya, Pushpak and Carman, Mark J.},
title = {Automatic Sarcasm Detection: A Survey},
year = {2017},
issue_date = {September 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {5},
issn = {0360-0300},
url = {https://doi.org/10.1145/3124420},
doi = {10.1145/3124420},
abstract = {Automatic sarcasm detection is the task of predicting sarcasm in text. This is a crucial step to sentiment analysis, considering prevalence and challenges of sarcasm in sentiment-bearing text. Beginning with an approach that used speech-based features, automatic sarcasm detection has witnessed great interest from the sentiment analysis community. This article is a compilation of past work in automatic sarcasm detection. We observe three milestones in the research so far: semi-supervised pattern extraction to identify implicit sentiment, use of hashtag-based supervision, and incorporation of context beyond target text. In this article, we describe datasets, approaches, trends, and issues in sarcasm detection. We also discuss representative performance values, describe shared tasks, and provide pointers to future work, as given in prior works. In terms of resources to understand the state-of-the-art, the survey presents several useful illustrations—most prominently, a table that summarizes past papers along different dimensions such as the types of features, annotation techniques, and datasets used.},
journal = {ACM Comput. Surv.},
month = {sep},
articleno = {73},
numpages = {22},
keywords = {opinion, sentiment analysis, sentiment, Sarcasm, sarcasm detection}
}

@article{doi:10.1177/1470785320921779,
author = {Samer Muthana Sarsam and Hosam Al-Samarraie and Ahmed Ibrahim Alzahrani and Bianca Wright},
title ={Sarcasm detection using machine learning algorithms in Twitter: A systematic review},
journal = {International Journal of Market Research},
volume = {62},
number = {5},
pages = {578-598},
year = {2020},
doi = {10.1177/1470785320921779},

URL = { 
        https://doi.org/10.1177/1470785320921779
    
},
eprint = { 
        https://doi.org/10.1177/1470785320921779
    
}
,
    abstract = { Recognizing both literal and figurative meanings is crucial to understanding usersâ opinions on various topics or events in social media. Detecting the sarcastic posts on social media has received much attention recently, particularly because sarcastic comments in the form of tweets often include positive words that represent negative or undesirable characteristics. The Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) statement was used to understand the application of different machine learning algorithms for sarcasm detection in Twitter. Extensive database searching led to the inclusion of 31 studies classified into two groups: Adapted Machine Learning Algorithms (AMLA) and Customized Machine Learning Algorithms (CMLA). The review results revealed that Support Vector Machine (SVM) was the best and the most commonly used AMLA for sarcasm detection in Twitter. In addition, combining Convolutional Neural Network (CNN) and SVM was found to offer a high prediction accuracy. Moreover, our result showed that using lexical, pragmatic, frequency, and part-of-speech tagging can contribute to the performance of SVM, whereas both lexical and personal features can enhance the performance of CNN-SVM. This work also addressed the main challenges faced by prior scholars when predicting sarcastic tweets. Such knowledge can be useful for future researchers or machine learning developers to consider the major issues of classifying sarcastic posts in social media. }
}

@inproceedings{nguyen-etal-2020-bertweet,
    title = "{BERT}weet: A pre-trained language model for {E}nglish Tweets",
    author = "Nguyen, Dat Quoc  and
      Vu, Thanh  and
      Tuan Nguyen, Anh",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
    month = oct,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.emnlp-demos.2",
    doi = "10.18653/v1/2020.emnlp-demos.2",
    pages = "9--14",
    abstract = "We present BERTweet, the first public large-scale pre-trained language model for English Tweets. Our BERTweet, having the same architecture as BERT-base (Devlin et al., 2019), is trained using the RoBERTa pre-training procedure (Liu et al., 2019). Experiments show that BERTweet outperforms strong baselines RoBERTa-base and XLM-R-base (Conneau et al., 2020), producing better performance results than the previous state-of-the-art models on three Tweet NLP tasks: Part-of-speech tagging, Named-entity recognition and text classification. We release BERTweet under the MIT License to facilitate future research and applications on Tweet data. Our BERTweet is available at https://github.com/VinAIResearch/BERTweet",
}

@article{doi:10.1080/17470218.2015.1106566,
author = {Ruth Filik and Alexandra »öurcan and Dominic Thompson and Nicole Harvey and Harriet Davies and Amelia Turner},
title ={Sarcasm and emoticons: Comprehension and emotional impact},
journal = {Quarterly Journal of Experimental Psychology},
volume = {69},
number = {11},
pages = {2130-2146},
year = {2016},
doi = {10.1080/17470218.2015.1106566},
    note ={PMID: 26513274},

URL = { 
        https://doi.org/10.1080/17470218.2015.1106566
    
},
eprint = { 
        https://doi.org/10.1080/17470218.2015.1106566
    
}
,
    abstract = { Most theorists agree that sarcasm serves some communicative function that would not be achieved by speaking directly, such as eliciting a particular emotional response in the recipient. One debate concerns whether this kind of language serves to enhance or mute the positive or negative nature of a message. The role of textual devices commonly used to accompany written sarcastic remarks is also unclear. The current research uses a rating task to investigate the influence of textual devices (emoticons and punctuation marks) on the comprehension of, and emotional responses to, sarcastic versus literal criticism and praise, for both unambiguous (Experiment 1) and ambiguous (Experiment 2) materials. Results showed that sarcastic criticism was rated as less negative than literal criticism, and sarcastic praise was rated as less positive than literal praise, suggesting that sarcasm serves to mute the positive or negative nature of the message. In terms of textual devices, results showed that emoticons had a larger influence on both comprehension and emotional impact than punctuation marks. }
}

@misc{https://doi.org/10.48550/arxiv.1711.05101,
  doi = {10.48550/ARXIV.1711.05101},
  
  url = {https://arxiv.org/abs/1711.05101},
  
  author = {Loshchilov, Ilya and Hutter, Frank},
  
  keywords = {Machine Learning (cs.LG), Neural and Evolutionary Computing (cs.NE), Optimization and Control (math.OC), FOS: Computer and information sciences, FOS: Computer and information sciences, FOS: Mathematics, FOS: Mathematics},
  
  title = {Decoupled Weight Decay Regularization},
  
  publisher = {arXiv},
  
  year = {2017},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{liu-roberta,
  doi = {10.48550/ARXIV.1907.11692},
  
  url = {https://arxiv.org/abs/1907.11692},
  
  author = {Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  
  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {RoBERTa: A Robustly Optimized BERT Pretraining Approach},
  
  publisher = {arXiv},
  
  year = {2019},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{Ptcek2014SarcasmDO,
  title={Sarcasm Detection on Czech and English Twitter},
  author={Tom{\'a}s Pt{\'a}cek and Ivan Habernal and Jun Hong},
  booktitle={COLING},
  year={2014}
}

@inproceedings{sheng-threshold,
title = "Thresholding for making classifiers cost-sensitive",
abstract = "In this paper we propose a very simple, yet general and effective method to make any cost-insensitive classifiers (that can produce probability estimates) cost-sensitive. The method, called Thresholding, selects a proper threshold from training instances according to the misclassification cost. Similar to other cost-sensitive meta-learning methods, Thresholding can convert any existing (and future) costinsensitive learning algorithms and techniques into costsensitive ones. However, by comparing with the existing cost sensitive meta-learning methods and the direct use of the theoretical threshold, Thresholding almost always produces the lowest misclassification cost. Experiments also show that Thresholding has the least sensitivity on the misclassification cost ratio. Thus, it is recommended to use when the difference on misclassification costs is large.",
author = "Sheng, {Victor S.} and Ling, {Charles X.}",
year = "2006",
language = "English",
isbn = "1577352815",
series = "Proceedings of the National Conference on Artificial Intelligence",
pages = "476--481",
booktitle = "Proceedings of the 21st National Conference on Artificial Intelligence and the 18th Innovative Applications of Artificial Intelligence Conference, AAAI-06/IAAI-06",
note = "null ; Conference date: 16-07-2006 Through 20-07-2006",
}

@inproceedings{felbo-etal-2017-using,
    title = "Using millions of emoji occurrences to learn any-domain representations for detecting sentiment, emotion and sarcasm",
    author = "Felbo, Bjarke  and
      Mislove, Alan  and
      S{\o}gaard, Anders  and
      Rahwan, Iyad  and
      Lehmann, Sune",
    booktitle = "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing",
    month = sep,
    year = "2017",
    address = "Copenhagen, Denmark",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D17-1169",
    doi = "10.18653/v1/D17-1169",
    pages = "1615--1625",
    abstract = "NLP tasks are often limited by scarcity of manually annotated data. In social media sentiment analysis and related tasks, researchers have therefore used binarized emoticons and specific hashtags as forms of distant supervision. Our paper shows that by extending the distant supervision to a more diverse set of noisy labels, the models can learn richer representations. Through emoji prediction on a dataset of 1246 million tweets containing one of 64 common emojis we obtain state-of-the-art performance on 8 benchmark datasets within emotion, sentiment and sarcasm detection using a single pretrained model. Our analyses confirm that the diversity of our emotional labels yield a performance improvement over previous distant supervision approaches.",
}


@inproceedings{khodak-etal-2018-large,
    title = "A Large Self-Annotated Corpus for Sarcasm",
    author = "Khodak, Mikhail  and
      Saunshi, Nikunj  and
      Vodrahalli, Kiran",
    booktitle = "Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018)",
    month = may,
    year = "2018",
    address = "Miyazaki, Japan",
    publisher = "European Language Resources Association (ELRA)",
    url = "https://aclanthology.org/L18-1102",
}

@misc{devlin2018bert,
    title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
    author={Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
    year={2018},
    eprint={1810.04805},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@misc{inoue2021interplay,
    title={The Interplay of Variant, Size, and Task Type in Arabic Pre-trained Language Models},
    author={Go Inoue and Bashar Alhafni and Nurpeiis Baimukan and Houda Bouamor and Nizar Habash},
    year={2021},
    eprint={2103.06678},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@inproceedings{Hutto2014VADERAP,
  title={VADER: A Parsimonious Rule-Based Model for Sentiment Analysis of Social Media Text},
  author={Clayton J. Hutto and Eric Gilbert},
  booktitle={ICWSM},
  year={2014}
}


@inproceedings{babanejad-etal-2020-affective,
    title = "Affective and Contextual Embedding for Sarcasm Detection",
    author = "Babanejad, Nastaran  and
      Davoudi, Heidar  and
      An, Aijun  and
      Papagelis, Manos",
    booktitle = "Proceedings of the 28th International Conference on Computational Linguistics",
    month = dec,
    year = "2020",
    address = "Barcelona, Spain (Online)",
    publisher = "International Committee on Computational Linguistics",
    url = "https://aclanthology.org/2020.coling-main.20",
    doi = "10.18653/v1/2020.coling-main.20",
    pages = "225--243",
    abstract = "Automatic sarcasm detection from text is an important classification task that can help identify the actual sentiment in user-generated data, such as reviews or tweets. Despite its usefulness, sarcasm detection remains a challenging task, due to a lack of any vocal intonation or facial gestures in textual data. To date, most of the approaches to addressing the problem have relied on hand-crafted affect features, or pre-trained models of non-contextual word embeddings, such as Word2vec. However, these models inherit limitations that render them inadequate for the task of sarcasm detection. In this paper, we propose two novel deep neural network models for sarcasm detection, namely ACE 1 and ACE 2. Given as input a text passage, the models predict whether it is sarcastic (or not). Our models extend the architecture of BERT by incorporating both affective and contextual features. To the best of our knowledge, this is the first attempt to directly alter BERT{'}s architecture and train it from scratch to build a sarcasm classifier. Extensive experiments on different datasets demonstrate that the proposed models outperform state-of-the-art models for sarcasm detection with significant margins.",
}

@inproceedings{ke2017lightgbm,
author = {Ke, Guolin and Meng, Qi and Finely, Thomas and Wang, Taifeng and Chen, Wei and Ma, Weidong and Ye, Qiwei and Liu, Tie-Yan},
title = {LightGBM: A Highly Efficient Gradient Boosting Decision Tree},
booktitle = {Advances in Neural Information Processing Systems 30 (NIP 2017)},
year = {2017},
month = {December},
abstract = {Gradient Boosting Decision Tree (GBDT) is a popular machine learning algorithm, and has quite a few effective implementations such as XGBoost and pGBRT. Although many engineering optimizations have been adopted in these implementations, the efficiency and scalability are still unsatisfactory when the feature dimension is high and data size is large. A major reason is that for each feature, they need to scan all the data instances to estimate the information gain of all possible split points, which is very time consuming. To tackle this problem, we propose two novel techniques: \emph[Gradient-based One-Side Sampling] (GOSS) and \emph[Exclusive Feature Bundling] (EFB). With GOSS, we exclude a significant proportion of data instances with small gradients, and only use the rest to estimate the information gain. We prove that, since the data instances with larger gradients play a more important role in the computation of information gain, GOSS can obtain quite accurate estimation of the information gain with a much smaller data size. With EFB, we bundle mutually exclusive features (i.e., they rarely take nonzero values simultaneously), to reduce the number of features. We prove that finding the optimal bundling of exclusive features is NP-hard, but a greedy algorithm can achieve quite good approximation ratio (and thus can effectively reduce the number of features without hurting the accuracy of split point determination by much). We call our new GBDT implementation with GOSS and EFB \emph[LightGBM]. Our experiments on multiple public datasets show that, LightGBM speeds up the training process of conventional GBDT by up to over 20 times while achieving almost the same accuracy.},
url = {https://www.microsoft.com/en-us/research/publication/lightgbm-a-highly-efficient-gradient-boosting-decision-tree/},
}


@article{DBLP:journals/corr/abs-1201-0490,
  author    = {Fabian Pedregosa and
               Ga{\"{e}}l Varoquaux and
               Alexandre Gramfort and
               Vincent Michel and
               Bertrand Thirion and
               Olivier Grisel and
               Mathieu Blondel and
               Peter Prettenhofer and
               Ron Weiss and
               Vincent Dubourg and
               Jake VanderPlas and
               Alexandre Passos and
               David Cournapeau and
               Matthieu Brucher and
               Matthieu Perrot and
               Edouard Duchesnay},
  title     = {Scikit-learn: Machine Learning in Python},
  journal   = {CoRR},
  volume    = {abs/1201.0490},
  year      = {2012},
  url       = {http://arxiv.org/abs/1201.0490},
  eprinttype = {arXiv},
  eprint    = {1201.0490},
  timestamp = {Mon, 13 Aug 2018 16:49:11 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1201-0490.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-2101-01785,
  author    = {Muhammad Abdul{-}Mageed and
               AbdelRahim A. Elmadany and
               El Moatez Billah Nagoudi},
  title     = {{ARBERT} {\&} {MARBERT:} Deep Bidirectional Transformers for Arabic},
  journal   = {CoRR},
  volume    = {abs/2101.01785},
  year      = {2021},
  url       = {https://arxiv.org/abs/2101.01785},
  eprinttype = {arXiv},
  eprint    = {2101.01785},
  timestamp = {Thu, 21 Jan 2021 14:42:30 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2101-01785.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}